{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>One line of code to get embeddings from any Remote Sensing Foundation Model (RSFM) for any location and any time</p>"},{"location":"#start-here","title":"Start Here","text":""},{"location":"#if-you-are-new","title":"If you are new","text":"<ol> <li>Read Quick Start to install and run a first example</li> <li>Read Core Concepts to understand temporal/output semantics</li> <li>Use Common Workflows to pick the right API for your task</li> </ol>"},{"location":"#if-you-want-to-choose-a-model","title":"If you want to choose a model","text":"<ul> <li>Go to Supported Models for the comparison matrix, preprocessing notes, and temporal behavior</li> </ul>"},{"location":"#if-you-want-exact-signatures-and-parameters","title":"If you want exact signatures and parameters","text":"<ul> <li>Go to API Reference</li> </ul>"},{"location":"#common-tasks","title":"Common Tasks","text":"Goal Best Entry Point Main API Get one embedding for one ROI Quick Start <code>get_embedding(...)</code> Compute embeddings for many ROIs (same model) Common Workflows <code>get_embeddings_batch(...)</code> Build an export dataset for experiments Common Workflows <code>export_batch(...)</code> Debug bad inputs/clouds/band issues Common Workflows <code>inspect_provider_patch(...)</code> / <code>inspect_gee_patch(...)</code> Compare model preprocessing and I/O assumptions Supported Models model matrix + notes"},{"location":"#motivation","title":"Motivation","text":"<p>The remote sensing community has seen an explosion of foundation models in recent years. Yet, using them in practice remains surprisingly painful: * Inconsistent model interfaces (imagery vs. tile embeddings) * Ambiguous input semantics (patch / tile / grid / pooled) * Large differences in temporal, spectral, and spatial requirements * No easy way to fairly compare multiple models in a single experiment</p> <p>RS-Embed aims to fix this.</p> <p>Goal</p> <p>Provide a minimal, unified, and stable API that turns diverse RS foundation models into a simple <code>ROI \u2192 embedding service</code> \u2014 so researchers can focus on downstream tasks, benchmarking, and analysis, not glue code.</p>"},{"location":"#why-rs-embed","title":"Why rs-embed?","text":"<ul> <li>Unified interface for diverse embedding models (on-the-fly models and precomputed products).</li> <li>Spatial + temporal specs to describe what you want, not how to fetch it.</li> <li>Batch export as a first-class workflow via <code>export_batch</code>.</li> </ul>"},{"location":"#documentation-map","title":"Documentation Map","text":""},{"location":"#learn","title":"Learn","text":"<ul> <li>Quick Start: installation + first successful runs</li> <li>Core Concepts: mental model (<code>TemporalSpec</code>, <code>OutputSpec</code>, backends)</li> </ul>"},{"location":"#guides","title":"Guides","text":"<ul> <li>Common Workflows: task-oriented usage patterns</li> <li>Supported Models: model capabilities, preprocessing, env knobs</li> </ul>"},{"location":"#reference","title":"Reference","text":"<ul> <li>API Reference: exact signatures and parameter details</li> <li>Limitations: current constraints and known edge cases</li> </ul>"},{"location":"#development","title":"Development","text":"<ul> <li>Extending: add new model adapters and integrate with registry/export</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This is the API reference entry page.</p> <p><code>rs-embed</code> API docs are split by topic for readability:</p> <ul> <li>API: Specs and Data Structures</li> <li>API: Embedding</li> <li>API: Export</li> <li>API: Inspect</li> </ul> <p>If you are looking for task-oriented usage first:</p> <ul> <li>Quick Start: fastest first run</li> <li>Common Workflows: task-first recipes</li> <li>Core Concepts: semantics for <code>TemporalSpec</code>, <code>OutputSpec</code>, and backends</li> </ul>"},{"location":"api/#imports","title":"Imports","text":"<pre><code>from rs_embed import (\n    # Specs\n    BBox, PointBuffer, TemporalSpec, SensorSpec, OutputSpec, InputPrepSpec,\n    # Core APIs\n    get_embedding, get_embeddings_batch, export_batch, export_npz,\n    # Utilities\n    inspect_provider_patch,\n    inspect_gee_patch,\n)\n</code></pre>"},{"location":"api/#choose-by-task","title":"Choose by Task","text":"I want to... Read this page understand spatial/temporal/output specs API: Specs and Data Structures get one embedding or batch embeddings API: Embedding build export pipelines and datasets API: Export inspect raw provider patches before inference API: Inspect"},{"location":"api/#page-map","title":"Page Map","text":""},{"location":"api/#api_specsmd","title":"<code>api_specs.md</code>","text":"<ul> <li><code>BBox</code>, <code>PointBuffer</code>, <code>TemporalSpec</code>, <code>SensorSpec</code>, <code>OutputSpec</code>, <code>InputPrepSpec</code></li> <li><code>Embedding</code> data structure semantics</li> </ul>"},{"location":"api/#api_embeddingmd","title":"<code>api_embedding.md</code>","text":"<ul> <li><code>get_embedding(...)</code></li> <li><code>get_embeddings_batch(...)</code></li> </ul>"},{"location":"api/#api_exportmd","title":"<code>api_export.md</code>","text":"<ul> <li><code>export_batch(...)</code></li> <li><code>export_npz(...)</code></li> <li>export performance behavior and layout options</li> </ul>"},{"location":"api/#api_inspectmd","title":"<code>api_inspect.md</code>","text":"<ul> <li><code>inspect_provider_patch(...)</code></li> <li><code>inspect_gee_patch(...)</code> (backward-compatible wrapper)</li> </ul>"},{"location":"api/#model-registry-advanced","title":"Model Registry (Advanced)","text":"<p>If you need a stable model list in code, use the model catalog:</p> <pre><code>from rs_embed.embedders.catalog import MODEL_SPECS\nprint(sorted(MODEL_SPECS.keys()))\n</code></pre> <p><code>list_models()</code> from <code>rs_embed.core.registry</code> only reports models currently loaded into the runtime registry.</p>"},{"location":"api/#errors","title":"Errors","text":"<p>rs-embed raises several explicit exception types (all in <code>rs_embed.core.errors</code>):</p> <ul> <li><code>SpecError</code>: spec validation failure (invalid bbox, missing temporal fields, etc.)</li> <li><code>ProviderError</code>: provider/backend errors (e.g., GEE initialization or fetch failure)</li> <li><code>ModelError</code>: unknown model ID, unsupported parameters, unsupported export format, etc.</li> </ul>"},{"location":"api/#optional-dependencies","title":"Optional Dependencies","text":"<p>Different features require different optional dependencies:</p> <ul> <li><code>pip install \"rs-embed[gee]\"</code>: use the Earth Engine backend</li> <li><code>pip install \"rs-embed[torch]\"</code>: torch model inference</li> <li><code>pip install \"rs-embed[models]\"</code>: dependencies for some model wrappers (e.g., rshf)</li> <li><code>pip install \"rs-embed[dev]\"</code>: dev dependencies such as pytest</li> </ul>"},{"location":"api/#versioning-notes","title":"Versioning Notes","text":"<p>The current version is still early stage (<code>0.1.x</code>):</p> <ul> <li><code>BBox/PointBuffer</code> currently require <code>crs=\"EPSG:4326\"</code></li> <li>Precomputed models mainly use <code>backend=\"local\"</code>; on-the-fly models mainly use provider backends (typically <code>\"gee\"</code>)</li> <li><code>export_batch(format=...)</code> currently supports <code>\"npz\"</code> and <code>\"netcdf\"</code>; it may be extended to parquet/zarr/hdf5, etc.</li> </ul>"},{"location":"api_embedding/","title":"API: Embedding","text":"<p>This page covers single-ROI and batch embedding APIs.</p> <p>Related pages:</p> <ul> <li>API: Specs and Data Structures</li> <li>API: Export</li> <li>API: Inspect</li> </ul>"},{"location":"api_embedding/#embedding-data-structure","title":"Embedding Data Structure","text":"<p><code>get_embedding</code> / <code>get_embeddings_batch</code> return an <code>Embedding</code>:</p> <pre><code>from rs_embed.core.embedding import Embedding\n\nEmbedding(\n    data: np.ndarray | xarray.DataArray,\n    meta: Dict[str, Any],\n)\n</code></pre> <ul> <li><code>data</code>: the embedding data (float32, vector or grid)</li> <li><code>meta</code>: includes model info, input info (optional), and export/check reports, etc.</li> </ul>"},{"location":"api_embedding/#embedding-functions","title":"Embedding Functions","text":""},{"location":"api_embedding/#get_embedding","title":"get_embedding","text":"<pre><code>get_embedding(\n    model: str,\n    *,\n    spatial: SpatialSpec,\n    temporal: Optional[TemporalSpec] = None,\n    sensor: Optional[SensorSpec] = None,\n    output: OutputSpec = OutputSpec.pooled(),\n    backend: str = \"gee\",\n    device: str = \"auto\",\n    input_prep: InputPrepSpec | str = \"resize\",\n) -&gt; Embedding\n</code></pre> <p>Computes the embedding for a single ROI.</p> <p>Parameters</p> <ul> <li><code>model</code>: model ID (see the Supported Models page, or use <code>rs_embed.core.registry.list_models()</code>)</li> <li><code>spatial</code>: <code>BBox</code> or <code>PointBuffer</code></li> <li><code>temporal</code>: <code>TemporalSpec</code> or <code>None</code></li> <li><code>sensor</code>: input descriptor for on-the-fly models; for most precomputed models this can be <code>None</code></li> <li><code>output</code>: <code>OutputSpec.pooled()</code> or <code>OutputSpec.grid(...)</code></li> <li><code>backend</code>: currently mainly <code>\"gee\"</code> (Google Earth Engine)</li> <li><code>device</code>: <code>\"auto\" / \"cpu\" / \"cuda\"</code> (if the model depends on torch)</li> <li><code>input_prep</code>: <code>\"resize\"</code> (default), <code>\"tile\"</code>, <code>\"auto\"</code>, or <code>InputPrepSpec(...)</code></li> </ul> <p>Returns</p> <ul> <li><code>Embedding</code></li> </ul> <p>Example</p> <pre><code>from rs_embed import PointBuffer, TemporalSpec, OutputSpec, get_embedding\n\nemb = get_embedding(\n    \"remoteclip_s2rgb\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(pooling=\"mean\"),\n    backend=\"gee\",\n    device=\"auto\",\n    input_prep=\"resize\",  # default\n)\nvec = emb.data  # (D,)\n</code></pre> <p>Performance tip</p> <p><code>get_embedding</code> tries to reuse a cached embedder instance internally to avoid repeatedly initializing the provider / loading model weights (especially for torch models).</p>"},{"location":"api_embedding/#get_embeddings_batch","title":"get_embeddings_batch","text":"<pre><code>get_embeddings_batch(\n    model: str,\n    *,\n    spatials: List[SpatialSpec],\n    temporal: Optional[TemporalSpec] = None,\n    sensor: Optional[SensorSpec] = None,\n    output: OutputSpec = OutputSpec.pooled(),\n    backend: str = \"gee\",\n    device: str = \"auto\",\n    input_prep: InputPrepSpec | str = \"resize\",\n) -&gt; List[Embedding]\n</code></pre> <p>Batch-computes embeddings for multiple ROIs using the same embedder instance (often more efficient than looping over <code>get_embedding</code>).</p> <p>Parameters</p> <ul> <li><code>spatials</code>: a non-empty <code>List[SpatialSpec]</code></li> <li>Others are the same as <code>get_embedding</code></li> </ul> <p>Returns</p> <ul> <li><code>List[Embedding]</code> (same length as <code>spatials</code>)</li> </ul> <p>Example</p> <pre><code>from rs_embed import PointBuffer, TemporalSpec, get_embeddings_batch\n\nspatials = [\n    PointBuffer(121.5, 31.2, 2048),\n    PointBuffer(120.5, 30.2, 2048),\n]\nembs = get_embeddings_batch(\n    \"remoteclip_s2rgb\",\n    spatials=spatials,\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n)\n</code></pre>"},{"location":"api_export/","title":"API: Export","text":"<p>This page documents dataset export APIs and export-specific runtime behavior.</p> <p>Related pages:</p> <ul> <li>API: Specs and Data Structures</li> <li>API: Embedding</li> <li>API: Inspect</li> </ul>"},{"location":"api_export/#export_batch-core","title":"export_batch (core)","text":"<pre><code>export_batch(\n    *,\n    spatials: List[SpatialSpec],\n    temporal: Optional[TemporalSpec],\n    models: List[str],\n    out: Optional[str] = None,\n    layout: Optional[str] = None,\n    out_dir: Optional[str] = None,\n    out_path: Optional[str] = None,\n    names: Optional[List[str]] = None,\n    backend: str = \"gee\",\n    device: str = \"auto\",\n    output: OutputSpec = OutputSpec.pooled(),\n    sensor: Optional[SensorSpec] = None,\n    per_model_sensors: Optional[Dict[str, SensorSpec]] = None,\n    format: str = \"npz\",\n    save_inputs: bool = True,\n    save_embeddings: bool = True,\n    save_manifest: bool = True,\n    fail_on_bad_input: bool = False,\n    chunk_size: int = 16,\n    num_workers: int = 8,\n    continue_on_error: bool = False,\n    max_retries: int = 0,\n    retry_backoff_s: float = 0.0,\n    async_write: bool = True,\n    writer_workers: int = 2,\n    resume: bool = False,\n    show_progress: bool = True,\n    input_prep: InputPrepSpec | str = \"resize\",\n) -&gt; Any\n</code></pre> <p>Recommended batch export entry point: export <code>inputs + embeddings + manifest</code> for multiple ROIs \u00d7 multiple models in one go.</p> <ul> <li><code>out_dir</code> mode: one file per point (recommended for massive numbers of points)</li> <li><code>out_path</code> mode: merge into a single output file (good for fewer points and portability)</li> <li>Decoupled output target API: <code>out + layout</code> (maps to the same two modes)</li> </ul> <p>Parameters</p> <ul> <li><code>spatials</code>: non-empty list</li> <li><code>temporal</code>: can be <code>None</code> (some models don\u2019t require time)</li> <li><code>models</code>: non-empty list of model IDs</li> <li>Output target:</li> <li>legacy API: choose one of <code>out_dir</code> / <code>out_path</code></li> <li>decoupled API: provide both <code>out</code> and <code>layout</code> (<code>\"per_item\"</code> or <code>\"combined\"</code>)</li> <li>do not mix <code>out+layout</code> with <code>out_dir/out_path</code></li> <li><code>names</code>: used only in <code>out_dir</code> mode, for output filenames (length must equal <code>spatials</code>)</li> <li><code>sensor</code>: a shared <code>SensorSpec</code> for all models (if models are on-the-fly)</li> <li><code>per_model_sensors</code>: override <code>SensorSpec</code> per model; keys are model strings</li> <li><code>format</code>: <code>\"npz\"</code> or <code>\"netcdf\"</code></li> <li><code>save_inputs</code>: whether to save model input patches (CHW numpy)</li> <li><code>save_embeddings</code>: whether to save embedding arrays</li> <li><code>save_manifest</code>: whether to save JSON manifests (each export artifact will have an accompanying <code>.json</code>)</li> <li><code>fail_on_bad_input</code>: whether to raise immediately if input checks fail</li> <li><code>chunk_size</code>: process points in chunks (controls memory/throughput)</li> <li>also used as the default inference batch size when batched inference is enabled</li> <li>in <code>per_item</code> mode with GEE prefetch enabled, rs-embed uses a one-slot prefetch pipeline (double buffering), so input-cache peak memory can be roughly up to 2 chunks (to overlap <code>prefetch(chunk k+1)</code> with <code>infer/write(chunk k)</code>)</li> <li><code>num_workers</code>: concurrency for GEE patch prefetching (ThreadPool)</li> <li><code>continue_on_error</code>: keep exporting remaining points/models even if one item fails</li> <li><code>max_retries</code>: retry count for provider fetch/write operations</li> <li><code>retry_backoff_s</code>: sleep seconds between retries</li> <li><code>async_write</code>: write output files asynchronously in <code>out_dir</code> mode</li> <li><code>writer_workers</code>: writer thread count when <code>async_write=True</code></li> <li><code>resume</code>: skip already-exported outputs and continue from remaining items</li> <li><code>show_progress</code>: show progress during batch export (overall progress + per-model inference progress)</li> <li><code>input_prep</code>: large-ROI input policy (<code>\"resize\"</code> default, <code>\"tile\"</code>, <code>\"auto\"</code>, or <code>InputPrepSpec(...)</code>)</li> </ul> <p>Automatic inference behavior</p> <ul> <li>In per-item output mode (<code>out_dir</code> / <code>layout=\"per_item\"</code>):</li> <li><code>device=\"cpu\"</code> (or auto-resolved CPU): defaults to per-item inference</li> <li><code>device=\"cuda\"</code> / <code>mps</code> / other accelerators (or auto-resolved GPU): prefers batched inference when the embedder implements batch APIs</li> <li>In combined output mode (<code>out_path</code> / <code>layout=\"combined\"</code>), rs-embed keeps the historical behavior of attempting batched model APIs (with fallback to single-item inference if batched execution fails)</li> <li>Model-level scheduling remains serial (one model at a time)</li> </ul> <p>Returns</p> <ul> <li><code>out_dir</code> mode: <code>List[dict]</code> (manifest for each point)</li> <li><code>out_path</code> mode: <code>dict</code> (combined manifest)</li> </ul> <p>Example: out_dir (recommended)</p> <pre><code>from rs_embed import export_batch, PointBuffer, TemporalSpec\n\nspatials = [\n    PointBuffer(121.5, 31.2, 2048),\n    PointBuffer(120.5, 30.2, 2048),\n]\nexport_batch(\n    spatials=spatials,\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    models=[\"remoteclip_s2rgb\", \"prithvi_eo_v2_s2_6b\"],\n    out_dir=\"exports\",\n    names=[\"p1\", \"p2\"],\n    input_prep=\"tile\",  # optional: API-side tiled inference for large ROIs\n    save_inputs=True,\n    save_embeddings=True,\n    chunk_size=32,\n    num_workers=8,\n)\n</code></pre> <p>Example: out_path (single merged file)</p> <pre><code>from rs_embed import export_batch, PointBuffer, TemporalSpec\n\nexport_batch(\n    spatials=[PointBuffer(121.5, 31.2, 2048)],\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    models=[\"remoteclip_s2rgb\"],\n    out_path=\"combined.npz\",\n)\n</code></pre> <p>Example: decoupled output target (<code>out + layout</code>)</p> <pre><code>from rs_embed import export_batch, PointBuffer, TemporalSpec\n\nexport_batch(\n    spatials=[PointBuffer(121.5, 31.2, 2048)],\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    models=[\"remoteclip_s2rgb\"],\n    out=\"exports/combined_run\",\n    layout=\"combined\",  # writes exports/combined_run.npz\n)\n</code></pre> <p>Key performance feature: avoid duplicate downloads</p> <p>When <code>backend=\"gee\"</code> and <code>save_inputs=True</code> and <code>save_embeddings=True</code>, <code>export_batch</code> prefetches the raw patch once, and passes that same patch into the embedder via <code>input_chw</code> to compute embeddings\u2014avoiding the pattern of \u201cdownload once to save inputs + download again for embeddings\u201d.</p> <p>About parallelism</p> <p><code>export_batch</code> currently has two levels of execution behavior: - IO level: GEE prefetching is parallelized (ThreadPool, controlled by <code>num_workers</code>).   - In per-item mode, rs-embed uses a one-slot double buffer: while chunk <code>k</code> is running inference / writing outputs, chunk <code>k+1</code> can be prefetched in the background (after the first chunk).   - This improves throughput when fetch and inference times are comparable, at the cost of a higher input-cache peak (roughly up to 2 chunks).   - In combined mode, prefetch still runs as a distinct stage before model execution (to keep checkpoint/resume semantics simpler and memory behavior predictable). - Inference level:   - model level: models are executed serially (one model at a time), to keep runtime/GPU behavior stable.   - batch level: for a single model, rs-embed can run batched inference when the embedder implements batch APIs (for example <code>get_embeddings_batch</code> / <code>get_embeddings_batch_from_inputs</code>). This is used in combined mode and, on GPU/accelerators, also in per-item mode. In short: rs-embed supports batch-level inference acceleration, while keeping model-level scheduling serial by design.</p>"},{"location":"api_export/#export_npz-single-roi-convenience-wrapper","title":"export_npz (single-ROI convenience wrapper)","text":"<pre><code>export_npz(\n    *,\n    spatial: SpatialSpec,\n    temporal: Optional[TemporalSpec],\n    models: List[str],\n    out_path: str,\n    backend: str = \"gee\",\n    device: str = \"auto\",\n    output: OutputSpec = OutputSpec.pooled(),\n    sensor: Optional[SensorSpec] = None,\n    per_model_sensors: Optional[Dict[str, SensorSpec]] = None,\n    save_inputs: bool = True,\n    save_embeddings: bool = True,\n    save_manifest: bool = True,\n    fail_on_bad_input: bool = False,\n    continue_on_error: bool = False,\n    max_retries: int = 0,\n    retry_backoff_s: float = 0.0,\n    input_prep: InputPrepSpec | str = \"resize\",\n) -&gt; Dict[str, Any]\n</code></pre> <p>Convenience wrapper around <code>export_batch(...)</code> for a single <code>spatial</code> query that always writes a single <code>.npz</code> file.</p> <ul> <li>Creates parent directory if needed</li> <li>Appends <code>.npz</code> suffix if missing</li> <li>Delegates to <code>export_batch(..., out_path=..., format=\"npz\")</code></li> </ul> <p>Use <code>export_batch(...)</code> directly when you need:</p> <ul> <li>multiple spatials</li> <li>non-<code>npz</code> formats (for example <code>netcdf</code>)</li> <li>output layout control (<code>out + layout</code> / <code>out_dir</code> / <code>out_path</code>)</li> </ul>"},{"location":"api_inspect/","title":"API: Inspect","text":"<p>This page documents raw input inspection utilities (patch checks) used before model inference.</p> <p>Related pages:</p> <ul> <li>API: Specs and Data Structures</li> <li>API: Embedding</li> <li>API: Export</li> </ul>"},{"location":"api_inspect/#inspect_provider_patch-recommended","title":"inspect_provider_patch (recommended)","text":"<pre><code>inspect_provider_patch(\n    *,\n    spatial: SpatialSpec,\n    temporal: Optional[TemporalSpec] = None,\n    sensor: SensorSpec,\n    backend: str = \"gee\",\n    name: str = \"gee_patch\",\n    value_range: Optional[Tuple[float, float]] = None,\n    return_array: bool = False,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Provider-agnostic patch inspection utility (recommended entry point). Use this when you want the same inspection flow but with a non-GEE provider backend.</p>"},{"location":"api_inspect/#inspect_gee_patch","title":"inspect_gee_patch","text":"<pre><code>inspect_gee_patch(\n    *,\n    spatial: SpatialSpec,\n    temporal: Optional[TemporalSpec] = None,\n    sensor: SensorSpec,\n    backend: str = \"gee\",\n    name: str = \"gee_patch\",\n    value_range: Optional[Tuple[float, float]] = None,\n    return_array: bool = False,\n) -&gt; Dict[str, Any]\n</code></pre> <p>Backwards-compatible GEE-focused wrapper around <code>inspect_provider_patch(...)</code>. It performs the same input quality checks (without running the model).</p> <p>Returns</p> <ul> <li>A JSON-serializable dict:</li> <li><code>ok</code>: bool</li> <li><code>report</code>: stats/check report</li> <li><code>sensor</code>, <code>temporal</code>, <code>backend</code></li> <li><code>artifacts</code>: optional quicklook save paths</li> <li>If <code>return_array=True</code>, includes <code>array_chw</code> (numpy array, not JSON-serializable)</li> </ul> <p>Example</p> <pre><code>from rs_embed import inspect_gee_patch, PointBuffer, TemporalSpec, SensorSpec\n\nrep = inspect_gee_patch(\n    spatial=PointBuffer(121.5, 31.2, 2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    sensor=SensorSpec(\n        collection=\"COPERNICUS/S2_SR_HARMONIZED\",\n        bands=(\"B4\", \"B3\", \"B2\"),\n        scale_m=10,\n        cloudy_pct=30,\n        composite=\"median\",\n        check_input=True,\n        check_save_dir=\"artifacts\",\n    ),\n    return_array=False,\n)\n</code></pre>"},{"location":"api_specs/","title":"API: Specs and Data Structures","text":"<p>This page documents the core spec/data types used across the public API.</p> <p>For task-oriented usage, see Common Workflows. For exact embedding/export/inspect functions, see:</p> <ul> <li>API: Embedding</li> <li>API: Export</li> <li>API: Inspect</li> </ul>"},{"location":"api_specs/#data-structures","title":"Data Structures","text":""},{"location":"api_specs/#spatialspec","title":"SpatialSpec","text":"<p><code>SpatialSpec</code> describes the spatial region for which you want to extract an embedding.</p>"},{"location":"api_specs/#bbox","title":"<code>BBox</code>","text":"<pre><code>BBox(minlon: float, minlat: float, maxlon: float, maxlat: float, crs: str = \"EPSG:4326\")\n</code></pre> <ul> <li>An EPSG:4326 lat/lon bounding box (the current version supports only EPSG:4326).</li> <li><code>validate()</code> checks that bounds are valid.</li> </ul>"},{"location":"api_specs/#pointbuffer","title":"<code>PointBuffer</code>","text":"<pre><code>PointBuffer(lon: float, lat: float, buffer_m: float, crs: str = \"EPSG:4326\")\n</code></pre> <ul> <li>A buffer centered at a point, measured in meters (a square ROI; internally projected into the coordinate system required by the provider).</li> <li>Requires <code>buffer_m &gt; 0</code>.</li> </ul>"},{"location":"api_specs/#temporalspec","title":"TemporalSpec","text":"<p><code>TemporalSpec</code> describes the time range (by year or by date range).</p> <pre><code>TemporalSpec(mode: Literal[\"year\", \"range\"], year: int | None, start: str | None, end: str | None)\n</code></pre> <p>Recommended constructors:</p> <pre><code>TemporalSpec.year(2022)\nTemporalSpec.range(\"2022-06-01\", \"2022-09-01\")\n</code></pre> <p>Temporal semantics in provider/on-the-fly paths:</p> <ul> <li><code>TemporalSpec.range(start, end)</code> is interpreted as a half-open window <code>[start, end)</code>, where <code>end</code> is excluded.</li> <li>In GEE-backed on-the-fly fetch, <code>range</code> is used to filter an image collection over the full window, then apply a compositing reducer (default <code>median</code>, optional <code>mosaic</code>).</li> <li>So the fetched input is usually a composite over the whole time window, not an automatically selected single-day scene.</li> <li>To approximate a single-day query, pass a one-day window such as <code>TemporalSpec.range(\"2022-06-01\", \"2022-06-02\")</code>.</li> </ul> <p>About <code>input_time</code> in metadata:</p> <ul> <li>Many embedders store <code>meta[\"input_time\"]</code> as the midpoint date of the temporal window.</li> <li>This midpoint is metadata (and for some models, an auxiliary time signal), not evidence that imagery was fetched from exactly that single date.</li> </ul>"},{"location":"api_specs/#sensorspec","title":"SensorSpec","text":"<p><code>SensorSpec</code> is mainly for on-the-fly models (fetch a patch from GEE online and feed it into the model). It specifies which collection to pull from, which bands, and what resolution/compositing strategy to use.</p> <pre><code>SensorSpec(\n    collection: str,\n    bands: Tuple[str, ...],\n    scale_m: int = 10,\n    cloudy_pct: int = 30,\n    fill_value: float = 0.0,\n    composite: Literal[\"median\", \"mosaic\"] = \"median\",\n    check_input: bool = False,\n    check_raise: bool = True,\n    check_save_dir: Optional[str] = None,\n)\n</code></pre> <ul> <li><code>collection</code>: GEE collection or image ID</li> <li><code>bands</code>: band names (tuple)</li> <li><code>scale_m</code>: sampling resolution (meters)</li> <li><code>cloudy_pct</code>: cloud filter (best-effort; depends on collection properties)</li> <li><code>fill_value</code>: no-data fill value</li> <li><code>composite</code>: image compositing method over the temporal window (median/mosaic)</li> <li><code>check_*</code>: optional input checks and quicklook saving (see <code>inspect_gee_patch</code>)</li> </ul> <p>Note</p> <p>For precomputed models (e.g., directly reading offline embedding products), <code>sensor</code> is usually ignored or set to <code>None</code>.</p>"},{"location":"api_specs/#outputspec","title":"OutputSpec","text":"<p><code>OutputSpec</code> controls the embedding output shape: a pooled vector or a dense grid.</p> <pre><code>OutputSpec(\n    mode: Literal[\"grid\", \"pooled\"],\n    scale_m: int = 10,\n    pooling: Literal[\"mean\", \"max\"] = \"mean\",\n    grid_orientation: Literal[\"north_up\", \"native\"] = \"north_up\",\n)\n</code></pre> <p>Recommended constructors:</p> <pre><code>OutputSpec.pooled(pooling=\"mean\")   # shape: (D,)\nOutputSpec.grid(scale_m=10)         # shape: (D, H, W), normalized to north-up when possible\nOutputSpec.grid(scale_m=10, grid_orientation=\"native\")  # keep model/provider native orientation\n</code></pre>"},{"location":"api_specs/#pooled","title":"<code>pooled</code>","text":"<p>ROI-level Vector Embedding</p> <p>Semantic meaning</p> <p><code>pooled</code> represents one whole ROI (Region of Interest) using a single vector <code>(D,)</code>.</p> <p>Best suited for:</p> <ul> <li>Classification / regression</li> <li>Retrieval / similarity search</li> <li>Clustering</li> <li>Cross-model comparison (recommended)</li> </ul> <p>Unified output format:</p> <pre><code>Embedding.data.shape == (D,)\n</code></pre> <p>How it is produced:</p> <p>ViT / MAE-style models (e.g., RemoteCLIP / Prithvi / SatMAE / ScaleMAE):</p> <ul> <li>Native output is patch tokens <code>(N, D)</code> (with optional CLS token)</li> <li>Remove CLS token if present, then pool tokens across the token axis (<code>mean</code> by default, optional <code>max</code>)</li> </ul> <p>Mean-pooling formula:</p> \\[ v_d = \\frac{1}{N'} \\sum_{i=1}^{N'} t_{i,d} \\] <p>Precomputed embeddings (e.g., Tessera / GSE / Copernicus):</p> <ul> <li>Native output is an embedding grid <code>(D, H, W)</code></li> <li>Pool over spatial dimensions <code>(H, W)</code></li> </ul> \\[ v_d = \\frac{1}{HW} \\sum_{y,x} g_{d,y,x} \\] <p>Why prefer <code>pooled</code> for benchmarks:</p> <ul> <li>Model-agnostic and stable</li> <li>Less sensitive to spatial/token layout differences</li> <li>Easiest output to compare across models</li> </ul>"},{"location":"api_specs/#grid","title":"<code>grid</code>","text":"<p>ROI-level Spatial Embedding Field</p> <p>Semantic meaning</p> <p><code>grid</code> returns a spatial embedding field <code>(D, H, W)</code>, where each spatial location maps to a vector.</p> <p>Best suited for:</p> <ul> <li>Spatial visualization (PCA / norm / similarity maps)</li> <li>Pixel-wise / patch-wise tasks</li> <li>Intra-ROI structure analysis</li> </ul> <p>Unified output format:</p> <pre><code>Embedding.data.shape == (D, H, W)\n</code></pre> <p>Notes:</p> <ul> <li><code>data</code> can be returned as <code>xarray.DataArray</code> with metadata in <code>meta</code>/<code>attrs</code></li> <li>For precomputed geospatial products, metadata may include CRS/crop context</li> <li>For ViT token grids, this is usually patch-grid metadata (not georeferenced pixel coordinates)</li> </ul> <p>How it is produced:</p> <p>ViT / MAE-style models:</p> <ul> <li>Native output: tokens <code>(N, D)</code></li> <li>Remove CLS token if present, reshape remaining tokens:</li> <li><code>(N', D) -&gt; (H, W, D) -&gt; (D, H, W)</code></li> <li><code>(H, W)</code> comes from patch layout (for example, <code>8x8</code>, <code>14x14</code>)</li> </ul> <p>Precomputed embeddings:</p> <ul> <li>Native output is already <code>(D, H, W)</code></li> </ul>"},{"location":"api_specs/#inputprepspec","title":"InputPrepSpec","text":"<p>Optional Large-ROI Input Policy</p> <p><code>InputPrepSpec</code> controls API-level handling of large on-the-fly inputs before model inference. This is mainly useful when you want to choose between the model's normal resize path and API-side tiled inference.</p> <pre><code>InputPrepSpec(\n    mode: Literal[\"resize\", \"tile\", \"auto\"] = \"resize\",\n    tile_size: Optional[int] = None,\n    tile_stride: Optional[int] = None,\n    max_tiles: int = 9,\n    pad_edges: bool = True,\n)\n</code></pre> <p>Recommended constructors:</p> <pre><code>InputPrepSpec.resize()               # default behavior (fastest)\nInputPrepSpec.tile()                 # tile size inferred from model defaults.image_size when available\nInputPrepSpec.auto(max_tiles=4)      # choose tile or resize automatically\nInputPrepSpec.tile(tile_size=224)    # explicit tile size override\n</code></pre> <p>You can also pass a string to public APIs as a shorthand:</p> <pre><code>input_prep=\"resize\"   # default\ninput_prep=\"tile\"\ninput_prep=\"auto\"\n</code></pre> <p>Current tiled design (API layer):</p> <ul> <li>Tile size defaults to <code>embedder.describe()[\"defaults\"][\"image_size\"]</code> when available (can be overridden).</li> <li>Boundary tiles use a cover-shift layout (for example <code>300 -&gt; [0,224]</code> and <code>[76,300]</code>) to avoid edge padding when possible.</li> <li>Grid stitching uses midpoint-cut ownership in overlap regions (instead of hard overwrite).</li> <li><code>tile_stride</code> currently must equal <code>tile_size</code> (explicit overlap/gap configuration is not enabled yet), but boundary shifting can still create overlap on the last tile.</li> <li><code>auto</code> is conservative and currently prefers tiling mainly for <code>OutputSpec.grid()</code> when tile count is small enough (<code>max_tiles</code>).</li> </ul> <p></p>"},{"location":"api_specs/#embedding","title":"Embedding","text":"<p><code>get_embedding</code> / <code>get_embeddings_batch</code> return an <code>Embedding</code>:</p> <pre><code>from rs_embed.core.embedding import Embedding\n\nEmbedding(\n    data: np.ndarray | xarray.DataArray,\n    meta: Dict[str, Any],\n)\n</code></pre> <ul> <li><code>data</code>: the embedding data (float32, vector or grid)</li> <li><code>meta</code>: includes model info, input info (optional), and export/check reports, etc.</li> </ul>"},{"location":"concepts/","title":"Core Concepts","text":"<p>This page explains the core mental model of <code>rs-embed</code> before you dive into the full API reference.</p> <p>If you are new to the project, read this page first, then go to Quick Start.</p>"},{"location":"concepts/#the-core-abstraction","title":"The Core Abstraction","text":"<p><code>rs-embed</code> exposes a unified interface:</p> <p><code>(model, spatial, temporal, sensor, output) -&gt; Embedding</code></p> <p>In practice, most users work with:</p> <ul> <li><code>spatial</code>: where (ROI)</li> <li><code>temporal</code>: when (year or time window)</li> <li><code>output</code>: what shape you want (<code>pooled</code> or <code>grid</code>)</li> <li><code>backend</code>: where data comes from (usually <code>gee</code> for on-the-fly models)</li> </ul>"},{"location":"concepts/#spatial-specs-what-area-you-want","title":"Spatial Specs: What Area You Want","text":"<p>Two common ways to define a region:</p> <ul> <li><code>PointBuffer(lon, lat, buffer_m)</code>: square ROI centered at a point</li> <li><code>BBox(minlon, minlat, maxlon, maxlat)</code>: explicit lat/lon bounds</li> </ul> <p>Current limitation:</p> <ul> <li>API currently accepts only <code>crs=\"EPSG:4326\"</code> for <code>BBox</code> / <code>PointBuffer</code></li> </ul> <p>See: API Reference and Limitations.</p>"},{"location":"concepts/#temporal-specs-window-not-necessarily-a-single-scene","title":"Temporal Specs: Window, Not Necessarily a Single Scene","text":"<p>This is the most important concept for readability and correct usage.</p>"},{"location":"concepts/#temporalspecyear","title":"<code>TemporalSpec.year(...)</code>","text":"<p>Used mainly for annual precomputed products (for example <code>gse_annual</code>).</p>"},{"location":"concepts/#temporalspecrangestart-end","title":"<code>TemporalSpec.range(start, end)</code>","text":"<p>For most on-the-fly GEE-backed models, this means:</p> <ol> <li>Filter imagery within the half-open window <code>[start, end)</code></li> <li>Composite the images (default <code>median</code>, optional <code>mosaic</code>)</li> <li>Feed the composite patch into the model</li> </ol> <p>It usually does not mean \"pick a single image acquired exactly on this date.\"</p> <p>Tip</p> <p>If you want a near single-day query, use a one-day window such as <code>TemporalSpec.range(\"2022-06-01\", \"2022-06-02\")</code>.</p> <p>See detailed model-specific temporal behavior in Supported Models.</p>"},{"location":"concepts/#output-specs-pooled-vs-grid","title":"Output Specs: <code>pooled</code> vs <code>grid</code>","text":""},{"location":"concepts/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<p>Returns one vector <code>(D,)</code> for the whole ROI.</p> <p>Use this for:</p> <ul> <li>classification / regression</li> <li>similarity search / retrieval</li> <li>clustering</li> <li>cross-model benchmarking (recommended default)</li> </ul>"},{"location":"concepts/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<p>Returns a spatial feature grid <code>(D, H, W)</code>.</p> <p>Use this for:</p> <ul> <li>visualization (PCA / norm maps)</li> <li>patch-wise analysis</li> <li>spatial structure inspection</li> </ul> <p>Note</p> <p>For ViT-like models, <code>grid</code> is often a token/patch grid, not guaranteed georeferenced raster pixels.</p>"},{"location":"concepts/#backends-and-providers","title":"Backends and Providers","text":"<p>Think of backend as the input retrieval/runtime path.</p> <ul> <li><code>backend=\"gee\"</code>: fetch imagery from Google Earth Engine (common for on-the-fly models)</li> <li><code>backend=\"local\"</code>: local/offline access for precomputed products (common for precomputed models)</li> </ul> <p>You usually do not need to customize providers directly unless you are debugging inputs or extending the library.</p>"},{"location":"concepts/#sensor-only-needed-for-some-paths","title":"<code>sensor</code>: Only Needed for Some Paths","text":"<p>For on-the-fly models, <code>SensorSpec(...)</code> describes:</p> <ul> <li>collection</li> <li>bands</li> <li>scale (meters)</li> <li>cloud filtering</li> <li>composite mode (<code>median</code> / <code>mosaic</code>)</li> </ul> <p>For most precomputed models, <code>sensor</code> is often <code>None</code> or ignored.</p>"},{"location":"concepts/#input-prep-resize-tile-auto","title":"Input Prep (<code>resize</code> / <code>tile</code> / <code>auto</code>)","text":"<p><code>input_prep</code> is an API-level policy for large on-the-fly inputs:</p> <ul> <li><code>\"resize\"</code>: fast default</li> <li><code>\"tile\"</code>: API-side tiled inference for large ROIs</li> <li><code>\"auto\"</code>: conservative automatic choice (mainly useful for some <code>grid</code> outputs)</li> </ul> <p>Use tiling when:</p> <ul> <li>you care about preserving more spatial detail for large ROIs</li> <li>model default resize would be too destructive</li> </ul> <p>See the tiled behavior details in API Reference.</p>"},{"location":"concepts/#precomputed-vs-on-the-fly-models","title":"Precomputed vs On-the-fly Models","text":""},{"location":"concepts/#precomputed","title":"Precomputed","text":"<ul> <li>Reads embeddings from existing embedding products</li> <li>Faster and simpler runtime</li> <li>Temporal coverage and resolution are fixed by the product</li> </ul> <p>Examples:</p> <ul> <li><code>tessera</code></li> <li><code>gse_annual</code></li> <li><code>copernicus_embed</code></li> </ul>"},{"location":"concepts/#on-the-fly","title":"On-the-fly","text":"<ul> <li>Fetches imagery patch, preprocesses, then runs model inference</li> <li>More flexible but heavier dependencies/runtime</li> <li>Requires careful attention to bands, temporal windows, and normalization</li> </ul> <p>Examples:</p> <ul> <li><code>remoteclip_s2rgb</code></li> <li><code>prithvi_eo_v2_s2_6b</code></li> <li><code>anysat</code></li> <li><code>terramind</code></li> </ul>"},{"location":"concepts/#reproducibility-checklist-recommended","title":"Reproducibility Checklist (Recommended)","text":"<p>When comparing models, keep these fixed first:</p> <ol> <li>Same <code>spatial</code> ROI definition</li> <li>Same <code>temporal</code> window</li> <li>Same <code>SensorSpec.composite</code> policy</li> <li>Same <code>OutputSpec</code> mode (usually <code>pooled</code>)</li> <li>Default model preprocessing unless you can exactly reproduce training pipelines</li> </ol> <p>The model-specific preprocessing knobs are summarized in Supported Models.</p>"},{"location":"concepts/#where-to-go-next","title":"Where To Go Next","text":"<ul> <li>New user: Quick Start</li> <li>Task-oriented usage: Common Workflows</li> <li>Model capabilities and preprocessing: Supported Models</li> <li>Full signatures and parameters: API Reference</li> </ul>"},{"location":"extending/","title":"Extending","text":""},{"location":"extending/#overview","title":"Overview","text":"<p>To add a new model, you typically do five things:</p> <ol> <li>Create an embedder class in <code>src/rs_embed/embedders/</code></li> <li>Decorate it with <code>@register(\"your_model_name\")</code></li> <li>Add it to <code>src/rs_embed/embedders/catalog.py</code> (<code>MODEL_SPECS</code>)</li> <li>Implement:</li> <li><code>describe()</code></li> <li><code>get_embedding(...)</code></li> <li>(Optional, recommended) Override:</li> <li><code>get_embeddings_batch(...)</code> for true batched inference (no prefetched inputs)</li> <li><code>get_embeddings_batch_from_inputs(...)</code> for true batched inference with prefetched <code>input_chw</code></li> </ol>"},{"location":"extending/#the-registry","title":"The Registry","text":"<p>Models are discovered through the registry in <code>rs_embed.core.registry</code>:</p> <ul> <li><code>@register(\"name\")</code> registers an embedder class.</li> <li><code>get_embedder_cls(\"name\")</code> resolves the class.</li> <li><code>list_models()</code> lists models that have already been loaded in the current process.</li> </ul> <p>Model loading is lazy:</p> <ul> <li><code>get_embedder_cls(\"name\")</code> looks up <code>name</code> in <code>MODEL_SPECS</code>.</li> <li>Then it imports the mapped module and reads the mapped class.</li> <li>The class is inserted into the runtime registry.</li> </ul> <p>Tip</p> <p>Put your embedder in <code>rs_embed/embedders/</code> and add it to <code>src/rs_embed/embedders/catalog.py</code>. If it's not in <code>MODEL_SPECS</code>, string-based lookup (<code>get_embedding(\"...\")</code>) will not find it.</p>"},{"location":"extending/#embedder-contract","title":"Embedder Contract","text":"<p>All models implement <code>EmbedderBase</code>:</p> <pre><code>from rs_embed.embedders.base import EmbedderBase\n\nclass EmbedderBase:\n    def describe(self) -&gt; dict: ...\n    def get_embedding(\n        self,\n        *,\n        spatial,\n        temporal,\n        sensor,\n        output,\n        backend,\n        device=\"auto\",\n        input_chw=None,\n    ): ...\n    def get_embeddings_batch(...): ...\n    def get_embeddings_batch_from_inputs(...): ...\n</code></pre>"},{"location":"extending/#describe","title":"<code>describe()</code>","text":"<p><code>describe()</code> should return a JSON-serializable dictionary describing capabilities and requirements. A typical structure is:</p> <pre><code>{\n  \"type\": \"on_the_fly\" | \"precomputed\",\n  \"backend\": [\"provider\" | \"gee\" | \"local\" | \"auto\" | \"tensor\", ...],\n  \"inputs\": {\n    \"sensor_required\": true/false,\n    \"default_sensor\": {...} | null,\n    \"notes\": \"...\"\n  },\n  \"temporal\": {\"mode\": \"year\" | \"range\"} | null,\n  \"output\": [\"pooled\", \"grid\"]\n}\n</code></pre> <p>Note</p> <p><code>describe()</code> should be fast and should not trigger heavy downloads or model loading. In current rs-embed, <code>describe()[\"backend\"]</code>, <code>describe()[\"output\"]</code>, and <code>describe()[\"temporal\"]</code> may be used for runtime validation and capability checks.</p>"},{"location":"extending/#template-minimal-model-hello-world","title":"Template: Minimal Model (Hello World)","text":"<p>This is the smallest possible embedder you can add. It returns a deterministic random vector.</p> <p>Create <code>src/rs_embed/embedders/toy_model.py</code>:</p> <pre><code>from __future__ import annotations\n\nimport hashlib\nfrom dataclasses import asdict\nfrom typing import Any, Dict, Optional\nimport numpy as np\n\nfrom rs_embed.core.registry import register\nfrom rs_embed.core.embedding import Embedding\nfrom rs_embed.core.specs import SpatialSpec, TemporalSpec, SensorSpec, OutputSpec\nfrom rs_embed.embedders.base import EmbedderBase\n\n\n@register(\"toy_model_v1\")\nclass ToyModelV1(EmbedderBase):\n    def describe(self) -&gt; Dict[str, Any]:\n        return {\n            \"type\": \"precomputed\",\n            \"backend\": [\"local\"],  # use \"provider\"/\"gee\" for on-the-fly fetchers\n            \"inputs\": {\"sensor_required\": False, \"default_sensor\": None},\n            \"output\": [\"pooled\"],\n        }\n\n    def get_embedding(\n        self,\n        *,\n        spatial: SpatialSpec,\n        temporal: Optional[TemporalSpec],\n        sensor: Optional[SensorSpec],\n        output: OutputSpec,\n        backend: str = \"local\",\n        device: str = \"auto\",\n        input_chw: Optional[np.ndarray] = None,\n    ) -&gt; Embedding:\n        # Use a stable hash so results are reproducible across processes.\n        seed_bytes = hashlib.blake2s(\n            f\"{spatial!r}|{temporal!r}|{self.model_name}\".encode(\"utf-8\"),\n            digest_size=4,\n        ).digest()\n        seed = int.from_bytes(seed_bytes, \"little\")\n        rng = np.random.default_rng(seed)\n\n        if output.mode != \"pooled\":\n            raise ValueError(\"toy_model_v1 only supports pooled output\")\n\n        vec = rng.standard_normal(512).astype(\"float32\")\n        meta = {\n            \"model\": self.model_name,\n            \"backend\": backend,\n            \"device\": device,\n            \"spatial\": asdict(spatial),\n            \"temporal\": asdict(temporal) if temporal else None,\n        }\n        return Embedding(data=vec, meta=meta)\n</code></pre> <p>Then register it in <code>src/rs_embed/embedders/catalog.py</code>:</p> <pre><code>MODEL_SPECS[\"toy_model_v1\"] = (\"toy_model\", \"ToyModelV1\")\n</code></pre>"},{"location":"extending/#on-the-fly-models-gee-patch-model-embedding","title":"On-the-fly Models (GEE patch \u2192 model \u2192 embedding)","text":"<p>Most vision models in rs-embed work like this:</p> <ol> <li>Use a provider (e.g., Earth Engine) to fetch an input patch (CHW numpy).</li> <li>Preprocess it (normalize/resample).</li> <li>Run inference.</li> <li>Return <code>Embedding(data=..., meta=...)</code>.</li> </ol>"},{"location":"extending/#recommended-pattern","title":"Recommended pattern","text":"<ul> <li>Use <code>SensorSpec</code> to define:</li> <li>collection</li> <li>bands</li> <li>scale_m</li> <li>composite strategy</li> <li>Use the provider to fetch inputs.</li> </ul> <p>You can follow existing implementations in: - <code>rs_embed/embedders/onthefly_*.py</code></p> <p>Tip</p> <p>Keep network IO (fetching patches) separate from model inference whenever possible. This makes batching and caching much easier.</p>"},{"location":"extending/#supporting-export_batch-input-reuse-input_chw","title":"Supporting <code>export_batch</code> Input Reuse (<code>input_chw</code>)","text":"<p><code>export_batch</code> can prefetch the input patch once and reuse it for both:</p> <ul> <li>saving <code>inputs</code></li> <li>computing <code>embeddings</code></li> </ul> <p>To benefit from this optimization, your <code>get_embedding</code> should follow this rule:</p> <p>If <code>input_chw</code> is provided, do not fetch inputs again. Use <code>input_chw</code> as the model input.</p> <p>Example snippet:</p> <pre><code>if input_chw is None:\n    # fetch from backend/provider\n    input_chw = provider.fetch_array_chw(...)\n# now preprocess + infer using input_chw\n</code></pre> <p>Important</p> <p>This is the key to avoiding \u201cdownload twice\u201d when <code>save_inputs=True</code> and <code>save_embeddings=True</code>.</p>"},{"location":"extending/#true-batch-inference-get_embeddings_batch-get_embeddings_batch_from_inputs","title":"True Batch Inference (<code>get_embeddings_batch</code> / <code>get_embeddings_batch_from_inputs</code>)","text":"<p><code>EmbedderBase.get_embeddings_batch</code> defaults to a Python loop calling <code>get_embedding</code>. <code>EmbedderBase.get_embeddings_batch_from_inputs</code> defaults to a Python loop calling <code>get_embedding(..., input_chw=...)</code>.</p> <p>If your model supports vectorized/batched inference (common for torch models), override one or both:</p> <pre><code>def get_embeddings_batch(\n    self,\n    *,\n    spatials,\n    temporal=None,\n    sensor=None,\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n    device=\"auto\",\n):\n    # 1) fetch/preprocess inputs for all spatials\n    # 2) stack into a batch tensor\n    # 3) run a single forward pass\n    # 4) split outputs back into Embedding objects\n</code></pre> <p>If your model supports <code>input_chw</code> reuse (recommended for on-the-fly models), also consider:</p> <pre><code>def get_embeddings_batch_from_inputs(\n    self,\n    *,\n    spatials,\n    input_chws,\n    temporal=None,\n    sensor=None,\n    output=OutputSpec.pooled(),\n    backend=\"auto\",\n    device=\"auto\",\n):\n    # 1) preprocess/stack prefetched CHW inputs\n    # 2) run a single batched forward pass\n    # 3) split outputs back into Embedding objects\n</code></pre> <p><code>export_batch(...)</code> prefers <code>get_embeddings_batch_from_inputs(...)</code> when it has prefetched provider inputs available, so overriding this method usually gives the biggest speedup for on-the-fly models.</p> <p>Best practice: - Batch inference (GPU-friendly). - Parallelize IO (provider fetch) with threads if needed. - Keep memory stable by using chunking (see <code>export_batch(chunk_size=...)</code>).</p>"},{"location":"extending/#handling-outputspec-pooled-vs-grid","title":"Handling <code>OutputSpec</code> (pooled vs grid)","text":"<p><code>OutputSpec</code> controls output shape:</p> <ul> <li><code>OutputSpec.pooled()</code> \u2192 <code>(D,)</code></li> <li><code>OutputSpec.grid(...)</code> \u2192 <code>(D, H, W)</code></li> </ul> <p>If your model does not support a mode, raise a clear error:</p> <pre><code>if output.mode == \"grid\" and not supported:\n    raise ValueError(\"model_x does not support grid output\")\n</code></pre>"},{"location":"extending/#optional-dependencies-packaging","title":"Optional Dependencies (Packaging)","text":"<p>Many embedders rely on optional packages (e.g., <code>torch</code>, <code>ee</code>). Follow this pattern:</p> <ul> <li>Import heavy dependencies inside methods or within a <code>try/except</code> at module import.</li> <li>If the dependency is missing, raise a helpful error (<code>ModelError</code>) explaining what to install.</li> </ul> <p>Example:</p> <pre><code>from rs_embed.core.errors import ModelError\n\ntry:\n    import torch\nexcept Exception as e:\n    torch = None\n    _torch_err = e\n\ndef _require_torch():\n    if torch is None:\n        raise ModelError('Torch is required. Install with: pip install \"rs-embed[torch]\"')\n</code></pre>"},{"location":"extending/#testing-your-new-model","title":"Testing Your New Model","text":""},{"location":"extending/#1-registry-test-fast","title":"1) Registry test (fast)","text":"<p>Add a test ensuring registration works:</p> <pre><code>from rs_embed.core.registry import get_embedder_cls\n\ndef test_toy_model_registered():\n    cls = get_embedder_cls(\"toy_model_v1\")\n    assert cls is not None\n</code></pre>"},{"location":"extending/#2-api-level-test-recommended","title":"2) API-level test (recommended)","text":"<pre><code>from rs_embed import PointBuffer, TemporalSpec, OutputSpec, get_embedding\n\ndef test_toy_model_get_embedding():\n    emb = get_embedding(\n        \"toy_model_v1\",\n        spatial=PointBuffer(0, 0, 1000),\n        temporal=TemporalSpec.year(2022),\n        output=OutputSpec.pooled(),\n        backend=\"local\",\n    )\n    assert emb.data.shape == (512,)\n</code></pre>"},{"location":"extending/#3-export-integration-test-optional","title":"3) Export integration test (optional)","text":"<p>If your model supports input reuse and batch export, add a small <code>export_batch</code> test using <code>monkeypatch</code> to avoid real network calls. See existing patterns in: - <code>tests/test_export_batch.py</code> - <code>tests/test_gee_provider.py</code></p> <p>Run tests:</p> <pre><code>pytest -q\n</code></pre>"},{"location":"extending/#documenting-the-model","title":"Documenting the Model","text":"<p>Update docs in one of these places:</p> <ul> <li><code>docs/models.md</code> (add model name and usage)</li> </ul>"},{"location":"extending/#checklist","title":"Checklist","text":"<p>Before opening a PR / shipping the model:</p> <ul> <li>[ ] <code>@register(\"...\")</code> added and entry added in <code>src/rs_embed/embedders/catalog.py</code></li> <li>[ ] <code>describe()</code> is fast and accurate</li> <li>[ ] <code>get_embedding()</code> supports <code>input_chw</code> reuse (if on-the-fly)</li> <li>[ ] override <code>get_embeddings_batch_from_inputs()</code> if your model can batch prefetched inputs</li> <li>[ ] clear errors for missing optional dependencies</li> <li>[ ] unit tests added (<code>pytest -q</code> passes)</li> <li>[ ] minimal usage example in docs or notebook</li> </ul>"},{"location":"limitations/","title":"Limitations","text":""},{"location":"limitations/#current-limitations-v01x","title":"Current Limitations (v0.1.x)","text":"<p>This page summarizes user-facing limitations in the current implementation.</p>"},{"location":"limitations/#1-spatial-input-crs","title":"1) Spatial input CRS","text":"<ul> <li><code>BBox</code> and <code>PointBuffer</code> currently require <code>crs=\"EPSG:4326\"</code>.</li> <li>Other CRS inputs are not accepted at the API boundary.</li> </ul>"},{"location":"limitations/#2-temporal-behavior-for-on-the-fly-models","title":"2) Temporal behavior for on-the-fly models","text":"<ul> <li>Most on-the-fly adapters treat <code>TemporalSpec.range(start, end)</code> as a window filter and build one composite image (<code>median</code> by default).</li> <li>This is not an automatic single-scene selection by acquisition date.</li> </ul>"},{"location":"limitations/#3-temporal-constraints-are-model-specific","title":"3) Temporal constraints are model-specific","text":"<ul> <li><code>gse_annual</code> currently requires <code>TemporalSpec.year(...)</code>.</li> <li><code>copernicus_embed</code> currently supports only year <code>2021</code>.</li> <li>Some precomputed models may ignore finer temporal granularity.</li> </ul>"},{"location":"limitations/#4-grid-output-is-not-always-georeferenced-raster-space","title":"4) Grid output is not always georeferenced raster space","text":"<ul> <li>For ViT-like models, <code>OutputSpec.grid()</code> is often a token/patch grid <code>(D, H, W)</code>.</li> <li>Treat it as model-internal spatial structure, not as guaranteed geo-aligned pixel coordinates.</li> </ul>"},{"location":"limitations/#5-optional-dependency-surface-is-large","title":"5) Optional dependency surface is large","text":"<ul> <li>Different models/providers require extra packages (<code>earthengine-api</code>, <code>torch</code>, <code>rshf</code>, <code>torchgeo</code>, etc.).</li> <li>Missing optional dependencies will fail at runtime for the corresponding model path.</li> </ul>"},{"location":"limitations/#6-known-edge-case-tessera-tile-boundary-mosaic","title":"6) Known edge case: tessera tile boundary mosaic","text":"<ul> <li>Near some UTM-zone boundaries, fetched tiles may have different CRS/resolution and strict mosaic can fail.</li> <li>If this occurs, try shifting ROI slightly or using a smaller ROI/window.</li> </ul>"},{"location":"model_detail_template/","title":"Model Detail Template","text":"<p>Use this page as a template when adding a new per-model documentation page (for example <code>docs/models/&lt;model_id&gt;.md</code> in the future).</p> <p>Goal: make every model page answer the same questions quickly, so users can compare models without re-reading source code.</p>"},{"location":"model_detail_template/#copy-this-template","title":"Copy This Template","text":"<ol> <li>Duplicate this page into a new model doc file</li> <li>Rename the title to the target model (for example <code>RemoteCLIP (remoteclip_s2rgb)</code>)</li> <li>Fill every section marked <code>TODO</code></li> <li>Link the page from Supported Models (Overview)</li> <li>Add or update any model-specific caveats in Supported Models (Advanced Reference) if needed</li> </ol>"},{"location":"model_detail_template/#template-body","title":"Template Body","text":""},{"location":"model_detail_template/#model-name-model_id","title":"<code>&lt;Model Name&gt;</code> (<code>&lt;model_id&gt;</code>)","text":"<p>One-sentence summary: what this model is good at and what rs-embed adapter path it uses.</p>"},{"location":"model_detail_template/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>&lt;model_id&gt;</code> Family / Backbone <code>TODO</code> Adapter type <code>precomputed</code> / <code>on-the-fly</code> Typical backend <code>local</code> / <code>gee</code> / other Primary input <code>TODO</code> Temporal mode <code>year</code> / <code>range</code> / model-specific Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none / <code>TODO</code> Training alignment (adapter path) Low / Medium / High + short note"},{"location":"model_detail_template/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"model_detail_template/#good-fit-for","title":"Good fit for","text":"<ul> <li><code>TODO</code></li> <li><code>TODO</code></li> </ul>"},{"location":"model_detail_template/#avoid-or-be-careful-when","title":"Avoid or be careful when","text":"<ul> <li><code>TODO</code></li> <li><code>TODO</code></li> </ul>"},{"location":"model_detail_template/#input-contract-what-the-adapter-expects","title":"Input Contract (What the Adapter Expects)","text":""},{"location":"model_detail_template/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li><code>SpatialSpec</code>: <code>TODO</code></li> <li><code>TemporalSpec</code>: <code>TODO</code> (for example <code>TemporalSpec.range(...)</code> only)</li> <li>Temporal semantics in rs-embed: <code>TODO</code> (single composite vs multi-frame)</li> </ul>"},{"location":"model_detail_template/#sensor-channels","title":"Sensor / channels","text":"<ul> <li>Collection (default): <code>TODO</code></li> <li>Band order (required): <code>TODO</code></li> <li>Resolution / <code>scale_m</code>: <code>TODO</code></li> <li>Fill / no-data behavior: <code>TODO</code></li> </ul>"},{"location":"model_detail_template/#extra-metadata-side-inputs","title":"Extra metadata / side inputs","text":"<ul> <li>Required side inputs beyond image tensor: <code>TODO</code></li> <li>How they are derived in rs-embed: <code>TODO</code></li> </ul>"},{"location":"model_detail_template/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<p>Document the actual adapter path, not the idealized paper pipeline.</p> <ol> <li>Raw provider tensor format: <code>TODO</code> (for example <code>CHW</code>, <code>TCHW</code>)</li> <li>Value range assumptions: <code>TODO</code></li> <li>Normalization steps: <code>TODO</code></li> <li>Resize / crop / pad policy: <code>TODO</code></li> <li>Any channel conversions or wavelength handling: <code>TODO</code></li> </ol>"},{"location":"model_detail_template/#environment-variables-that-change-behavior","title":"Environment variables that change behavior","text":"Env var Default Effect <code>TODO</code> <code>TODO</code> <code>TODO</code>"},{"location":"model_detail_template/#output-semantics","title":"Output Semantics","text":""},{"location":"model_detail_template/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Output shape: <code>TODO</code></li> <li>Pooling behavior: <code>TODO</code></li> <li>Any caveats: <code>TODO</code></li> </ul>"},{"location":"model_detail_template/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Output shape: <code>TODO</code></li> <li>Is this georeferenced raster space or token grid? <code>TODO</code></li> <li>Stitching / tiling behavior caveats (if relevant): <code>TODO</code></li> </ul>"},{"location":"model_detail_template/#examples","title":"Examples","text":""},{"location":"model_detail_template/#minimal-example","title":"Minimal example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"&lt;model_id&gt;\",\n    spatial=PointBuffer(lon=0.0, lat=0.0, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",  # TODO adjust if not gee\n)\n</code></pre>"},{"location":"model_detail_template/#example-with-model-specific-options","title":"Example with model-specific options","text":"<pre><code># TODO: show custom SensorSpec / env vars / output mode / input_prep as needed\n</code></pre>"},{"location":"model_detail_template/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li><code>TODO</code>: missing optional dependency</li> <li><code>TODO</code>: wrong band order / channel count</li> <li><code>TODO</code>: temporal mode mismatch (<code>year</code> vs <code>range</code>)</li> <li><code>TODO</code>: backend mismatch (<code>local</code> vs <code>gee</code>)</li> </ul> <p>Recommended first check:</p> <ul> <li>Use <code>inspect_provider_patch(...)</code> / <code>inspect_gee_patch(...)</code> to inspect raw inputs before blaming the model.</li> </ul>"},{"location":"model_detail_template/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>For fair comparisons, document what must be held constant across models:</p> <ul> <li>ROI definition (<code>BBox</code> / <code>PointBuffer</code>)</li> <li>temporal window and compositing policy</li> <li>output mode (<code>pooled</code> vs <code>grid</code>)</li> <li>normalization mode / env overrides</li> <li>channel order / wavelength schema</li> </ul>"},{"location":"model_detail_template/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Catalog registration: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/&lt;file&gt;.py</code></li> <li>Related helpers: <code>TODO</code></li> </ul>"},{"location":"model_detail_template/#doc-maintenance-checklist","title":"Doc Maintenance Checklist","text":"<ul> <li>[ ] Model ID matches <code>MODEL_SPECS</code></li> <li>[ ] Input channels / band order verified in adapter code</li> <li>[ ] Temporal semantics verified in adapter code</li> <li>[ ] Env vars verified in adapter code (not copied from stale docs)</li> <li>[ ] Example snippet runs or is syntactically valid</li> <li>[ ] Linked from Supported Models (Overview)</li> </ul>"},{"location":"models/","title":"Supported Models (Overview)","text":"<p>This page is the model selection entry point.</p> <p>Use it to quickly narrow down candidates, then jump to:</p> <ul> <li>Supported Models (Advanced Reference) for detailed matrices (preprocessing / temporal semantics / env vars)</li> <li>Model Detail Template to create a per-model documentation page</li> </ul>"},{"location":"models/#how-to-use-this-page","title":"How To Use This Page","text":"<p>Recommended flow:</p> <ol> <li>Pick a shortlist from the overview tables below</li> <li>Validate temporal + input assumptions in Advanced Reference</li> <li>For production/benchmark runs, confirm model-specific caveats and env vars before exporting</li> </ol>"},{"location":"models/#quick-chooser-by-goal","title":"Quick Chooser by Goal","text":"Goal Good starting models Why Fast baseline / simple pipeline <code>tessera</code>, <code>gse_annual</code>, <code>copernicus_embed</code> Precomputed embeddings, fewer runtime dependencies Simple S2 RGB on-the-fly experiments <code>remoteclip_s2rgb</code>, <code>satmae_rgb</code>, <code>scalemae_rgb</code>, <code>dynamicvis</code> Straightforward RGB input paths Time-series temporal modeling <code>agrifm</code>, <code>anysat</code>, <code>galileo</code> Native multi-frame temporal packaging Multispectral / strict spectral semantics <code>dofa</code>, <code>terramind</code>, <code>thor_1_0_base</code>, <code>satvision_toa</code> Strong channel/schema assumptions Mixed-modality experiments (S1/S2) <code>terrafm_b</code> Supports S2 or S1 path (per call)"},{"location":"models/#available-detail-pages-current","title":"Available Detail Pages (Current)","text":"<ul> <li><code>remoteclip_s2rgb</code></li> <li><code>prithvi_eo_v2_s2_6b</code></li> <li><code>anysat</code></li> <li><code>galileo</code></li> <li><code>terramind</code></li> <li><code>dofa</code></li> <li><code>satvision_toa</code></li> <li><code>thor_1_0_base</code></li> <li><code>agrifm</code></li> <li><code>satmae_rgb</code></li> <li><code>scalemae_rgb</code></li> <li><code>wildsat</code></li> <li><code>dynamicvis</code></li> <li><code>fomo</code></li> <li><code>terrafm_b</code></li> <li><code>tessera</code></li> <li><code>gse_annual</code></li> <li><code>copernicus_embed</code></li> </ul> <p>More model detail pages can be added using the Model Detail Template.</p>"},{"location":"models/#model-catalog-snapshot","title":"Model Catalog Snapshot","text":""},{"location":"models/#precomputed-embeddings","title":"Precomputed Embeddings","text":"Model ID Type Primary Input / Source Outputs Temporal mode Notes Detail <code>tessera</code> Precomputed GeoTessera embedding tiles <code>pooled</code>, <code>grid</code> yearly coverage product Fast baseline, local/offline workflows detail <code>gse_annual</code> Precomputed Google Satellite Embedding (annual) <code>pooled</code>, <code>grid</code> <code>TemporalSpec.year(...)</code> Annual product via provider path detail <code>copernicus_embed</code> Precomputed Copernicus embeddings <code>pooled</code>, <code>grid</code> limited (2021) Coarse resolution product detail"},{"location":"models/#on-the-fly-foundation-models","title":"On-the-fly Foundation Models","text":"Model ID Primary Input Temporal style Outputs Notable requirements Detail <code>remoteclip_s2rgb</code> S2 RGB (<code>B4,B3,B2</code>) single composite window <code>pooled</code>, <code>grid</code> provider backend; RGB preprocessing detail <code>satmae_rgb</code> S2 RGB (<code>B4,B3,B2</code>) single composite window <code>pooled</code>, <code>grid</code> RGB path; ViT token/grid behavior detail <code>scalemae_rgb</code> S2 RGB + scale single composite window <code>pooled</code>, <code>grid</code> requires <code>sensor.scale_m</code> / <code>input_res_m</code> detail <code>dynamicvis</code> S2 RGB (<code>B4,B3,B2</code>) single composite window <code>pooled</code>, <code>grid</code> larger default resize (<code>512</code>) detail <code>wildsat</code> S2 RGB single composite window <code>pooled</code>, <code>grid</code> normalization options detail <code>prithvi_eo_v2_s2_6b</code> S2 6-band single composite window <code>pooled</code>, <code>grid</code> required temporal + location side inputs detail <code>terrafm_b</code> S2 12-band or S1 VV/VH single composite window <code>pooled</code>, <code>grid</code> choose modality per call detail <code>terramind</code> S2 SR 12-band single composite window <code>pooled</code>, <code>grid</code> strict normalization/channel semantics detail <code>dofa</code> Multispectral + wavelengths single composite window <code>pooled</code>, <code>grid</code> wavelength vector required/inferred detail <code>fomo</code> S2 12-band single composite window <code>pooled</code>, <code>grid</code> normalization mode choices detail <code>thor_1_0_base</code> S2 SR 10-band single composite window <code>pooled</code>, <code>grid</code> strict stats-based normalization detail <code>satvision_toa</code> TOA 14-channel single composite window <code>pooled</code>, <code>grid</code> strict channel order + calibration detail <code>anysat</code> S2 10-band time series multi-frame <code>pooled</code>, <code>grid</code> frame dates (<code>s2_dates</code>) side input detail <code>galileo</code> S2 10-band time series multi-frame <code>pooled</code>, <code>grid</code> month tokens + grouped tensors detail <code>agrifm</code> S2 10-band time series multi-frame <code>pooled</code>, <code>grid</code> fixed <code>T</code> frame stack behavior detail"},{"location":"models/#temporal-and-comparison-notes-what-people-usually-miss","title":"Temporal and Comparison Notes (What People Usually Miss)","text":"<ul> <li><code>TemporalSpec.range(start, end)</code> is usually a window for compositing, not a single-scene acquisition selector.</li> <li><code>OutputSpec.grid()</code> may be a token/patch grid, not a georeferenced raster grid (especially for ViT-like backbones).</li> <li>Cross-model comparisons are easiest with <code>OutputSpec.pooled()</code> and fixed ROI/temporal/compositing settings.</li> <li>Multi-frame models (<code>agrifm</code>, <code>anysat</code>, <code>galileo</code>) need extra attention to frame count and temporal side inputs.</li> </ul> <p>Read the details in Supported Models (Advanced Reference).</p>"},{"location":"models/#per-model-detail-pages-template-first","title":"Per-model Detail Pages (Template-first)","text":"<p>This repo now includes a reusable template page for documenting each model consistently:</p> <ul> <li>Model Detail Template</li> </ul> <p>Recommended fields for each model page:</p> <ul> <li>what the model expects (<code>input</code> contract, band order, temporal mode)</li> <li>what rs-embed currently feeds (current adapter behavior)</li> <li>preprocessing defaults and env knobs</li> <li>output semantics (<code>pooled</code> vs <code>grid</code> details)</li> <li>caveats for reproducibility / fair benchmarking</li> </ul>"},{"location":"models/#source-of-truth-in-code","title":"Source of Truth in Code","text":"<p>Model registration source of truth:</p> <ul> <li><code>src/rs_embed/embedders/catalog.py</code> (<code>MODEL_SPECS</code>)</li> </ul> <p>Implementation details for each adapter live in:</p> <ul> <li><code>src/rs_embed/embedders/onthefly_*.py</code></li> <li><code>src/rs_embed/embedders/precomputed_*.py</code></li> </ul> <p>When docs and code disagree, check code first and update docs accordingly.</p>"},{"location":"models_reference/","title":"Supported Models (Advanced Reference)","text":"<p>This page preserves the detailed model comparison matrices and preprocessing notes.</p> <p>If you are choosing a model for the first time, start with:</p> <ul> <li>Supported Models (Overview)</li> </ul> <p>If you are authoring a new per-model doc page, use:</p> <ul> <li>Model Detail Template</li> </ul> <p>This page is best used after you already narrowed down candidate models and want to compare:</p> <ol> <li>preprocessing assumptions</li> <li>temporal packaging</li> <li>side-input requirements</li> <li>environment-variable tuning knobs</li> </ol>"},{"location":"models_reference/#how-to-use-this-page","title":"How To Use This Page","text":""},{"location":"models_reference/#quick-chooser-by-goal","title":"Quick chooser by goal","text":"Goal Start with Why Fast baseline / simple pipeline <code>tessera</code>, <code>gse_annual</code>, <code>copernicus_embed</code> Precomputed embeddings, fewer runtime dependencies General on-the-fly RGB experiments <code>remoteclip_s2rgb</code>, <code>satmae_rgb</code>, <code>scalemae_rgb</code>, <code>dynamicvis</code> Simple S2 RGB input paths Time-series modeling <code>agrifm</code>, <code>anysat</code>, <code>galileo</code> Native multi-frame temporal packaging Multispectral / strict spectral semantics <code>dofa</code>, <code>terramind</code>, <code>thor_1_0_base</code>, <code>satvision_toa</code> Strong channel/schema assumptions S1/S2 modality experiments <code>terrafm_b</code> Supports S2 or S1 paths (per call)"},{"location":"models_reference/#readability-tips","title":"Readability tips","text":"<ul> <li>Start with Quick Comparison if you are deciding between models</li> <li>Read Temporal Handling and Multi-frame Semantics before comparing temporal models</li> <li>Read Modality and Extra Inputs Matrix if you need fair cross-model benchmarking</li> <li>Read Environment Variables... only when tuning preprocessing or reproducing training pipelines</li> </ul>"},{"location":"models_reference/#precomputed-embeddings","title":"Precomputed Embeddings","text":"Model ID Output Resolution Dim Time Coverage Notes Tessera <code>tessera</code> pooled / grid 10m 128 2017\u20132025 GeoTessera global tile embeddings Google Satellite Embedding (Alpha Earth) <code>gse_annual</code> pooled / grid 10 m 64 2017\u20132024 Annual embeddings via GEE Copernicus Embed <code>copernicus_embed</code> pooled / grid 0.25\u00b0 768 2021 Official Copernicus embeddings"},{"location":"models_reference/#on-the-fly-foundation-models","title":"On-the-fly Foundation Models","text":"<p>Source of truth:</p> <ul> <li><code>src/rs_embed/embedders/catalog.py</code></li> <li><code>src/rs_embed/embedders/onthefly_*.py</code></li> <li><code>src/rs_embed/embedders/_vit_mae_utils.py</code></li> <li><code>src/rs_embed/embedders/runtime_utils.py</code></li> </ul> <p>Registered on-the-fly IDs:</p> <ul> <li><code>remoteclip_s2rgb</code></li> <li><code>satmae_rgb</code></li> <li><code>scalemae_rgb</code></li> <li><code>anysat</code></li> <li><code>dynamicvis</code></li> <li><code>galileo</code></li> <li><code>wildsat</code></li> <li><code>prithvi_eo_v2_s2_6b</code></li> <li><code>terrafm_b</code></li> <li><code>terramind</code></li> <li><code>dofa</code></li> <li><code>fomo</code></li> <li><code>thor_1_0_base</code></li> <li><code>agrifm</code></li> <li><code>satvision_toa</code></li> </ul>"},{"location":"models_reference/#quick-comparison","title":"Quick Comparison","text":"Model ID Architecture / Backbone Input Default Preprocessing Resize / Crop / Pad Output Structure Training Alignment <code>remoteclip_s2rgb</code> <code>rshf.remoteclip.RemoteCLIP</code> (open_clip style CLIP ViT) S2 RGB (<code>B4,B3,B2</code>) raw SR <code>0..10000</code> -&gt; <code>/10000</code> -&gt; RGB <code>uint8</code>; then model transform if available, else CLIP norm image size 224; fallback path uses <code>Resize + CenterCrop</code>; no pad pooled vector or ViT token grid Medium (high if wrapper transform matches training; fallback is generic CLIP pipeline) <code>satmae_rgb</code> <code>rshf.satmae.SatMAE</code> S2 RGB (<code>B4,B3,B2</code>) raw SR -&gt; <code>/10000</code> -&gt; RGB <code>uint8</code>; prefer model transform, else CLIP norm default 224; CLIP fallback has <code>Resize + CenterCrop</code>; no pad token sequence -&gt; pooled or patch-token grid Medium <code>scalemae_rgb</code> <code>rshf.scalemae.ScaleMAE</code> (ViT style) S2 RGB (<code>B4,B3,B2</code>) + <code>input_res_m</code> raw SR -&gt; <code>/10000</code> -&gt; RGB <code>uint8</code>; CLIP norm tensor; pass <code>input_res_m</code> default 224; CLIP path has <code>Resize + CenterCrop</code>; no pad token sequence or pooled vector depending on wrapper output Medium <code>anysat</code> AnySat from upstream <code>hubconf.py</code> (<code>AnySat</code>) S2 10-band TCHW (or CHW auto-expanded) clip to <code>0..10000</code>; normalize mode default <code>per_tile_zscore</code>; builds per-frame <code>s2_dates</code> resize TCHW to default 24; no crop, no pad patch output <code>[D,H,W]</code>, pooled by spatial mean/max Medium <code>dynamicvis</code> <code>DynamicVisBackbone</code> (official repo) S2 RGB (<code>B4,B3,B2</code>) raw SR -&gt; <code>/10000</code> -&gt; RGB <code>uint8</code> -&gt; ImageNet mean/std default 512; resize to square; no pad last feature map <code>[D,H,W]</code>, pooled by spatial mean/max Medium <code>galileo</code> <code>Encoder</code> from official <code>single_file_galileo.py</code> S2 10-band TCHW (or CHW auto-expanded) clip to <code>0..10000</code>; normalize mode default <code>unit_scale</code>; constructs Galileo tensors with configurable <code>T</code> + per-frame <code>months</code>, optional NDVI channel default 64 with patch 8; bilinear resize; no pad pooled token vector and S2-group token grid Medium <code>wildsat</code> WildSAT backbone + optional image head from checkpoint S2 RGB CHW clip to <code>0..10000</code> then <code>/10000</code>; default normalization <code>minmax</code>; convert to <code>uint8</code> then unit tensor default 224; resize RGB; no pad pooled branch output and optional grid (token or feature path) Medium-Low <code>prithvi_eo_v2_s2_6b</code> TerraTorch <code>BACKBONE_REGISTRY</code> Prithvi backbone S2 6-band (<code>BLUE,GREEN,RED,NIR_NARROW,SWIR_1,SWIR_2</code>) raw SR -&gt; <code>/10000</code> -&gt; clamp <code>[0,1]</code>; prep mode from env default mode <code>resize</code> to 224; optional <code>pad</code> to patch multiple (legacy) token sequence -&gt; pooled or patch-token grid Medium <code>terrafm_b</code> TerraFM-B from HF code/weights S2 12-band or S1 VV/VH S2: <code>/10000</code> to <code>[0,1]</code>; S1: <code>log1p</code> + p99 scaling to <code>[0,1]</code> resize to 224; no pad pooled embedding, optional feature-map grid Medium <code>terramind</code> TerraTorch <code>BACKBONE_REGISTRY</code> TerraMind backbone S2 SR 12-band raw <code>0..10000</code>; resize 224; z-score with TerraMind v1/v01 pretrained mean/std fixed 224; no pad token sequence -&gt; pooled or patch-token grid High <code>dofa</code> TorchGeo DOFA (<code>dofa_base_patch16_224</code> / <code>dofa_large_patch16_224</code>) multi-band SR CHW + wavelengths raw SR -&gt; <code>/10000</code> to <code>[0,1]</code>; provide/infer wavelengths bilinear resize to 224; explicitly no crop/pad pooled vector or token grid (usually 14x14) Medium-High <code>fomo</code> FoMo <code>MultiSpectralViT</code> (FoMo-Bench) S2 SR 12-band clip <code>0..10000</code>; default <code>unit_scale</code> (optional minmax/none) default 64; bilinear resize; no pad token sequence pooled; grid as spectral-mean patch-token map Medium <code>thor_1_0_base</code> THOR via TerraTorch + <code>thor_terratorch_ext</code> S2 SR 10-band clip <code>0..10000</code>; default <code>thor_stats</code> z-score after reflectance scaling default 288; bilinear resize; no pad pooled tokens and grouped token grid Medium-High <code>agrifm</code> AgriFM <code>PretrainingSwinTransformer3DEncoder</code> S2 10-band time series <code>[T,C,H,W]</code> clip <code>0..10000</code>; default <code>agrifm_stats</code> z-score using official config stats default 224; TCHW resize; no pad feature map grid <code>[D,H,W]</code>, pooled by spatial mean/max High <code>satvision_toa</code> <code>timm</code> <code>SwinTransformerV2</code> (SatVision-TOA checkpoints) TOA 14 channels in strict order channel-aware normalization to <code>[0,1]</code> (<code>auto/raw/unit</code>, reflectance + emissive calibration) default 128; bilinear resize; no pad model output as pooled or grid depending on tensor shape High (if band order and calibration match checkpoint)"},{"location":"models_reference/#temporal-handling","title":"Temporal Handling","text":"<ul> <li>For most on-the-fly adapters, <code>TemporalSpec.range(start, end)</code> means: filter imagery in <code>[start, end)</code>, then build one composite patch for model input (<code>median</code> by default, or <code>mosaic</code> if configured via <code>SensorSpec.composite</code>).</li> <li>In these adapters, <code>meta.input_time</code> is typically the midpoint of the temporal window and is mainly metadata (or an auxiliary time signal for models that require it), not a guaranteed single-scene acquisition date.</li> <li>Multi-frame adapters: <code>agrifm</code>, <code>anysat</code>, and <code>galileo</code> fetch TCHW sequences by splitting the requested range into sub-windows and compositing each sub-window into one frame.</li> <li>Current single-composite adapters include: <code>remoteclip_s2rgb</code>, <code>satmae_rgb</code>, <code>scalemae_rgb</code>, <code>dynamicvis</code>, <code>wildsat</code>, <code>prithvi_eo_v2_s2_6b</code>, <code>terrafm_b</code>, <code>terramind</code>, <code>dofa</code>, <code>fomo</code>, <code>thor_1_0_base</code>, and <code>satvision_toa</code>.</li> </ul>"},{"location":"models_reference/#multi-frame-semantics","title":"Multi-frame Semantics","text":"<p>Shared behavior for current multi-frame adapters (<code>agrifm</code>, <code>anysat</code>, <code>galileo</code>):</p> <ul> <li>Frame construction: split <code>TemporalSpec.range(start, end)</code> into <code>T</code> equal sub-windows (end-exclusive), then composite each sub-window into one frame.</li> <li>Missing-observation fallback: if a sub-window has no valid image, provider path reuses a fallback composite so frame count remains stable.</li> <li>Fixed frame count: runtime always ensures exact <code>T</code> frames for model input.   For user-provided <code>input_chw</code>, <code>CHW</code> is repeated to <code>T</code>, and <code>TCHW</code> is padded/truncated to <code>T</code>.</li> <li>Sensor compositing policy: frame composite mode follows <code>SensorSpec.composite</code> (<code>median</code> default, <code>mosaic</code> optional).</li> </ul> <p>Per-model temporal packaging:</p> Model ID Frame count env (default) Temporal side input Notes <code>agrifm</code> <code>RS_EMBED_AGRIFM_FRAMES</code> (<code>8</code>) none (uses <code>TCHW</code> directly) Temporal information is encoded only in the frame stack. <code>anysat</code> <code>RS_EMBED_ANYSAT_FRAMES</code> (<code>8</code>) <code>s2_dates</code> (per-frame DOY, <code>0..364</code>) DOY values are derived from each frame bin midpoint date. <code>galileo</code> <code>RS_EMBED_GALILEO_FRAMES</code> (<code>8</code>) <code>months</code> (per-frame month, <code>1..12</code>) By default from frame bin midpoints; <code>RS_EMBED_GALILEO_MONTH</code> can force a constant month for all frames."},{"location":"models_reference/#modality-and-extra-inputs-matrix","title":"Modality and Extra Inputs Matrix","text":"<p>Interpretation:</p> <ul> <li>\"Backbone multimodal\" means the upstream foundation model family supports multiple modalities.</li> <li>\"Current rs-embed path\" means what this implementation currently feeds in practice.</li> <li>\"Requires extra metadata\" means additional non-image inputs required by the forward path (hard requirement).</li> </ul> Model ID Backbone multimodal? Current rs-embed path uses multiple modalities? Multi-input forward (beyond image tensor)? Requires extra metadata? <code>remoteclip_s2rgb</code> No No No No <code>satmae_rgb</code> No No No No <code>scalemae_rgb</code> No No Yes (<code>input_res_m</code>) Yes: scale/resolution (<code>sensor.scale_m</code>) <code>anysat</code> Yes Partially (S2-only imagery, plus temporal date tokens) Yes (<code>s2</code>, <code>s2_dates</code>) Yes: day-of-year/date signal (derived from temporal range) <code>dynamicvis</code> No No No No <code>galileo</code> Yes Mostly S2 path in current adapter + temporal month tokens Yes (multiple tensors + masks + <code>months</code>) Yes: month/time signal (derived from temporal range) <code>wildsat</code> No No No No <code>prithvi_eo_v2_s2_6b</code> No (this adapter path) No Yes (<code>x</code>, <code>temporal_coords</code>, <code>location_coords</code>) Yes: location + time are required <code>terrafm_b</code> Yes (<code>S1</code>/<code>S2</code>) Yes (select one modality per call: <code>s1</code> or <code>s2</code>) No No hard extra metadata (optional S1 options: orbit, linear/DB path) <code>terramind</code> Yes Usually single selected modality (<code>S2L2A</code> default) No (single selected modality tensor in this adapter) No hard extra metadata <code>dofa</code> Yes (spectral generalization) Yes (multi-band spectral input) Yes (image + wavelength list) Yes: per-band wavelengths (explicit or inferable from bands) <code>fomo</code> No No No No <code>thor_1_0_base</code> No (this adapter path) No No No <code>agrifm</code> No (this adapter path) No No extra side tensor, but temporal stack <code>[T,C,H,W]</code> required Temporal coverage is important (no separate metadata tensor) <code>satvision_toa</code> No (this adapter path) No No separate side tensor Yes: strict 14-channel order/calibration schema (band semantics) <p>Practically multi-input models:</p> <ul> <li><code>prithvi_eo_v2_s2_6b</code>: image + temporal coords + location coords</li> <li><code>anysat</code>: image/time-series + date tokens (<code>s2_dates</code>)</li> <li><code>galileo</code>: image-derived tensors + masks + per-frame month tokens (<code>months</code>)</li> <li><code>dofa</code>: image + wavelength vector</li> <li><code>scalemae_rgb</code>: image + <code>input_res_m</code></li> </ul>"},{"location":"models_reference/#environment-variables-that-directly-change-preprocessingtemporal-packaging","title":"Environment Variables That Directly Change Preprocessing/Temporal Packaging","text":"Model ID Main preprocessing env keys <code>remoteclip_s2rgb</code> fixed <code>image_size=224</code> in code path; no per-model preprocess env switch <code>satmae_rgb</code> <code>RS_EMBED_SATMAE_IMG</code> <code>scalemae_rgb</code> <code>RS_EMBED_SCALEMAE_IMG</code> <code>anysat</code> <code>RS_EMBED_ANYSAT_IMG</code>, <code>RS_EMBED_ANYSAT_NORM</code>, <code>RS_EMBED_ANYSAT_FRAMES</code> <code>dynamicvis</code> <code>RS_EMBED_DYNAMICVIS_IMG</code> <code>galileo</code> <code>RS_EMBED_GALILEO_IMG</code>, <code>RS_EMBED_GALILEO_PATCH</code>, <code>RS_EMBED_GALILEO_NORM</code>, <code>RS_EMBED_GALILEO_INCLUDE_NDVI</code>, <code>RS_EMBED_GALILEO_FRAMES</code>, <code>RS_EMBED_GALILEO_MONTH</code> <code>wildsat</code> <code>RS_EMBED_WILDSAT_IMG</code>, <code>RS_EMBED_WILDSAT_NORM</code> <code>prithvi_eo_v2_s2_6b</code> <code>RS_EMBED_PRITHVI_PREP</code>, <code>RS_EMBED_PRITHVI_IMG</code>, <code>RS_EMBED_PRITHVI_PATCH_MULT</code> <code>terrafm_b</code> modality and sensor-side options (<code>s2</code>/<code>s1</code>); image size fixed to 224 in implementation <code>terramind</code> <code>RS_EMBED_TERRAMIND_NORMALIZE</code> (default z-score stats), image size fixed 224 <code>dofa</code> image size fixed 224; provider/tensor channels and wavelengths drive preprocessing <code>fomo</code> <code>RS_EMBED_FOMO_IMG</code>, <code>RS_EMBED_FOMO_NORM</code> <code>thor_1_0_base</code> <code>RS_EMBED_THOR_IMG</code>, <code>RS_EMBED_THOR_NORMALIZE</code> <code>agrifm</code> <code>RS_EMBED_AGRIFM_IMG</code>, <code>RS_EMBED_AGRIFM_NORM</code>, <code>RS_EMBED_AGRIFM_FRAMES</code> <code>satvision_toa</code> <code>RS_EMBED_SATVISION_TOA_IMG</code>, <code>RS_EMBED_SATVISION_TOA_NORM</code>, channel-index and calibration env keys"},{"location":"models_reference/#practical-guidance","title":"Practical Guidance","text":"<ul> <li>For highest reproducibility, keep each model's default normalization mode unless you can match the original training pipeline exactly.</li> <li>For strict-schema models (<code>satvision_toa</code>, <code>terramind</code>, <code>thor_1_0_base</code>, <code>agrifm</code>), do not change channel order unless checkpoint metadata explicitly allows it.</li> <li>If comparing embeddings across models, standardize ROI and temporal compositing first; model preprocessing differences are substantial.</li> </ul>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#quick-start","title":"Quick Start","text":"<p>This page is for getting a first successful run quickly.</p> <ul> <li>New to <code>rs-embed</code>: follow this page top-to-bottom</li> <li>Already installed: jump to Run <code>examples/quickstart.py</code></li> <li>Need semantics first (<code>TemporalSpec</code>, <code>OutputSpec</code>): read Core Concepts</li> <li>Need task-oriented patterns after setup: read Common Workflows</li> </ul>"},{"location":"quickstart/#install-temporary","title":"Install (temporary)","text":"<pre><code>git clone https://github.com/Dinghye/rs-embed.git\n# or: git clone git@github.com:Dinghye/rs-embed.git\ncd rs-embed\nconda env create -f environment.yml\nconda activate rs-embed\npip install -e .\n</code></pre> <p>For on-the-fly model demos (GEE + torch wrappers), install optional dependencies if needed:</p> <pre><code>pip install -e \".[gee,torch,models]\"\n</code></pre> <p>Examples notebook: <code>examples/playground.ipynb</code></p>"},{"location":"quickstart/#authenticate-google-earth-engine","title":"Authenticate Google Earth Engine","text":"<p>If you are using GEE for the first time, complete the authentication process with the following command.</p> <pre><code>earthengine authenticate\n</code></pre>"},{"location":"quickstart/#run-examplesquickstartpy","title":"Run <code>examples/quickstart.py</code>","text":"<p>You can run the packaged quickstart script directly:</p> <pre><code># show CLI options\npython examples/quickstart.py --help\n</code></pre>"},{"location":"quickstart/#local-mode-default-precomputed","title":"Local mode (default, precomputed)","text":"<p>Runs <code>tessera</code> examples for: - single embedding (<code>pooled</code> + <code>grid</code>) - batch embeddings (<code>get_embeddings_batch</code>) - optional export (<code>export_batch</code>)</p> <pre><code>python examples/quickstart.py --mode local\npython examples/quickstart.py --mode local --run-export\n</code></pre>"},{"location":"quickstart/#gee-mode-on-the-fly","title":"GEE mode (on-the-fly)","text":"<p>Runs <code>remoteclip_s2rgb</code> examples for: - <code>inspect_gee_patch</code> (backward-compatible wrapper; see also <code>inspect_provider_patch</code>) - single embedding - batch embeddings - optional export</p> <pre><code>python examples/quickstart.py --mode gee --device auto\npython examples/quickstart.py --mode gee --run-export --out-dir examples/_outputs/quickstart\n</code></pre>"},{"location":"quickstart/#run-all-demos","title":"Run all demos","text":"<pre><code>python examples/quickstart.py --mode all\npython examples/quickstart.py --mode all --run-export\n</code></pre> <p>Tip</p> <p>If you see <code>ModuleNotFoundError: No module named 'rs_embed'</code>, run from repository root after installation: <code>pip install -e .</code></p>"},{"location":"quickstart/#1-compute-a-single-embedding","title":"1. Compute a single embedding","text":"<pre><code>from rs_embed import PointBuffer, TemporalSpec, OutputSpec, get_embedding\n\nemb = get_embedding(\n    \"remoteclip_s2rgb\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(pooling=\"mean\"),\n    backend=\"gee\",\n    device=\"auto\",\n)\n\nvec = emb.data  # shape: (D,)\nmeta = emb.meta\n</code></pre> <p>Note</p> <p><code>TemporalSpec.range(start, end)</code> is treated as a temporal window (half-open: <code>[start, end)</code>). On GEE-backed on-the-fly paths, inputs are typically composites over that window (<code>median</code> by default), not an auto-selected single-day scene.</p>"},{"location":"quickstart/#2-batch-compute-embeddings-for-many-points","title":"2. Batch compute embeddings for many points","text":"<pre><code>from rs_embed import PointBuffer, TemporalSpec, get_embeddings_batch\n\nspatials = [\n    PointBuffer(121.5, 31.2, 2048),\n    PointBuffer(120.5, 30.2, 2048),\n]\n\nembs = get_embeddings_batch(\n    \"remoteclip_s2rgb\",\n    spatials=spatials,\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    backend=\"gee\",\n    device=\"auto\",\n)\n</code></pre>"},{"location":"quickstart/#3-export-at-scale-recommended-workflow","title":"3. Export at scale (recommended workflow)","text":"<p><code>export_batch</code> is the core export API. It supports:</p> <ul> <li>arbitrary point / ROI lists</li> <li>multiple models per ROI</li> <li>saving inputs and embeddings</li> <li>manifests for downstream bookkeeping</li> </ul> <pre><code>from rs_embed import export_batch, PointBuffer, TemporalSpec\n\nspatials = [\n    PointBuffer(121.5, 31.2, 2048),\n    PointBuffer(120.5, 30.2, 2048),\n]\n\nexport_batch(\n    spatials=spatials,\n    names=[\"p1\", \"p2\"],\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    models=[\"remoteclip_s2rgb\", \"prithvi_eo_v2_s2_6b\"],\n    out_dir=\"exports\",\n    backend=\"gee\",\n    device=\"auto\",\n    save_inputs=True,\n    save_embeddings=True,\n    chunk_size=32,\n    num_workers=8,\n    resume=True,\n    show_progress=True,\n)\n</code></pre>"},{"location":"quickstart/#working-with-providers-backends","title":"Working with Providers / Backends","text":"<p>rs-embed supports pluggable backends. In most setups:</p> <ul> <li><code>backend=\"gee\"</code> uses Google Earth Engine for patch retrieval and preprocessing (best for on-the-fly models).</li> </ul> <p>If the behavior of a model input looks wrong, inspect the raw patch first:</p> <ul> <li><code>inspect_provider_patch</code> (recommended, provider-agnostic)</li> <li><code>inspect_gee_patch</code> (backward-compatible alias)</li> </ul> <p>Tip</p> <p>For large exports, tune: - <code>chunk_size</code>: how many ROIs per chunk (controls memory peak) - <code>num_workers</code>: how many concurrent fetch workers (controls IO parallelism) - <code>resume=True</code>: skip files already exported in previous runs</p>"},{"location":"quickstart/#export-formats","title":"Export Formats","text":"<p><code>export_batch(format=...)</code> is designed to be extensible.</p> <ul> <li>Current formats: <code>npz</code>, <code>netcdf</code></li> <li>Planned: parquet / zarr / hdf5 (depending on your roadmap)</li> </ul> <p><code>export_npz(...)</code> is provided as a convenience wrapper for single-ROI exports and shares the same performance optimizations.</p> <p>Tip</p> <p>If you are building a repeatable dataset pipeline (many points and/or many models), prefer <code>export_batch(...)</code>. See Common Workflows for the task-first export pattern.</p>"},{"location":"quickstart/#performance-notes","title":"Performance Notes","text":""},{"location":"quickstart/#1-avoid-repeated-model-initialization","title":"1. Avoid repeated model initialization","text":"<p>rs-embed caches embedder instances internally (per <code>model + backend + device + sensor</code>), so repeated calls do not re-initialize providers or reload weights.</p>"},{"location":"quickstart/#2-avoid-repeated-input-downloads","title":"2. Avoid repeated input downloads","text":"<p>When you use:</p> <ul> <li><code>backend=\"gee\"</code></li> <li><code>save_inputs=True</code></li> <li><code>save_embeddings=True</code></li> </ul> <p><code>export_batch</code> will prefetch each input patch once and reuse it for both: - saving the input patch - computing embeddings (via <code>input_chw</code>)</p>"},{"location":"quickstart/#3-io-parallelism-vs-inference-safety","title":"3. IO parallelism vs inference safety","text":"<p><code>export_batch</code> currently uses two-level scheduling: - IO level: remote patch prefetch is parallelized (<code>num_workers</code>). - Inference level:   - model-to-model execution is serial (stability-first default),   - but each model can use batched inference over many points when batch APIs are available (such as <code>get_embeddings_batch</code> / <code>get_embeddings_batch_from_inputs</code>): in combined mode by default, and in per-item mode when running on GPU/accelerators.</p> <p>So rs-embed supports batch-level inference acceleration, while model-level scheduling remains serial by design.</p>"},{"location":"workflows/","title":"Common Workflows","text":"<p>This page is task-first: start from what you want to do, then use the smallest API surface that gets you there.</p> <p>For full signatures and edge cases, see API Reference.</p>"},{"location":"workflows/#workflow-1-get-a-single-embedding-fastest-path","title":"Workflow 1: Get a Single Embedding (Fastest Path)","text":"<p>Use <code>get_embedding(...)</code> when you want one ROI embedding now.</p> <pre><code>from rs_embed import PointBuffer, TemporalSpec, OutputSpec, get_embedding\n\nemb = get_embedding(\n    \"remoteclip_s2rgb\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n    device=\"auto\",\n)\n</code></pre> <p>Choose this when:</p> <ul> <li>you are prototyping</li> <li>you want to inspect metadata</li> <li>you are debugging model behavior on one location</li> </ul>"},{"location":"workflows/#workflow-2-compare-many-points-for-one-model","title":"Workflow 2: Compare Many Points for One Model","text":"<p>Use <code>get_embeddings_batch(...)</code> when the model is fixed and you have multiple ROIs.</p> <pre><code>from rs_embed import PointBuffer, TemporalSpec, OutputSpec, get_embeddings_batch\n\nspatials = [\n    PointBuffer(121.5, 31.2, 2048),\n    PointBuffer(120.5, 30.2, 2048),\n]\n\nembs = get_embeddings_batch(\n    \"remoteclip_s2rgb\",\n    spatials=spatials,\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre> <p>Choose this when:</p> <ul> <li>same model, many points</li> <li>you want simpler code than manual loops</li> <li>you may benefit from embedder-level batch inference</li> </ul>"},{"location":"workflows/#workflow-3-export-a-dataset-recommended-for-real-projects","title":"Workflow 3: Export a Dataset (Recommended for Real Projects)","text":"<p>Use <code>export_batch(...)</code> for reproducible data pipelines and downstream experiments.</p> <pre><code>from rs_embed import export_batch, PointBuffer, TemporalSpec\n\nspatials = [\n    PointBuffer(121.5, 31.2, 2048),\n    PointBuffer(120.5, 30.2, 2048),\n]\n\nexport_batch(\n    spatials=spatials,\n    names=[\"p1\", \"p2\"],\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    models=[\"remoteclip_s2rgb\", \"prithvi_eo_v2_s2_6b\"],\n    out_dir=\"exports\",\n    backend=\"gee\",\n    save_inputs=True,\n    save_embeddings=True,\n    resume=True,\n)\n</code></pre> <p>Choose this when:</p> <ul> <li>multiple models and/or many points</li> <li>you need manifests for bookkeeping</li> <li>you want resumable exports</li> <li>you want to avoid duplicate input downloads</li> </ul>"},{"location":"workflows/#workflow-4-inspect-inputs-before-running-a-model","title":"Workflow 4: Inspect Inputs Before Running a Model","text":"<p>Use patch inspection when outputs look suspicious (clouds, wrong band order, bad dynamic range, etc.).</p>"},{"location":"workflows/#preferred-provider-agnostic","title":"Preferred: provider-agnostic","text":"<pre><code>from rs_embed import inspect_provider_patch, PointBuffer, TemporalSpec, SensorSpec\n\nreport = inspect_provider_patch(\n    spatial=PointBuffer(121.5, 31.2, 2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    sensor=SensorSpec(\n        collection=\"COPERNICUS/S2_SR_HARMONIZED\",\n        bands=(\"B4\", \"B3\", \"B2\"),\n        scale_m=10,\n    ),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"workflows/#backward-compatible-alias","title":"Backward-compatible alias","text":"<ul> <li><code>inspect_gee_patch(...)</code> calls the same underlying inspection flow for GEE paths.</li> </ul>"},{"location":"workflows/#workflow-5-large-roi-with-better-spatial-fidelity","title":"Workflow 5: Large ROI with Better Spatial Fidelity","text":"<p>If you request large ROIs for on-the-fly models, try API-side tiling:</p> <pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"remoteclip_s2rgb\",\n    spatial=PointBuffer(121.5, 31.2, 8000),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.grid(),\n    backend=\"gee\",\n    input_prep=\"tile\",\n)\n</code></pre> <p>Use <code>input_prep=\"tile\"</code> when:</p> <ul> <li><code>OutputSpec.grid()</code> matters</li> <li>large ROI resize would lose too much detail</li> <li>you accept extra runtime cost for better spatial structure preservation</li> </ul>"},{"location":"workflows/#workflow-6-fair-cross-model-comparisons","title":"Workflow 6: Fair Cross-Model Comparisons","text":"<p>When benchmarking models, prefer:</p> <ul> <li>same ROI list</li> <li>same temporal window</li> <li>same compositing policy (<code>SensorSpec.composite</code>)</li> <li><code>OutputSpec.pooled()</code> first</li> <li>default model normalization unless replicating original training setup</li> </ul> <p>Then use Supported Models to review model-specific preprocessing and required side inputs.</p>"},{"location":"workflows/#choosing-the-right-page","title":"Choosing the Right Page","text":"<ul> <li>Need runnable setup steps: Quick Start</li> <li>Need mental model and semantics: Core Concepts</li> <li>Need model capability matrix: Supported Models</li> <li>Need exact function signatures/options: API Reference</li> </ul>"},{"location":"models/agrifm/","title":"AgriFM (<code>agrifm</code>)","text":"<p>Multi-frame Sentinel-2 adapter for AgriFM (Video Swin-style backbone), with fixed-frame temporal packaging and provider-backed S2 sequence fetching.</p>"},{"location":"models/agrifm/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>agrifm</code> Family / Backbone AgriFM (repo + checkpoint loader, lightweight shim path supported) Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>) Primary input S2 SR 10-band time series (<code>T,10,H,W</code>) Temporal mode <code>range</code> in practice (window split into <code>T</code> frames) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none required (adapter builds fixed frame stack) Training alignment (adapter path) High when <code>n_frames</code>, normalization, and checkpoint/repo versions are fixed"},{"location":"models/agrifm/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/agrifm/#good-fit-for","title":"Good fit for","text":"<ul> <li>crop/agriculture-oriented temporal S2 experiments</li> <li>comparisons against other multi-frame adapters (<code>anysat</code>, <code>galileo</code>)</li> <li>workflows where a consistent fixed-length frame stack is useful</li> </ul>"},{"location":"models/agrifm/#be-careful-when","title":"Be careful when","text":"<ul> <li>changing <code>RS_EMBED_AGRIFM_FRAMES</code> across experiments (changes temporal packaging)</li> <li>feeding <code>CHW</code> inputs and forgetting they get repeated to <code>T</code> frames</li> <li>comparing with single-window models without documenting temporal/frame construction</li> </ul>"},{"location":"models/agrifm/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/agrifm/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li>Provider backend only (<code>backend=\"gee\"</code> / provider-compatible backend)</li> <li><code>TemporalSpec</code> normalized to range via shared helper (<code>TemporalSpec.range(...)</code> recommended)</li> <li>Provider path fetches a multi-frame S2 sequence over the range and composes it into fixed <code>T</code> frames</li> </ul>"},{"location":"models/agrifm/#sensor-channels","title":"Sensor / channels","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: <code>B2,B3,B4,B5,B6,B7,B8,B8A,B11,B12</code></li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code>, <code>fill_value=0.0</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>accepts <code>CHW</code> with <code>C=10</code></li> <li>adapter repeats the same frame to <code>T = RS_EMBED_AGRIFM_FRAMES</code></li> <li>accepts <code>TCHW</code> with <code>C=10</code></li> <li>adapter pads (repeat last frame) or truncates to exact <code>T</code></li> <li>values are clipped to raw S2 SR range <code>0..10000</code></li> </ul>"},{"location":"models/agrifm/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Resolve runtime settings:</li> <li><code>n_frames</code>, <code>image_size</code>, normalization mode</li> <li>checkpoint path (local or auto-download)</li> <li>AgriFM repo path (local or auto-clone)</li> <li>Fetch provider multi-frame raw <code>TCHW</code> or coerce <code>input_chw</code> (<code>CHW</code>/<code>TCHW</code>) to exact <code>T</code></li> <li>Optional input inspection on frame 0 (temporarily scaled to <code>[0,1]</code>)</li> <li>Normalize with <code>RS_EMBED_AGRIFM_NORM</code>:</li> <li><code>agrifm_stats</code> (default): z-score with AgriFM S2 statistics</li> <li><code>unit_scale</code>: divide by <code>10000</code> and clip <code>[0,1]</code></li> <li><code>none</code> / <code>raw</code>: keep raw <code>0..10000</code> (clipped)</li> <li>Resize all frames to <code>RS_EMBED_AGRIFM_IMG</code> (default <code>224</code>)</li> <li>Load AgriFM model (checkpoint + repo code)</li> <li>Forward to produce embedding grid <code>(D,H,W)</code></li> <li>Return:</li> <li>pooled vector = spatial mean/max over grid</li> <li>grid = <code>xarray.DataArray</code></li> </ol>"},{"location":"models/agrifm/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":""},{"location":"models/agrifm/#temporal-preprocessing","title":"Temporal / preprocessing","text":"Env var Default Effect <code>RS_EMBED_AGRIFM_FRAMES</code> <code>8</code> Fixed frame count <code>T</code> <code>RS_EMBED_AGRIFM_IMG</code> <code>224</code> Resize target image size <code>RS_EMBED_AGRIFM_NORM</code> <code>agrifm_stats</code> <code>agrifm_stats</code>, <code>unit_scale</code>, or <code>none</code> <code>RS_EMBED_AGRIFM_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs"},{"location":"models/agrifm/#checkpoint-loading","title":"Checkpoint loading","text":"Env var Default Effect <code>RS_EMBED_AGRIFM_CKPT</code> unset Local checkpoint path <code>RS_EMBED_AGRIFM_AUTO_DOWNLOAD</code> <code>1</code> Allow checkpoint auto-download <code>RS_EMBED_AGRIFM_CACHE_DIR</code> <code>~/.cache/rs_embed/agrifm</code> Checkpoint cache dir <code>RS_EMBED_AGRIFM_CKPT_FILE</code> <code>AgriFM.pth</code> Cached checkpoint filename <code>RS_EMBED_AGRIFM_CKPT_URL</code> project default URL Checkpoint download URL <code>RS_EMBED_AGRIFM_CKPT_MIN_BYTES</code> large-size threshold Download validation threshold"},{"location":"models/agrifm/#repo-loading-agrifm-source-code","title":"Repo loading (AgriFM source code)","text":"Env var Default Effect <code>RS_EMBED_AGRIFM_REPO_PATH</code> unset Local AgriFM repo path <code>RS_EMBED_AGRIFM_REPO_URL</code> <code>https://github.com/flyakon/AgriFM</code> Repo clone source <code>RS_EMBED_AGRIFM_REPO_CACHE</code> <code>~/.cache/rs_embed</code> Repo cache root <code>RS_EMBED_AGRIFM_AUTO_DOWNLOAD_REPO</code> <code>1</code> Auto-clone repo when missing"},{"location":"models/agrifm/#output-semantics","title":"Output Semantics","text":""},{"location":"models/agrifm/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Adapter pools the AgriFM grid spatially:</li> <li><code>mean</code> -&gt; spatial mean over <code>(H,W)</code></li> <li><code>max</code> -&gt; spatial max over <code>(H,W)</code></li> <li>Metadata records <code>pooling=\"spatial_mean\"</code> or <code>pooling=\"spatial_max\"</code></li> </ul>"},{"location":"models/agrifm/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Returns AgriFM feature grid as <code>xarray.DataArray</code> <code>(D,H,W)</code></li> <li>Grid is model feature map space (not georeferenced raster pixels)</li> <li>Metadata includes <code>n_frames</code>, <code>grid_hw</code>, normalization mode, and input sizes</li> </ul>"},{"location":"models/agrifm/#examples","title":"Examples","text":""},{"location":"models/agrifm/#minimal-provider-backed-example","title":"Minimal provider-backed example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"agrifm\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-01-01\", \"2022-12-31\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/agrifm/#example-temporal-packaging-and-normalization-tuning","title":"Example temporal packaging and normalization tuning","text":"<pre><code># Example (shell):\n# export RS_EMBED_AGRIFM_FRAMES=8\n# export RS_EMBED_AGRIFM_IMG=224\n# export RS_EMBED_AGRIFM_NORM=agrifm_stats\n</code></pre>"},{"location":"models/agrifm/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>backend mismatch (<code>agrifm</code> is provider-only)</li> <li>wrong <code>input_chw</code> shape (must be <code>CHW</code>/<code>TCHW</code> with <code>C=10</code>)</li> <li>silent temporal mismatch from <code>CHW</code> repeat-to-<code>T</code> behavior</li> <li>checkpoint download failure or invalid local checkpoint path</li> <li>AgriFM repo missing when auto-download is disabled</li> <li>missing lightweight import deps (<code>torch</code>, <code>timm</code>, <code>einops</code>) for repo backbone import</li> </ul> <p>Recommended first checks:</p> <ul> <li>inspect metadata for <code>n_frames</code>, <code>norm_mode</code>, <code>input_frames</code>, <code>grid_hw</code></li> <li>verify whether input came from provider fetch vs repeated <code>CHW</code></li> <li>pin checkpoint and repo path before benchmarking</li> </ul>"},{"location":"models/agrifm/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li><code>RS_EMBED_AGRIFM_FRAMES</code>, <code>RS_EMBED_AGRIFM_IMG</code>, normalization mode</li> <li>checkpoint source/path and repo source/path</li> <li>temporal window and compositing settings</li> <li>output mode / pooling choice</li> </ul> <p>Temporal note:</p> <ul> <li>Multi-frame models are very sensitive to frame count and frame construction; changing <code>FRAMES</code> is a different experiment.</li> </ul>"},{"location":"models/agrifm/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_agrifm.py</code></li> <li>Shared temporal fetch/coercion helpers: <code>src/rs_embed/embedders/runtime_utils.py</code></li> </ul>"},{"location":"models/anysat/","title":"AnySat (<code>anysat</code>)","text":"<p>Multi-frame Sentinel-2 time-series adapter that builds AnySat inputs (<code>s2</code> + <code>s2_dates</code>) from a temporal window and returns patch-grid features or pooled vectors.</p>"},{"location":"models/anysat/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>anysat</code> Family / Backbone AnySat (loaded from upstream <code>hubconf.py</code>) Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code> via public API) Primary input S2 10-band time series (<code>T,C,H,W</code>) Temporal mode <code>range</code> in practice (adapter normalizes <code>year</code>/<code>None</code> to range) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs required <code>s2_dates</code> (per-frame DOY values) Training alignment (adapter path) Medium (depends on frame count, normalization mode, and image size)"},{"location":"models/anysat/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/anysat/#good-fit-for","title":"Good fit for","text":"<ul> <li>temporal S2 sequence modeling (not just single composites)</li> <li>experiments where day-of-year context matters</li> <li>comparing multi-frame adapters (<code>anysat</code>, <code>galileo</code>, <code>agrifm</code>)</li> </ul>"},{"location":"models/anysat/#be-careful-when","title":"Be careful when","text":"<ul> <li>comparing to single-composite models without matching temporal design assumptions</li> <li>changing frame count / normalization mode without recording it</li> <li>assuming <code>grid</code> is a georeferenced raster (it is patch output mapped to <code>(D,H,W)</code>)</li> </ul>"},{"location":"models/anysat/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/anysat/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li><code>SpatialSpec</code>: <code>BBox</code> or <code>PointBuffer</code></li> <li><code>TemporalSpec</code>: normalized to range via shared helper (<code>range</code> preferred for reproducibility)</li> <li>Adapter splits the temporal window into <code>T</code> sub-windows and composites one frame per bin</li> <li>Frame dates are converted to AnySat-style day-of-year values (<code>0..364</code>) and passed as <code>s2_dates</code></li> </ul>"},{"location":"models/anysat/#sensor-channels","title":"Sensor / channels","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: <code>(\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B11\",\"B12\")</code></li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code>, <code>fill_value=0.0</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>accepts <code>CHW</code> (<code>C=10</code>) or <code>TCHW</code> (<code>C=10</code>)</li> <li><code>CHW</code> is repeated to <code>T</code> frames</li> <li><code>TCHW</code> is padded/truncated to exact <code>T</code></li> <li>values are clipped to raw-SR range <code>0..10000</code></li> </ul>"},{"location":"models/anysat/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Fetch S2 10-band time series <code>raw_tchw</code> in <code>[T,C,H,W]</code> (or coerce <code>input_chw</code> to <code>TCHW</code>)</li> <li>Optionally resize all frames to square <code>RS_EMBED_ANYSAT_IMG</code> (default <code>24</code>)</li> <li>Normalize series using <code>RS_EMBED_ANYSAT_NORM</code>:</li> <li><code>per_tile_zscore</code> (default)</li> <li><code>unit_scale</code> / <code>reflectance</code> (<code>/10000 -&gt; [0,1]</code>)</li> <li><code>raw</code> / <code>none</code></li> <li>Build AnySat side input dict:</li> <li><code>s2</code>: <code>[1,T,10,H,W]</code></li> <li><code>s2_dates</code>: <code>[1,T]</code> (DOY values from frame-bin midpoints)</li> <li>Forward with <code>output=\"patch\"</code> and <code>patch_size=output.scale_m</code></li> <li>Map AnySat patch output <code>[B,H,W,D]</code> -&gt; rs-embed grid <code>[D,H,W]</code></li> <li>Optionally spatial-pool grid to vector (<code>mean</code> or <code>max</code>)</li> </ol> <p>Important constraint:</p> <ul> <li><code>output.scale_m</code> / patch size must be a positive multiple of 10 meters</li> </ul>"},{"location":"models/anysat/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_ANYSAT_FRAMES</code> <code>8</code> Number of temporal frames <code>T</code> <code>RS_EMBED_ANYSAT_IMG</code> <code>24</code> Per-frame resize target (square) <code>RS_EMBED_ANYSAT_NORM</code> <code>per_tile_zscore</code> Series normalization mode <code>RS_EMBED_ANYSAT_MODEL_SIZE</code> <code>base</code> AnySat model size <code>RS_EMBED_ANYSAT_FLASH_ATTN</code> <code>0</code> Enable flash attention path if supported <code>RS_EMBED_ANYSAT_PRETRAINED</code> <code>1</code> Use pretrained model <code>RS_EMBED_ANYSAT_CKPT</code> unset Local checkpoint override <code>RS_EMBED_ANYSAT_REPO_PATH</code> unset Local AnySat repo path (<code>hubconf.py</code>) <code>RS_EMBED_ANYSAT_REPO_URL</code> upstream AnySat Git URL Repo clone source when auto-downloading <code>RS_EMBED_ANYSAT_REPO_CACHE</code> <code>~/.cache/rs_embed/anysat</code> Repo cache root <code>RS_EMBED_ANYSAT_AUTO_DOWNLOAD_REPO</code> <code>1</code> Auto-clone AnySat repo if missing <code>RS_EMBED_ANYSAT_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs"},{"location":"models/anysat/#output-semantics","title":"Output Semantics","text":""},{"location":"models/anysat/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Pools patch grid over spatial dims <code>(H,W)</code></li> <li>Supports <code>mean</code> and <code>max</code> pooling (<code>patch_mean</code> / <code>patch_max</code> semantics)</li> </ul>"},{"location":"models/anysat/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Returns patch features as <code>xarray.DataArray</code> <code>(D,H,W)</code></li> <li>Metadata includes <code>grid_hw</code>, <code>grid_shape</code>, patch output info, and temporal packaging details (<code>n_frames</code>, <code>doy0_values</code>)</li> <li>This is model patch output structure, not guaranteed georeferenced raster pixels</li> </ul>"},{"location":"models/anysat/#examples","title":"Examples","text":""},{"location":"models/anysat/#minimal-example","title":"Minimal example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"anysat\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-01-01\", \"2023-01-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/anysat/#example-with-temporalframe-tuning-env-controlled","title":"Example with temporal/frame tuning (env-controlled)","text":"<pre><code># Example (shell):\n# export RS_EMBED_ANYSAT_FRAMES=8\n# export RS_EMBED_ANYSAT_NORM=per_tile_zscore\n# export RS_EMBED_ANYSAT_IMG=24\n</code></pre>"},{"location":"models/anysat/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>backend is not provider-compatible</li> <li>wrong channel count for <code>input_chw</code> (must be 10 channels)</li> <li><code>output.scale_m</code> is not a positive multiple of 10</li> <li>AnySat repo unavailable and auto-download disabled (<code>RS_EMBED_ANYSAT_AUTO_DOWNLOAD_REPO=0</code>)</li> <li>local checkpoint missing / too small / invalid format</li> <li>inconsistent results from untracked changes to <code>FRAMES</code>, <code>NORM</code>, or image size</li> </ul> <p>Recommended first check:</p> <ul> <li>Inspect input patches and confirm temporal window/frame construction is what you intended.</li> </ul>"},{"location":"models/anysat/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>For fair comparisons and stable reruns, record:</p> <ul> <li>temporal window (<code>TemporalSpec.range(...)</code>)</li> <li><code>RS_EMBED_ANYSAT_FRAMES</code></li> <li><code>RS_EMBED_ANYSAT_NORM</code></li> <li><code>RS_EMBED_ANYSAT_IMG</code></li> <li><code>output.scale_m</code> (patch size)</li> <li>AnySat repo/ckpt source (<code>repo_path</code>, repo URL/cache, pretrained vs local ckpt)</li> </ul>"},{"location":"models/anysat/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_anysat.py</code></li> <li>TCHW coercion helper: <code>src/rs_embed/embedders/runtime_utils.py</code></li> </ul>"},{"location":"models/copernicus_embed/","title":"Copernicus Embed (<code>copernicus_embed</code>)","text":"<p>Local precomputed embedding adapter using <code>torchgeo.datasets.CopernicusEmbed</code>, with bbox slicing and optional bbox expansion to improve tile overlap on small ROIs.</p>"},{"location":"models/copernicus_embed/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>copernicus_embed</code> Family / Source TorchGeo <code>CopernicusEmbed</code> dataset Adapter type <code>precomputed</code> Typical backend <code>local</code> (or <code>auto</code>) Primary input <code>BBox</code> / <code>PointBuffer</code> in EPSG:4326, sliced via TorchGeo dataset bbox indexing Temporal mode strict <code>TemporalSpec.year(2021)</code> in v0.1 Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none Training alignment (adapter path) N/A (precomputed product)"},{"location":"models/copernicus_embed/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/copernicus_embed/#good-fit-for","title":"Good fit for","text":"<ul> <li>local/offline precomputed embedding workflows via TorchGeo</li> <li>quick spatial baseline features without provider requests</li> <li>experiments where coarse precomputed coverage is acceptable</li> </ul>"},{"location":"models/copernicus_embed/#be-careful-when","title":"Be careful when","text":"<ul> <li>requesting years other than <code>2021</code> (unsupported in current adapter)</li> <li>assuming exact ROI slicing without expansion (adapter expands bbox by default)</li> <li>using non-local backends (<code>copernicus_embed</code> is local/auto only)</li> </ul>"},{"location":"models/copernicus_embed/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/copernicus_embed/#spatial","title":"Spatial","text":"<p>Accepted <code>SpatialSpec</code>:</p> <ul> <li><code>BBox</code></li> <li><code>PointBuffer</code> (converted to EPSG:4326 bbox)</li> </ul> <p>The adapter internally slices <code>CopernicusEmbed</code> with bbox indexing:</p> <ul> <li><code>ds[minlon:maxlon, minlat:maxlat]</code></li> </ul>"},{"location":"models/copernicus_embed/#temporal","title":"Temporal","text":"<ul> <li>requires <code>TemporalSpec.year(...)</code></li> <li>current adapter supports only <code>2021</code></li> <li>adapter validates the year before dataset access</li> </ul>"},{"location":"models/copernicus_embed/#backend-data-directory","title":"Backend / data directory","text":"<ul> <li>backend must be <code>local</code> or <code>auto</code></li> <li>data directory resolution:</li> <li><code>RS_EMBED_COP_DIR</code> (default <code>data/copernicus_embed</code>)</li> <li>optional per-call override via <code>sensor.collection=\"dir:/path/to/copernicus_embed\"</code></li> </ul>"},{"location":"models/copernicus_embed/#retrieval-pipeline-current-rs-embed-path","title":"Retrieval Pipeline (Current rs-embed Path)","text":"<ol> <li>Validate <code>TemporalSpec.year(...)</code> and supported year (<code>2021</code>)</li> <li>Resolve local <code>data_dir</code> (env or <code>sensor.collection</code> override)</li> <li>Load/cache TorchGeo <code>CopernicusEmbed</code> dataset (<code>download=True</code> in current adapter)</li> <li>Convert <code>SpatialSpec</code> to EPSG:4326 bbox</li> <li>Expand bbox by fixed <code>expand_deg=1.0</code> (centered) to increase tile overlap chance for small ROIs</li> <li>Slice dataset with bbox indexing and get <code>sample[\"image\"]</code> (<code>CHW</code>)</li> <li>Return pooled vector or grid</li> </ol> <p>Notes:</p> <ul> <li><code>temporal</code> is validated but metadata in current adapter is built with <code>temporal=None</code>; record the requested year externally if strict provenance matters.</li> </ul>"},{"location":"models/copernicus_embed/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_COP_DIR</code> <code>data/copernicus_embed</code> Local TorchGeo CopernicusEmbed data directory <code>RS_EMBED_COPERNICUS_BATCH_WORKERS</code> <code>4</code> Batch worker count for <code>get_embeddings_batch(...)</code> <p>Non-env override:</p> <ul> <li><code>sensor.collection=\"dir:/path/to/copernicus_embed\"</code> overrides data directory per call</li> </ul> <p>Current fixed adapter behavior (not env-configurable in v0.1):</p> <ul> <li><code>download=True</code></li> <li><code>expand_deg=1.0</code></li> </ul>"},{"location":"models/copernicus_embed/#output-semantics","title":"Output Semantics","text":""},{"location":"models/copernicus_embed/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Pools <code>CHW</code> embedding grid over spatial dims:</li> <li><code>mean</code> -&gt; <code>mean_hw</code></li> <li><code>max</code> -&gt; <code>max_hw</code></li> </ul>"},{"location":"models/copernicus_embed/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Returns TorchGeo sample embedding tensor as <code>xarray.DataArray</code> <code>(D,H,W)</code></li> <li>Grid is precomputed product space (dataset slice), not raw imagery pixels</li> </ul>"},{"location":"models/copernicus_embed/#examples","title":"Examples","text":""},{"location":"models/copernicus_embed/#minimal-local-example","title":"Minimal local example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"copernicus_embed\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=5000),\n    temporal=TemporalSpec.year(2021),\n    output=OutputSpec.pooled(),\n    backend=\"local\",\n)\n</code></pre>"},{"location":"models/copernicus_embed/#local-dataset-directory-override","title":"Local dataset directory override","text":"<pre><code># Example (shell):\n# export RS_EMBED_COP_DIR=/data/copernicus_embed\n</code></pre>"},{"location":"models/copernicus_embed/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>year not supported (<code>2021</code> only in current adapter)</li> <li>backend is not <code>local</code>/<code>auto</code></li> <li>missing <code>torchgeo</code> dependency</li> <li>dataset files missing/corrupt under <code>RS_EMBED_COP_DIR</code></li> <li>small ROI misses coverage even after expansion (returns dataset slicing issues)</li> </ul> <p>Recommended first checks:</p> <ul> <li>confirm <code>TemporalSpec.year(2021)</code></li> <li>inspect metadata <code>data_dir</code>, <code>expand_deg</code>, <code>chw_shape</code>, <code>bbox_4326</code></li> <li>test a larger ROI if coverage seems empty</li> </ul>"},{"location":"models/copernicus_embed/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li>local dataset path/version snapshot</li> <li>requested year (must be <code>2021</code>)</li> <li>ROI geometry</li> <li>output mode / pooling choice</li> </ul>"},{"location":"models/copernicus_embed/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/precomputed_copernicus_embed.py</code></li> </ul>"},{"location":"models/dofa/","title":"DOFA (<code>dofa</code>)","text":"<p>TorchGeo DOFA adapter for multispectral inputs with explicit per-channel wavelengths, supporting provider and tensor backends.</p>"},{"location":"models/dofa/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>dofa</code> Family / Backbone TorchGeo DOFA (<code>dofa_base_patch16_224</code> / <code>dofa_large_patch16_224</code>) Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>), also supports <code>backend=\"tensor\"</code> Primary input Multiband SR CHW + wavelengths (\u00b5m) Temporal mode provider path requires <code>TemporalSpec.range(...)</code> Output modes <code>pooled</code>, <code>grid</code> Extra side inputs required wavelength vector (<code>wavelengths_um</code>) Training alignment (adapter path) Medium-High (when wavelengths and band semantics are correct)"},{"location":"models/dofa/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/dofa/#good-fit-for","title":"Good fit for","text":"<ul> <li>multispectral experiments where wavelength-aware modeling matters</li> <li>custom sensor/band combinations (if you provide matching wavelengths)</li> <li>comparing spectral models against S2-specific models</li> </ul>"},{"location":"models/dofa/#be-careful-when","title":"Be careful when","text":"<ul> <li>wavelengths are missing or mismatched with channels</li> <li>assuming arbitrary bands can be inferred automatically (only known sets like S2 are inferable)</li> <li>comparing results without logging <code>variant</code> and wavelengths used</li> </ul>"},{"location":"models/dofa/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/dofa/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li>Provider path requires <code>TemporalSpec.range(start, end)</code></li> <li>Tensor path does not use provider/temporal fetch semantics</li> </ul>"},{"location":"models/dofa/#sensor-channels-provider-path","title":"Sensor / channels (provider path)","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: S2 SR 12-band set (<code>B1,B2,B3,B4,B5,B6,B7,B8,B8A,B9,B11,B12</code>)</li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code>, <code>fill_value=0.0</code></li> </ul> <p>Wavelengths:</p> <ul> <li>Adapter requires one wavelength (\u00b5m) per channel</li> <li>If <code>sensor.wavelengths</code> is not provided, adapter tries to infer from <code>sensor.bands</code> (works for recognized S2 band names)</li> <li><code>len(wavelengths_um)</code> must equal channel count <code>C</code></li> </ul> <p><code>input_chw</code> contract (provider override path):</p> <ul> <li>must be <code>CHW</code> with <code>C == len(bands)</code></li> <li>raw SR values expected (<code>0..10000</code>), adapter converts to <code>[0,1]</code></li> </ul>"},{"location":"models/dofa/#tensor-backend-contract","title":"Tensor backend contract","text":"<ul> <li><code>backend=\"tensor\"</code> requires <code>sensor.data</code> as <code>CHW</code> or <code>BCHW</code></li> <li>current v0.1 tensor backend expects <code>B=1</code> for <code>BCHW</code></li> <li><code>sensor.wavelengths</code> should be provided, or <code>sensor.bands</code> must allow wavelength inference</li> </ul>"},{"location":"models/dofa/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":""},{"location":"models/dofa/#provider-path","title":"Provider path","text":"<ol> <li>Fetch multiband SR patch and scale to <code>[0,1]</code></li> <li>Optional input inspection (<code>expected_channels=len(bands)</code>, value range <code>[0,1]</code>)</li> <li>Resize to fixed <code>224x224</code> (bilinear; no crop/pad)</li> <li>Load DOFA model variant (<code>base</code> / <code>large</code>)</li> <li>Forward with image tensor + wavelength vector</li> <li>Return pooled embedding or reshape tokens to patch-token grid</li> </ol>"},{"location":"models/dofa/#tensor-path","title":"Tensor path","text":"<ol> <li>Read <code>sensor.data</code> (CHW/BCHW, <code>B=1</code> if BCHW)</li> <li>Resize to <code>224x224</code></li> <li>Resolve wavelengths from <code>sensor.wavelengths</code> or infer from <code>sensor.bands</code></li> <li>Forward DOFA with image + wavelengths</li> </ol> <p>Fixed adapter behavior:</p> <ul> <li>image size fixed to <code>224</code> in current implementation</li> </ul>"},{"location":"models/dofa/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_DOFA_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs <code>RS_EMBED_DOFA_BATCH_SIZE</code> CPU:<code>8</code>, CUDA:<code>64</code> Inference batch size for batch APIs <p>Non-env model selection knobs (passed via <code>sensor</code> fields in current adapter path):</p> <ul> <li><code>sensor.variant</code>: <code>base</code> / <code>large</code></li> <li><code>sensor.bands</code>: channel semantics for provider fetch and wavelength inference</li> <li><code>sensor.wavelengths</code>: explicit wavelength vector (\u00b5m)</li> </ul>"},{"location":"models/dofa/#output-semantics","title":"Output Semantics","text":""},{"location":"models/dofa/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Returns DOFA pooled vector <code>(D,)</code></li> <li>Metadata includes wavelength vector, variant, preprocess strategy, token metadata</li> </ul>"},{"location":"models/dofa/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Reshapes DOFA patch tokens to <code>xarray.DataArray</code> <code>(D,H,W)</code> (usually square token grid)</li> <li>Requires token count to be a perfect square</li> <li>Grid is ViT patch-token layout, not georeferenced raster pixels</li> </ul>"},{"location":"models/dofa/#examples","title":"Examples","text":""},{"location":"models/dofa/#minimal-provider-backed-example-s2-wavelengths-inferred-automatically","title":"Minimal provider-backed example (S2 wavelengths inferred automatically)","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"dofa\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/dofa/#custom-bands-wavelengths-example-conceptual","title":"Custom bands / wavelengths example (conceptual)","text":"<pre><code>from rs_embed import SensorSpec\n\nsensor = SensorSpec(\n    collection=\"COPERNICUS/S2_SR_HARMONIZED\",\n    bands=(\"B2\", \"B3\", \"B4\", \"B8\"),\n    scale_m=10,\n)\n# If bands are non-standard, provide wavelengths explicitly via an extended sensor object/field used by your code path.\n</code></pre>"},{"location":"models/dofa/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>provider path called with non-<code>range</code> temporal spec</li> <li>wavelength vector missing or wrong length for channel count</li> <li>unsupported band names for automatic wavelength inference</li> <li>tensor backend with <code>BCHW</code> and <code>B != 1</code></li> <li>unknown <code>variant</code> (must be <code>base</code> or <code>large</code>)</li> </ul> <p>Recommended first checks:</p> <ul> <li>print/log <code>bands</code> and <code>wavelengths_um</code> used by the adapter</li> <li>verify provider input is scaled/ordered as expected before forward pass</li> </ul>"},{"location":"models/dofa/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li><code>variant</code> (<code>base</code> vs <code>large</code>)</li> <li>exact <code>bands</code> and <code>wavelengths_um</code></li> <li>temporal window and compositing (provider path)</li> <li>output mode (<code>pooled</code> vs <code>grid</code>)</li> <li>whether backend is <code>provider</code> or <code>tensor</code></li> </ul>"},{"location":"models/dofa/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_dofa.py</code></li> <li>Wavelength inference map: <code>src/rs_embed/embedders/onthefly_dofa.py</code></li> </ul>"},{"location":"models/dynamicvis/","title":"DynamicVis (<code>dynamicvis</code>)","text":"<p>Sentinel-2 RGB on-the-fly adapter for DynamicVis, loading the official DynamicVis backbone from upstream code + Hugging Face checkpoint and returning last-stage feature maps as pooled/grid embeddings.</p>"},{"location":"models/dynamicvis/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>dynamicvis</code> Family / Backbone DynamicVis <code>DynamicVisBackbone</code> (official repo code) Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>) Primary input S2 RGB (<code>B4,B3,B2</code>) Temporal mode <code>range</code> in practice (normalized via shared helper) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none (but backbone config knobs are exposed via env) Training alignment (adapter path) Medium-High when checkpoint + DynamicVis repo/runtime deps match expected upstream environment"},{"location":"models/dynamicvis/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/dynamicvis/#good-fit-for","title":"Good fit for","text":"<ul> <li>RGB experiments where you want a non-ViT feature-map backbone path</li> <li>larger input-size runs (<code>512</code> default) with dense feature maps</li> <li>comparisons against other RGB models using feature-map pooling instead of token pooling</li> </ul>"},{"location":"models/dynamicvis/#be-careful-when","title":"Be careful when","text":"<ul> <li>OpenMMLab runtime deps (<code>mmengine</code>, <code>mmcv</code>) are not installed</li> <li>assuming <code>grid</code> is token grid (here it is last-stage feature map grid)</li> <li>changing <code>arch/path_type/sampling_scale</code> without recording them</li> </ul>"},{"location":"models/dynamicvis/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/dynamicvis/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li>Provider backend only (<code>backend=\"gee\"</code> / provider-compatible backend)</li> <li><code>TemporalSpec</code> normalized via shared helper; use <code>TemporalSpec.range(...)</code> for reproducibility</li> <li>Temporal window is used for compositing/filtering</li> </ul>"},{"location":"models/dynamicvis/#sensor-channels","title":"Sensor / channels","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: <code>(\"B4\", \"B3\", \"B2\")</code></li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>must be <code>CHW</code> with 3 bands in <code>(B4,B3,B2)</code> order</li> <li>expected raw S2 SR values in <code>0..10000</code></li> <li>adapter converts to <code>[0,1]</code> then <code>uint8</code> RGB before ImageNet normalization</li> </ul>"},{"location":"models/dynamicvis/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Fetch S2 RGB patch as <code>uint8</code> (provider path) or convert <code>input_chw</code> raw SR -&gt; <code>[0,1]</code> -&gt; <code>uint8</code></li> <li>Resize to <code>RS_EMBED_DYNAMICVIS_IMG</code> (default <code>512</code>)</li> <li>Convert to tensor with ImageNet normalization (mean/std)</li> <li>Load DynamicVis backbone from:</li> <li>DynamicVis repo code (installed / local path / auto-clone)</li> <li>Hugging Face checkpoint (<code>hf_repo</code> + <code>ckpt_file</code>)</li> <li>Forward backbone and extract last returned feature tensor</li> <li>Adapter normalizes output:</li> <li>if feature map <code>[B,C,H,W]</code>: use last-stage feature map</li> <li>if vector-like <code>[B,D]</code>: convert to <code>1x1</code> feature map</li> <li>Return pooled vector or grid</li> </ol>"},{"location":"models/dynamicvis/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":""},{"location":"models/dynamicvis/#backbone-checkpoint-repo-loading","title":"Backbone / checkpoint / repo loading","text":"Env var Default Effect <code>RS_EMBED_DYNAMICVIS_HF_REPO</code> <code>KyanChen/DynamicVis</code> HF repo for checkpoint download <code>RS_EMBED_DYNAMICVIS_CKPT_FILE</code> upstream default ckpt filename Checkpoint file in HF repo <code>RS_EMBED_DYNAMICVIS_REPO_PATH</code> unset Local DynamicVis repo path <code>RS_EMBED_DYNAMICVIS_REPO_URL</code> upstream GitHub URL Repo clone source <code>RS_EMBED_DYNAMICVIS_REPO_CACHE</code> <code>~/.cache/rs_embed/dynamicvis</code> Repo cache root <code>RS_EMBED_DYNAMICVIS_AUTO_DOWNLOAD_REPO</code> <code>1</code> Auto-clone DynamicVis repo when missing"},{"location":"models/dynamicvis/#modelruntime-settings","title":"Model/runtime settings","text":"Env var Default Effect <code>RS_EMBED_DYNAMICVIS_IMG</code> <code>512</code> Resize target image size <code>RS_EMBED_DYNAMICVIS_ARCH</code> <code>auto</code> Backbone arch hint (<code>b/base</code> or <code>l/large</code>; auto infers from ckpt filename) <code>RS_EMBED_DYNAMICVIS_PATH_TYPE</code> <code>forward_reverse_mean</code> DynamicVis backbone path type <code>RS_EMBED_DYNAMICVIS_SAMPLING_SCALE</code> <code>0.1</code> Sampling scale parameter <code>RS_EMBED_DYNAMICVIS_MAMBA2</code> <code>0</code> Enable Mamba2 variant flag <code>RS_EMBED_DYNAMICVIS_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs <p>Related cache envs (used by HF download path):</p> <ul> <li><code>HUGGINGFACE_HUB_CACHE</code>, <code>HF_HOME</code>, <code>HUGGINGFACE_HOME</code></li> </ul>"},{"location":"models/dynamicvis/#output-semantics","title":"Output Semantics","text":""},{"location":"models/dynamicvis/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Pools the last-stage feature map spatially:</li> <li><code>mean</code> -&gt; <code>featmap_mean</code></li> <li><code>max</code> -&gt; <code>featmap_max</code></li> <li>Not token pooling</li> </ul>"},{"location":"models/dynamicvis/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Returns last-stage backbone feature map as <code>xarray.DataArray</code> <code>(D,H,W)</code></li> <li>Metadata marks <code>grid_kind=\"last_stage_featmap\"</code></li> <li>Grid is model feature-map layout, not georeferenced raster pixels</li> </ul>"},{"location":"models/dynamicvis/#examples","title":"Examples","text":""},{"location":"models/dynamicvis/#minimal-provider-backed-example","title":"Minimal provider-backed example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"dynamicvis\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/dynamicvis/#example-backbone-tuning-env-controlled","title":"Example backbone tuning (env-controlled)","text":"<pre><code># Example (shell):\n# export RS_EMBED_DYNAMICVIS_IMG=512\n# export RS_EMBED_DYNAMICVIS_ARCH=b\n# export RS_EMBED_DYNAMICVIS_PATH_TYPE=forward_reverse_mean\n# export RS_EMBED_DYNAMICVIS_SAMPLING_SCALE=0.1\n</code></pre>"},{"location":"models/dynamicvis/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>missing OpenMMLab runtime deps (<code>mmengine</code>, <code>mmcv</code>)</li> <li>DynamicVis repo import failures (repo present but dependencies missing)</li> <li>HF checkpoint download issues / invalid checkpoint file</li> <li>wrong <code>input_chw</code> shape (<code>CHW</code>, <code>C=3</code>)</li> <li>confusion between feature-map grid and token grid semantics</li> </ul> <p>Recommended first checks:</p> <ul> <li>inspect metadata: <code>arch</code>, <code>path_type</code>, <code>sampling_scale</code>, <code>mamba2</code>, <code>feature_kind</code></li> <li>verify repo path and checkpoint source</li> <li>start with <code>OutputSpec.pooled()</code> before debugging grid shape differences</li> </ul>"},{"location":"models/dynamicvis/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li>HF checkpoint repo/file</li> <li>DynamicVis repo source/path (or commit if using local clone)</li> <li><code>IMG</code>, <code>ARCH</code>, <code>PATH_TYPE</code>, <code>SAMPLING_SCALE</code>, <code>MAMBA2</code></li> <li>temporal window + compositing settings</li> <li>output mode and pooling choice</li> </ul>"},{"location":"models/dynamicvis/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_dynamicvis.py</code></li> </ul>"},{"location":"models/fomo/","title":"FoMo (<code>fomo</code>)","text":"<p>Multispectral Sentinel-2 adapter for FoMo-Bench (MultiSpectralViT), with explicit S2 modality-key mapping and token/grid outputs averaged across spectral modalities.</p>"},{"location":"models/fomo/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>fomo</code> Family / Backbone FoMo-Bench <code>MultiSpectralViT</code> (repo + checkpoint loader) Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>) Primary input S2 SR 12-band (<code>B1,B2,B3,B4,B5,B6,B7,B8,B8A,B9,B11,B12</code>) Temporal mode <code>range</code> in practice (normalized via shared helper) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs required modality keys (adapter provides S2 defaults, configurable via env) Training alignment (adapter path) Medium-High when <code>S2_KEYS</code>, normalization, and model config match checkpoint assumptions"},{"location":"models/fomo/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/fomo/#good-fit-for","title":"Good fit for","text":"<ul> <li>strict multispectral S2 experiments with spectral-token modeling</li> <li>testing modality-aware token layouts beyond plain ViT RGB pipelines</li> <li>analyses where spectral-token averaging into a spatial grid is acceptable</li> </ul>"},{"location":"models/fomo/#be-careful-when","title":"Be careful when","text":"<ul> <li>changing <code>RS_EMBED_FOMO_S2_KEYS</code> without understanding FoMo modality indexing</li> <li>comparing to raster-like models and treating FoMo grid as georeferenced pixels</li> <li>modifying model architecture envs (<code>DIM/DEPTH/HEADS/...</code>) while using incompatible checkpoints</li> </ul>"},{"location":"models/fomo/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/fomo/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li>Provider backend only (<code>backend=\"gee\"</code> / provider-compatible backend)</li> <li><code>TemporalSpec</code> normalized via shared helper; use <code>TemporalSpec.range(...)</code></li> </ul>"},{"location":"models/fomo/#sensor-channels","title":"Sensor / channels","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: <code>B1,B2,B3,B4,B5,B6,B7,B8,B8A,B9,B11,B12</code></li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code>, <code>fill_value=0.0</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>must be <code>CHW</code> with <code>C=12</code> in the adapter S2 band order above</li> <li>expected raw S2 SR values in <code>0..10000</code></li> </ul>"},{"location":"models/fomo/#modality-keys","title":"Modality keys","text":"<ul> <li>FoMo forward path requires a list of modality keys for each channel</li> <li>adapter default S2 mapping is encoded via <code>_DEFAULT_S2_MODALITY_KEYS</code></li> <li>override with <code>RS_EMBED_FOMO_S2_KEYS</code> (must provide exactly 12 comma-separated integers)</li> </ul>"},{"location":"models/fomo/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Fetch S2 SR 12-band patch (provider path) or use <code>input_chw</code></li> <li>Normalize with <code>RS_EMBED_FOMO_NORM</code>:</li> <li><code>unit_scale</code> (default): divide by <code>10000</code></li> <li><code>per_tile_minmax</code>: per-channel tile min-max after unit scaling</li> <li><code>none</code> / <code>raw</code>: keep raw <code>0..10000</code> (clipped)</li> <li>Resize to <code>RS_EMBED_FOMO_IMG</code> (default <code>64</code>)</li> <li>Build/load FoMo model from:</li> <li>FoMo-Bench repo code (local / auto-clone)</li> <li>checkpoint (local / auto-download)</li> <li>Forward with <code>(x, spectral_keys)</code> and <code>pool=False</code> to get tokens <code>[N,D]</code></li> <li>Compute outputs:</li> <li>pooled vector: mean/max over all tokens</li> <li>grid: average tokens across modalities and reshape patch grid when possible</li> <li>fallback: <code>1x1</code> vector grid if token layout is not grid-compatible</li> </ol>"},{"location":"models/fomo/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":""},{"location":"models/fomo/#core-model-preprocessing","title":"Core model / preprocessing","text":"Env var Default Effect <code>RS_EMBED_FOMO_IMG</code> <code>64</code> Resize target image size <code>RS_EMBED_FOMO_PATCH</code> <code>16</code> Patch size (used for model config + grid expectations) <code>RS_EMBED_FOMO_NORM</code> <code>unit_scale</code> <code>unit_scale</code>, <code>per_tile_minmax</code>, or <code>none</code> <code>RS_EMBED_FOMO_S2_KEYS</code> adapter S2 default mapping 12 comma-separated modality keys <code>RS_EMBED_FOMO_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs"},{"location":"models/fomo/#fomo-model-config-advanced-keep-aligned-with-checkpoint","title":"FoMo model config (advanced; keep aligned with checkpoint)","text":"Env var Default Effect <code>RS_EMBED_FOMO_DIM</code> <code>768</code> Model dim <code>RS_EMBED_FOMO_DEPTH</code> <code>12</code> Transformer depth <code>RS_EMBED_FOMO_HEADS</code> <code>12</code> Attention heads <code>RS_EMBED_FOMO_MLP_DIM</code> <code>2048</code> MLP dim <code>RS_EMBED_FOMO_NUM_CLASSES</code> <code>1000</code> Class head size (config compatibility)"},{"location":"models/fomo/#checkpoint-repo-loading","title":"Checkpoint / repo loading","text":"Env var Default Effect <code>RS_EMBED_FOMO_CKPT</code> unset Local checkpoint path <code>RS_EMBED_FOMO_AUTO_DOWNLOAD</code> <code>1</code> Allow checkpoint auto-download <code>RS_EMBED_FOMO_CACHE_DIR</code> repo cache default Checkpoint cache dir <code>RS_EMBED_FOMO_CKPT_FILE</code> default FoMo checkpoint filename Cached ckpt filename <code>RS_EMBED_FOMO_CKPT_URL</code> default Dropbox URL Checkpoint download URL <code>RS_EMBED_FOMO_CKPT_MIN_BYTES</code> adapter threshold Download size sanity check <code>RS_EMBED_FOMO_REPO_PATH</code> unset Local FoMo-Bench repo path <code>RS_EMBED_FOMO_REPO_URL</code> FoMo-Bench GitHub URL Repo clone source <code>RS_EMBED_FOMO_REPO_CACHE</code> <code>~/.cache/rs_embed/fomo</code> Repo cache root <code>RS_EMBED_FOMO_AUTO_DOWNLOAD_REPO</code> <code>1</code> Auto-clone FoMo-Bench repo"},{"location":"models/fomo/#output-semantics","title":"Output Semantics","text":""},{"location":"models/fomo/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Pools FoMo token sequence across tokens:</li> <li><code>mean</code> -&gt; <code>token_mean</code></li> <li><code>max</code> -&gt; <code>token_max</code></li> <li>Metadata records <code>token_count</code>, <code>token_dim</code>, and pooling mode</li> </ul>"},{"location":"models/fomo/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Preferred path:</li> <li>interpret tokens as <code>[modalities, H, W, D]</code></li> <li>average over modalities</li> <li>return <code>(D,H,W)</code> grid with <code>grid_kind=\"spectral_mean_patch_tokens\"</code></li> <li>Fallback path:</li> <li>if token layout is incompatible with expected modality/grid layout, return <code>1x1</code> vector grid (<code>grid_kind=\"vector_as_1x1\"</code>)</li> </ul> <p>Grid is model token-derived structure, not georeferenced raster pixels.</p>"},{"location":"models/fomo/#examples","title":"Examples","text":""},{"location":"models/fomo/#minimal-provider-backed-example","title":"Minimal provider-backed example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"fomo\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/fomo/#example-fomo-tuning-env-controlled","title":"Example FoMo tuning (env-controlled)","text":"<pre><code># Example (shell):\n# export RS_EMBED_FOMO_IMG=64\n# export RS_EMBED_FOMO_PATCH=16\n# export RS_EMBED_FOMO_NORM=unit_scale\n# export RS_EMBED_FOMO_S2_KEYS=6,7,8,9,10,11,12,13,14,15,17,18\n</code></pre>"},{"location":"models/fomo/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>backend mismatch (<code>fomo</code> is provider-only)</li> <li>wrong <code>input_chw</code> shape (<code>C</code> must be <code>12</code>)</li> <li><code>RS_EMBED_FOMO_S2_KEYS</code> length mismatch (must be 12 values)</li> <li>checkpoint/repo download/import failures</li> <li>changed model config envs incompatible with checkpoint architecture</li> <li>grid returns <code>1x1</code> fallback because token layout is not modality-grid compatible</li> </ul> <p>Recommended first checks:</p> <ul> <li>inspect metadata <code>spectral_keys</code>, <code>token_count</code>, <code>grid_kind</code>, <code>grid_expected_tokens</code></li> <li>revert architecture envs to defaults before benchmarking</li> <li>verify normalization mode and image/patch sizes</li> </ul>"},{"location":"models/fomo/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li>checkpoint source/path and FoMo-Bench repo source/path</li> <li><code>IMG</code>, <code>PATCH</code>, normalization mode</li> <li><code>S2_KEYS</code> mapping</li> <li>model config envs (<code>DIM/DEPTH/HEADS/MLP_DIM/NUM_CLASSES</code>)</li> <li>temporal window + compositing settings</li> </ul>"},{"location":"models/fomo/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_fomo.py</code></li> </ul>"},{"location":"models/galileo/","title":"Galileo (<code>galileo</code>)","text":"<p>Multi-frame Sentinel-2 adapter that constructs Galileo encoder inputs (including <code>months</code>) from a temporal window and returns pooled vectors or S2-group patch-token grids.</p>"},{"location":"models/galileo/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>galileo</code> Family / Backbone Galileo <code>Encoder</code> from official <code>single_file_galileo.py</code> Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code> via public API) Primary input S2 10-band time series (<code>T,C,H,W</code>) Temporal mode <code>range</code> in practice (adapter normalizes via shared helper) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs required <code>months</code> (per-frame month tokens), plus Galileo masks/tensors built by adapter Training alignment (adapter path) Medium (depends on <code>FRAMES</code>, <code>IMG</code>, <code>PATCH</code>, normalization, NDVI inclusion)"},{"location":"models/galileo/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/galileo/#good-fit-for","title":"Good fit for","text":"<ul> <li>temporal S2 sequence modeling with explicit month tokens</li> <li>comparisons against other multi-frame adapters (<code>anysat</code>, <code>agrifm</code>)</li> <li>feature-grid analysis over Galileo S2-related token groups</li> </ul>"},{"location":"models/galileo/#be-careful-when","title":"Be careful when","text":"<ul> <li>comparing to single-composite models without matching temporal assumptions</li> <li>changing <code>image_size</code> / <code>patch_size</code> inconsistently (<code>image_size</code> must divide by <code>patch_size</code>)</li> <li>changing month handling (<code>RS_EMBED_GALILEO_MONTH</code>) without documenting it</li> </ul>"},{"location":"models/galileo/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/galileo/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li><code>SpatialSpec</code>: <code>BBox</code> or <code>PointBuffer</code></li> <li><code>TemporalSpec</code>: normalized to range via shared helper (<code>range</code> recommended for reproducibility)</li> <li>Adapter builds <code>T</code> frames by splitting the temporal window into equal sub-windows and compositing each frame</li> <li>Month side input:</li> <li>default: derived from frame-bin midpoints</li> <li>optional override: <code>RS_EMBED_GALILEO_MONTH</code> (constant month for all frames)</li> </ul>"},{"location":"models/galileo/#sensor-channels","title":"Sensor / channels","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: 10-band S2 set used by adapter (<code>B2,B3,B4,B5,B6,B7,B8,B8A,B11,B12</code>)</li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code>, <code>fill_value=0.0</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>accepts <code>CHW</code> (<code>C=10</code>) or <code>TCHW</code> (<code>C=10</code>) through shared coercion helper</li> <li><code>CHW</code> repeats to <code>T</code>; <code>TCHW</code> pads/truncates to exact <code>T</code></li> <li>values are clipped to raw-SR range <code>0..10000</code></li> </ul>"},{"location":"models/galileo/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Fetch S2 10-band <code>raw_tchw</code> or coerce user <code>input_chw</code> to <code>TCHW</code></li> <li>Resolve months sequence from frame bins (or <code>RS_EMBED_GALILEO_MONTH</code>)</li> <li>Resize frames to <code>RS_EMBED_GALILEO_IMG</code> (default <code>64</code>) if needed</li> <li>Normalize S2 series with <code>RS_EMBED_GALILEO_NORM</code> (default <code>unit_scale</code>)</li> <li>Build Galileo encoder tensors and masks:</li> <li><code>s_t_x</code>, <code>sp_x</code>, <code>t_x</code>, <code>st_x</code></li> <li>masks <code>s_t_m</code>, <code>sp_m</code>, <code>t_m</code>, <code>st_m</code></li> <li><code>months</code></li> <li>Optional NDVI channel injection when <code>RS_EMBED_GALILEO_INCLUDE_NDVI=1</code> and model space supports NDVI</li> <li>Forward Galileo encoder (<code>patch_size=RS_EMBED_GALILEO_PATCH</code>, default <code>8</code>)</li> <li>Outputs:</li> <li>pooled vector from visible tokens (<code>encoder.average_tokens(...)</code>)</li> <li>grid from S2-related space-time groups, averaged over time/group dimensions</li> </ol> <p>Constraint:</p> <ul> <li><code>image_size % patch_size == 0</code> is required</li> </ul>"},{"location":"models/galileo/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_GALILEO_MODEL_SIZE</code> <code>nano</code> Galileo model size selector <code>RS_EMBED_GALILEO_MODEL_PATH</code> unset Local model/checkpoint path override <code>RS_EMBED_GALILEO_REPO_PATH</code> unset Local Galileo repo path <code>RS_EMBED_GALILEO_REPO_URL</code> upstream Galileo repo Repo clone source <code>RS_EMBED_GALILEO_REPO_CACHE</code> <code>~/.cache/rs_embed/galileo</code> Repo cache root <code>RS_EMBED_GALILEO_AUTO_DOWNLOAD_REPO</code> <code>1</code> Auto-clone repo if missing <code>RS_EMBED_GALILEO_IMG</code> <code>64</code> Frame resize target <code>RS_EMBED_GALILEO_PATCH</code> <code>8</code> Encoder patch size <code>RS_EMBED_GALILEO_FRAMES</code> <code>8</code> Number of temporal frames <code>T</code> <code>RS_EMBED_GALILEO_NORM</code> <code>unit_scale</code> S2 normalization mode <code>RS_EMBED_GALILEO_ADD_LN</code> <code>1</code> Add layer norm on encoder exit <code>RS_EMBED_GALILEO_INCLUDE_NDVI</code> <code>1</code> Include NDVI channel when supported <code>RS_EMBED_GALILEO_MONTH</code> unset Force a constant month (1..12) for all frames <code>RS_EMBED_GALILEO_FETCH_WORKERS</code> <code>8</code> Prefetch workers for batch APIs"},{"location":"models/galileo/#output-semantics","title":"Output Semantics","text":""},{"location":"models/galileo/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Default pooled path uses Galileo pooled token output (<code>token_mean</code> semantics in metadata)</li> <li>If <code>OutputSpec.pooling=\"max\"</code>, adapter max-pools the produced grid instead (<code>grid_max</code>)</li> </ul>"},{"location":"models/galileo/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Returns S2-related Galileo space-time-group patch tokens as <code>xarray.DataArray</code> <code>(D,H,W)</code></li> <li>Grid is produced by selecting S2 groups and averaging over time + channel-group axes</li> <li>This is model token structure, not georeferenced raster pixels</li> </ul>"},{"location":"models/galileo/#examples","title":"Examples","text":""},{"location":"models/galileo/#minimal-example","title":"Minimal example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"galileo\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-01-01\", \"2023-01-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/galileo/#example-tuning-temporal-packaging-env-controlled","title":"Example tuning temporal packaging (env-controlled)","text":"<pre><code># Example (shell):\n# export RS_EMBED_GALILEO_FRAMES=8\n# export RS_EMBED_GALILEO_IMG=64\n# export RS_EMBED_GALILEO_PATCH=8\n# export RS_EMBED_GALILEO_NORM=unit_scale\n# export RS_EMBED_GALILEO_INCLUDE_NDVI=1\n</code></pre>"},{"location":"models/galileo/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>backend is not provider-compatible</li> <li><code>image_size</code> not divisible by <code>patch_size</code></li> <li>wrong <code>input_chw</code> channel count (must be 10)</li> <li>unexpected effects from <code>RS_EMBED_GALILEO_MONTH</code> forcing a constant month</li> <li>missing local repo/model path when auto-download is disabled</li> </ul> <p>Recommended first checks:</p> <ul> <li>verify temporal window/frame count and month sequence in metadata</li> <li>inspect raw inputs before changing normalization or model settings</li> </ul>"},{"location":"models/galileo/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Record and keep fixed:</p> <ul> <li>temporal window and <code>RS_EMBED_GALILEO_FRAMES</code></li> <li><code>RS_EMBED_GALILEO_IMG</code>, <code>RS_EMBED_GALILEO_PATCH</code></li> <li>normalization mode / NDVI inclusion</li> <li>month override (if any)</li> <li>model source (repo/model path, model size)</li> </ul>"},{"location":"models/galileo/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_galileo.py</code></li> <li>Shared TCHW coercion helper: <code>src/rs_embed/embedders/runtime_utils.py</code></li> </ul>"},{"location":"models/gse_annual/","title":"Google Satellite Embedding Annual (<code>gse_annual</code>)","text":"<p>Provider-backed precomputed annual embedding adapter for <code>GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL</code>, supporting pooled vectors or provider-sampled embedding grids.</p>"},{"location":"models/gse_annual/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>gse_annual</code> Family / Source Google Satellite Embedding annual product (<code>GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL</code>) Adapter type <code>precomputed</code> Typical backend provider backend (<code>gee</code>) Primary input Provider-sampled annual embedding image collection Temporal mode strict <code>TemporalSpec.year(...)</code> Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none Training alignment (adapter path) N/A (precomputed product)"},{"location":"models/gse_annual/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/gse_annual/#good-fit-for","title":"Good fit for","text":"<ul> <li>quick annual baselines from a maintained provider-hosted embedding product</li> <li>low-friction comparisons using <code>OutputSpec.pooled()</code></li> <li>workflows that want provider-based sampling (no local tile cache management)</li> </ul>"},{"location":"models/gse_annual/#be-careful-when","title":"Be careful when","text":"<ul> <li>using <code>TemporalSpec.range(...)</code> (not supported in v0.1)</li> <li>assuming native imagery semantics (this is an embedding product)</li> <li>forgetting that <code>output.scale_m</code> affects provider sampling resolution</li> </ul>"},{"location":"models/gse_annual/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/gse_annual/#backend-temporal","title":"Backend / temporal","text":"<ul> <li>provider backend only (<code>gee</code> / provider-compatible; not <code>auto</code>)</li> <li>requires <code>TemporalSpec.year(year=...)</code></li> <li>adapter validates <code>temporal.mode == \"year\"</code></li> </ul>"},{"location":"models/gse_annual/#spatial-sampling","title":"Spatial / sampling","text":"<ul> <li>accepts normal <code>SpatialSpec</code> provider sampling path</li> <li>fetches all embedding bands from annual collection using provider helper</li> <li><code>OutputSpec.scale_m</code> controls sampling scale passed to provider</li> </ul> <p>Fixed provider fetch settings in current adapter:</p> <ul> <li>collection: <code>GOOGLE/SATELLITE_EMBEDDING/V1/ANNUAL</code></li> <li><code>fill_value=-9999.0</code></li> <li><code>composite=\"mosaic\"</code></li> </ul>"},{"location":"models/gse_annual/#retrieval-pipeline-current-rs-embed-path","title":"Retrieval Pipeline (Current rs-embed Path)","text":"<ol> <li>Validate provider backend + <code>TemporalSpec.year(...)</code></li> <li>Fetch all embedding bands as <code>CHW</code> from annual collection</li> <li>Replace fill value <code>-9999</code> with <code>NaN</code></li> <li>Build metadata (year, scale, band names)</li> <li>Return:</li> <li>pooled vector via <code>pool_chw_to_vec(...)</code></li> <li>grid as <code>xarray.DataArray</code> <code>(D,H,W)</code> with <code>d</code> coords set to band names</li> </ol>"},{"location":"models/gse_annual/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_GSE_BATCH_WORKERS</code> <code>4</code> Batch worker count for <code>get_embeddings_batch(...)</code> <p>Primary non-env sampling knob:</p> <ul> <li><code>OutputSpec.scale_m</code> (passed to provider sampling)</li> </ul>"},{"location":"models/gse_annual/#output-semantics","title":"Output Semantics","text":""},{"location":"models/gse_annual/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Pools precomputed embedding grid over spatial dims using <code>OutputSpec.pooling</code></li> <li>Metadata records pooling mode (<code>mean</code> / <code>max</code>)</li> </ul>"},{"location":"models/gse_annual/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Returns provider-sampled embedding grid as <code>xarray.DataArray</code> <code>(D,H,W)</code></li> <li><code>d</code> coordinate uses product band names (not integer indices only)</li> <li>Grid is provider-sampled embedding image in product space, not raw imagery pixels</li> </ul>"},{"location":"models/gse_annual/#examples","title":"Examples","text":""},{"location":"models/gse_annual/#minimal-annual-example","title":"Minimal annual example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"gse_annual\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.year(2021),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/gse_annual/#sampling-resolution-example","title":"Sampling resolution example","text":"<pre><code>from rs_embed import OutputSpec\n\nout = OutputSpec.pooled(scale_m=30)\n</code></pre>"},{"location":"models/gse_annual/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>backend is not provider-compatible</li> <li>missing <code>TemporalSpec.year(...)</code></li> <li><code>TemporalSpec.range(...)</code> used instead of <code>year</code></li> <li>provider sampling issues / permissions (GEE auth or provider config)</li> <li>unexpected NaNs due to fill regions (<code>-9999</code> -&gt; <code>NaN</code>)</li> </ul> <p>Recommended first checks:</p> <ul> <li>inspect metadata <code>year</code>, <code>scale_m</code>, <code>bands</code></li> <li>try <code>OutputSpec.pooled()</code> first to validate access</li> <li>adjust <code>OutputSpec.scale_m</code> if sampling is too coarse/fine</li> </ul>"},{"location":"models/gse_annual/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li><code>TemporalSpec.year(...)</code></li> <li>provider backend config / auth context</li> <li><code>OutputSpec.scale_m</code></li> <li>output mode and pooling choice</li> </ul>"},{"location":"models/gse_annual/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/precomputed_gse_annual.py</code></li> </ul>"},{"location":"models/prithvi_eo_v2_s2_6b/","title":"Prithvi-EO v2 (<code>prithvi_eo_v2_s2_6b</code>)","text":"<p>TerraTorch-backed Prithvi adapter for Sentinel-2 6-band inputs, with required temporal/location coordinate side inputs derived by rs-embed.</p>"},{"location":"models/prithvi_eo_v2_s2_6b/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>prithvi_eo_v2_s2_6b</code> Family / Backbone Prithvi-EO v2 via TerraTorch <code>BACKBONE_REGISTRY</code> Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code> via public API) Primary input S2 6-band (<code>BLUE,GREEN,RED,NIR_NARROW,SWIR_1,SWIR_2</code>) Temporal mode <code>range</code> preferred; adapter normalizes <code>year</code>/<code>None</code> to a range Output modes <code>pooled</code>, <code>grid</code> Extra side inputs required temporal coords + location coords (derived by adapter) Training alignment (adapter path) Medium (depends on preprocessing mode and resize/pad choices)"},{"location":"models/prithvi_eo_v2_s2_6b/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/prithvi_eo_v2_s2_6b/#good-fit-for","title":"Good fit for","text":"<ul> <li>multispectral S2 experiments beyond RGB</li> <li>token/grid feature inspection with a ViT-like backbone</li> <li>comparisons that need explicit time + location conditioning in the forward path</li> </ul>"},{"location":"models/prithvi_eo_v2_s2_6b/#be-careful-when","title":"Be careful when","text":"<ul> <li>comparing to models without side inputs (time/location signals can change behavior)</li> <li>changing preprocessing mode (<code>resize</code> vs <code>pad</code>) without documenting it</li> <li>assuming <code>grid</code> is georeferenced pixel space (it is token grid)</li> </ul>"},{"location":"models/prithvi_eo_v2_s2_6b/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/prithvi_eo_v2_s2_6b/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li><code>SpatialSpec</code>: <code>BBox</code> or <code>PointBuffer</code></li> <li><code>TemporalSpec</code>:</li> <li><code>range</code>: used directly</li> <li><code>year</code>: normalized to full-year half-open range <code>[YYYY-01-01, (YYYY+1)-01-01)</code></li> <li><code>None</code>: normalized to adapter default range via shared helper (not recommended for reproducible experiments)</li> <li>Adapter derives:</li> <li>temporal coordinates from temporal midpoint date</li> <li>location coordinates from ROI center <code>(lon, lat)</code> in EPSG:4326</li> </ul>"},{"location":"models/prithvi_eo_v2_s2_6b/#sensor-channels","title":"Sensor / channels","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: <code>(\"BLUE\", \"GREEN\", \"RED\", \"NIR_NARROW\", \"SWIR_1\", \"SWIR_2\")</code></li> <li><code>scale_m=30</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code>, <code>fill_value=0.0</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>must be <code>CHW</code> with 6 bands (raw S2 SR values expected, <code>0..10000</code>)</li> <li>adapter normalizes to <code>[0,1]</code>, clips, and replaces non-finite values</li> </ul>"},{"location":"models/prithvi_eo_v2_s2_6b/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Fetch 6-band S2 patch from provider (or reuse <code>input_chw</code>)</li> <li>Normalize raw SR -&gt; <code>[0,1]</code> (<code>/10000</code>, clip, <code>nan_to_num</code>)</li> <li>Optional input checks and quicklook RGB export (<code>bands=(2,1,0)</code>)</li> <li>Apply Prithvi input prep (<code>_prepare_prithvi_chw</code>):</li> <li><code>resize</code> to <code>RS_EMBED_PRITHVI_IMG</code> (default <code>224</code>), or</li> <li><code>pad</code> H/W to multiple of <code>RS_EMBED_PRITHVI_PATCH_MULT</code> (default <code>16</code>)</li> <li>Compute temporal/date and location side inputs</li> <li>Forward pass to token sequence</li> <li>Convert to pooled vector or patch-token grid</li> </ol>"},{"location":"models/prithvi_eo_v2_s2_6b/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_PRITHVI_KEY</code> <code>prithvi_eo_v2_100_tl</code> TerraTorch model key <code>RS_EMBED_PRITHVI_PRETRAINED</code> <code>1</code> Use pretrained weights vs random init <code>RS_EMBED_PRITHVI_PREP</code> <code>resize</code> Input prep mode: <code>resize</code> or <code>pad</code> <code>RS_EMBED_PRITHVI_IMG</code> <code>224</code> Target square size for <code>resize</code> mode <code>RS_EMBED_PRITHVI_PATCH_MULT</code> <code>16</code> Pad multiple for <code>pad</code> mode <code>RS_EMBED_PRITHVI_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs <code>RS_EMBED_PRITHVI_BATCH_SIZE</code> CPU:<code>4</code>, CUDA:<code>16</code> Inference batch size for batch APIs"},{"location":"models/prithvi_eo_v2_s2_6b/#output-semantics","title":"Output Semantics","text":""},{"location":"models/prithvi_eo_v2_s2_6b/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Pools patch tokens using <code>mean</code>/<code>max</code> according to <code>OutputSpec.pooling</code></li> <li>CLS token is removed if present (recorded in metadata)</li> </ul>"},{"location":"models/prithvi_eo_v2_s2_6b/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Returns patch-token grid <code>(D,H,W)</code> as <code>xarray.DataArray</code></li> <li>Grid metadata includes token grid shape and whether CLS was removed</li> <li>Token grid is model-internal spatial structure, not guaranteed georeferenced raster pixels</li> </ul>"},{"location":"models/prithvi_eo_v2_s2_6b/#examples","title":"Examples","text":""},{"location":"models/prithvi_eo_v2_s2_6b/#minimal-example-explicit-temporal-window","title":"Minimal example (explicit temporal window)","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"prithvi_eo_v2_s2_6b\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/prithvi_eo_v2_s2_6b/#with-custom-preprocessing-mode-env-controlled","title":"With custom preprocessing mode (env-controlled)","text":"<pre><code># Example (shell):\n# export RS_EMBED_PRITHVI_PREP=pad\n# export RS_EMBED_PRITHVI_PATCH_MULT=16\n# export RS_EMBED_PRITHVI_PRETRAINED=1\n</code></pre>"},{"location":"models/prithvi_eo_v2_s2_6b/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>non-provider backend passed to adapter path</li> <li>wrong <code>input_chw</code> channel count (must be 6)</li> <li>missing TerraTorch/torch dependencies</li> <li>inconsistent comparisons due to hidden changes in <code>RS_EMBED_PRITHVI_PREP</code> / <code>RS_EMBED_PRITHVI_IMG</code></li> <li>confusion about <code>year</code> input semantics (adapter converts to full-year range)</li> </ul> <p>Recommended first check:</p> <ul> <li>Inspect raw fetched patch and verify 6-band order/value range before debugging model output quality.</li> </ul>"},{"location":"models/prithvi_eo_v2_s2_6b/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Document and keep fixed:</p> <ul> <li>temporal specification (prefer explicit <code>TemporalSpec.range(...)</code>)</li> <li><code>sensor.scale_m</code> (default here is <code>30</code>, unlike many S2 adapters using <code>10</code>)</li> <li>preprocessing mode (<code>resize</code> vs <code>pad</code>) and related env vars</li> <li>output mode (<code>pooled</code> vs <code>grid</code>) and pooling method</li> <li>model key / pretrained flag</li> </ul>"},{"location":"models/prithvi_eo_v2_s2_6b/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_prithvi.py</code></li> <li>Shared temporal normalization helper: <code>src/rs_embed/embedders/meta_utils.py</code></li> </ul>"},{"location":"models/remoteclip_s2rgb/","title":"RemoteCLIP (<code>remoteclip_s2rgb</code>)","text":"<p>Sentinel-2 RGB on-the-fly embedding via <code>rshf.remoteclip.RemoteCLIP</code>, with pooled vector or ViT token-grid outputs.</p>"},{"location":"models/remoteclip_s2rgb/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>remoteclip_s2rgb</code> Family / Backbone RemoteCLIP (CLIP-style ViT via <code>rshf.remoteclip.RemoteCLIP</code>) Adapter type <code>on-the-fly</code> Typical backend provider backend (public API usually <code>backend=\"gee\"</code>) Primary input S2 RGB (<code>B4,B3,B2</code>) Temporal mode <code>TemporalSpec.range(...)</code> required Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none Training alignment (adapter path) Medium (higher if wrapper <code>model.transform(...)</code> matches training pipeline; fallback is generic CLIP preprocess)"},{"location":"models/remoteclip_s2rgb/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/remoteclip_s2rgb/#good-fit-for","title":"Good fit for","text":"<ul> <li>fast RGB baselines on Sentinel-2</li> <li>CLIP-style embedding experiments and retrieval setups</li> <li>simple comparisons with <code>pooled</code> vectors across multiple models</li> </ul>"},{"location":"models/remoteclip_s2rgb/#be-careful-when","title":"Be careful when","text":"<ul> <li>you need strict multispectral semantics (RGB-only path)</li> <li>you assume <code>grid</code> is georeferenced pixels (it is a ViT token grid)</li> <li>your wrapper/model build only exposes pooled outputs (then <code>grid</code> can fail)</li> </ul>"},{"location":"models/remoteclip_s2rgb/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/remoteclip_s2rgb/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li><code>SpatialSpec</code>: <code>BBox</code> or <code>PointBuffer</code></li> <li><code>TemporalSpec</code>: must be <code>TemporalSpec.range(start, end)</code></li> <li>Temporal semantics: window filter + composite (default <code>median</code>), not single-scene selection</li> </ul>"},{"location":"models/remoteclip_s2rgb/#sensor-channels","title":"Sensor / channels","text":"<p>Default path (if <code>sensor</code> is omitted):</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: <code>(\"B4\", \"B3\", \"B2\")</code> (RGB in that order)</li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code></li> </ul> <p>Adapter notes:</p> <ul> <li><code>sensor.collection</code> can be used as a checkpoint override with <code>hf:&lt;repo_or_path&gt;</code> (for example <code>hf:MVRL/remote-clip-vit-base-patch32</code>)</li> <li><code>input_chw</code> (prefetched/raw path) must be <code>CHW</code> with exactly 3 bands in <code>(B4,B3,B2)</code> order</li> </ul>"},{"location":"models/remoteclip_s2rgb/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Fetch S2 RGB patch from provider (or reuse <code>input_chw</code>)</li> <li>Normalize raw SR values to <code>[0,1]</code> (for <code>input_chw</code>, divide by <code>10000</code> and clip)</li> <li>Optional input checks / quicklook export via <code>SensorSpec.check_*</code></li> <li>Convert <code>CHW [0,1]</code> -&gt; <code>uint8 HWC</code></li> <li>Model preprocess:</li> <li>preferred: <code>model.transform(rgb_u8, image_size)</code> if available</li> <li>fallback: <code>Resize(224) -&gt; CenterCrop(224) -&gt; ToTensor -&gt; CLIP normalization</code></li> <li>Forward pass to get tokens (preferred) or pooled vector (fallback path)</li> </ol> <p>Current adapter image size:</p> <ul> <li>fixed <code>224</code> in this adapter path</li> </ul>"},{"location":"models/remoteclip_s2rgb/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_REMOTECLIP_FETCH_WORKERS</code> <code>8</code> Provider prefetch worker count for batch APIs <code>RS_EMBED_REMOTECLIP_BATCH_SIZE</code> CPU:<code>8</code>, CUDA:<code>64</code> Inference batch size for batch APIs <code>HUGGINGFACE_HUB_CACHE</code> / <code>HF_HOME</code> / <code>HUGGINGFACE_HOME</code> unset Controls HF cache path used for model snapshot downloads <p>Checkpoint override (not env-based in this adapter):</p> <ul> <li>set <code>sensor.collection=\"hf:&lt;repo_or_local_path&gt;\"</code></li> </ul>"},{"location":"models/remoteclip_s2rgb/#output-semantics","title":"Output Semantics","text":""},{"location":"models/remoteclip_s2rgb/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Returns a vector <code>(D,)</code></li> <li>If token sequence is available, adapter mean-pools tokens (records <code>pooling=\"token_mean\"</code> in metadata)</li> <li>If wrapper only returns pooled vector, adapter returns it directly</li> </ul>"},{"location":"models/remoteclip_s2rgb/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Requires token sequence output <code>[N,D]</code></li> <li>Returns ViT token grid as <code>xarray.DataArray</code> with shape <code>(D, Ht, Wt)</code></li> <li>This is a patch-token grid, not georeferenced raster pixels</li> <li>Typical note from adapter: often <code>7x7</code> for ViT-B/32 at 224px (checkpoint-dependent)</li> </ul>"},{"location":"models/remoteclip_s2rgb/#examples","title":"Examples","text":""},{"location":"models/remoteclip_s2rgb/#minimal-example","title":"Minimal example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"remoteclip_s2rgb\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/remoteclip_s2rgb/#custom-checkpoint-via-sensorcollectionhf","title":"Custom checkpoint via <code>sensor.collection=\"hf:...\"</code>","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec, SensorSpec\n\nemb = get_embedding(\n    \"remoteclip_s2rgb\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    sensor=SensorSpec(\n        collection=\"hf:MVRL/remote-clip-vit-base-patch32\",\n        bands=(\"B4\", \"B3\", \"B2\"),\n        scale_m=10,\n        cloudy_pct=30,\n        composite=\"median\",\n    ),\n    output=OutputSpec.grid(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/remoteclip_s2rgb/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li><code>backend</code> is not a provider backend (adapter expects provider path; public API <code>\"gee\"</code> is the common choice)</li> <li><code>TemporalSpec</code> is missing or not <code>range</code></li> <li><code>input_chw</code> shape is not <code>CHW</code> with 3 channels</li> <li>missing optional dependencies (<code>rshf</code>, <code>huggingface_hub</code>, torch stack)</li> <li><code>grid</code> requested but wrapper only exposes pooled outputs / no token path</li> </ul> <p>Recommended first check:</p> <ul> <li>Use <code>inspect_provider_patch(...)</code> / <code>inspect_gee_patch(...)</code> to verify raw RGB inputs and temporal composite quality.</li> </ul>"},{"location":"models/remoteclip_s2rgb/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>For fair comparisons, keep fixed:</p> <ul> <li>same ROI and temporal window</li> <li>same <code>SensorSpec.composite</code> (<code>median</code> / <code>mosaic</code>)</li> <li>same <code>OutputSpec</code> mode (prefer <code>pooled</code> first)</li> <li>same checkpoint (<code>sensor.collection=\"hf:...\"</code> override if used)</li> <li>same preprocessing path (be aware wrapper transform vs CLIP fallback can differ)</li> </ul>"},{"location":"models/remoteclip_s2rgb/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_remoteclip.py</code></li> <li>Token/grid utilities: <code>src/rs_embed/embedders/onthefly_remoteclip.py</code> (token reshape helpers)</li> </ul>"},{"location":"models/satmae_rgb/","title":"SatMAE RGB (<code>satmae_rgb</code>)","text":"<p>Sentinel-2 RGB on-the-fly adapter for SatMAE (<code>rshf.satmae.SatMAE</code>), returning pooled vectors or ViT patch-token grids from <code>forward_encoder(mask_ratio=0.0)</code>.</p>"},{"location":"models/satmae_rgb/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>satmae_rgb</code> Family / Backbone SatMAE via <code>rshf.satmae.SatMAE</code> Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>) Primary input S2 RGB (<code>B4,B3,B2</code>) Temporal mode range window in practice (normalized via shared helper) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none Training alignment (adapter path) Medium-High (higher when wrapper <code>model.transform(...)</code> is available and used)"},{"location":"models/satmae_rgb/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/satmae_rgb/#good-fit-for","title":"Good fit for","text":"<ul> <li>strong RGB-only SatMAE baseline on Sentinel-2</li> <li>MAE-style token-grid analysis (<code>OutputSpec.grid()</code>)</li> <li>comparisons with other RGB ViT adapters (<code>remoteclip_s2rgb</code>, <code>scalemae_rgb</code>, <code>wildsat</code>)</li> </ul>"},{"location":"models/satmae_rgb/#be-careful-when","title":"Be careful when","text":"<ul> <li>you need multispectral semantics (this is RGB-only)</li> <li>assuming <code>grid</code> is georeferenced pixels (it is a patch-token grid)</li> <li>comparing runs across environments where <code>rshf</code> wrapper preprocessing behavior may differ</li> </ul>"},{"location":"models/satmae_rgb/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/satmae_rgb/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li>Provider backend only (<code>backend=\"gee\"</code> / provider-compatible backend)</li> <li><code>TemporalSpec</code> is normalized via shared helper; use <code>TemporalSpec.range(...)</code> for reproducibility</li> <li>Temporal window is used for compositing/filtering, not single-scene identity selection</li> </ul>"},{"location":"models/satmae_rgb/#sensor-channels","title":"Sensor / channels","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: <code>(\"B4\", \"B3\", \"B2\")</code></li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>must be <code>CHW</code> with exactly 3 bands in <code>(B4,B3,B2)</code> order</li> <li>expected raw S2 SR values in <code>0..10000</code></li> <li>adapter converts to <code>[0,1]</code>, then <code>uint8</code> RGB before model preprocessing</li> </ul>"},{"location":"models/satmae_rgb/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Fetch S2 RGB patch as <code>uint8</code> RGB (provider path) or convert <code>input_chw</code> raw SR -&gt; <code>[0,1]</code> -&gt; <code>uint8</code></li> <li>Resize to <code>RS_EMBED_SATMAE_IMG</code> (default <code>224</code>)</li> <li>Model preprocessing inside adapter:</li> <li>preferred: <code>model.transform(rgb_u8, image_size)</code> if wrapper exposes it</li> <li>fallback: generic CLIP-style tensor preprocessing (<code>rgb_u8_to_tensor_clipnorm</code>)</li> <li>Run <code>forward_encoder(mask_ratio=0.0)</code> to get token sequence <code>[N,D]</code></li> <li>Return:</li> <li><code>pooled</code>: patch-token pooling (<code>mean</code> / <code>max</code>)</li> <li><code>grid</code>: patch-token reshape to <code>xarray.DataArray</code></li> </ol> <p>Notes:</p> <ul> <li>Current adapter path always targets token output (not pooled wrapper outputs).</li> <li>CLS token is removed automatically when pooling / grid reshape helpers detect it.</li> </ul>"},{"location":"models/satmae_rgb/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_SATMAE_ID</code> <code>MVRL/satmae-vitlarge-fmow-pretrain-800</code> HF model ID used by <code>SatMAE.from_pretrained(...)</code> <code>RS_EMBED_SATMAE_IMG</code> <code>224</code> Resize / preprocess image size <code>RS_EMBED_SATMAE_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs <code>RS_EMBED_SATMAE_BATCH_SIZE</code> CPU:<code>8</code>, CUDA:<code>32</code> Inference batch size for batch APIs"},{"location":"models/satmae_rgb/#output-semantics","title":"Output Semantics","text":""},{"location":"models/satmae_rgb/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Pools SatMAE patch tokens using <code>OutputSpec.pooling</code></li> <li>Metadata records <code>pooling=\"patch_mean\"</code> or <code>patch_max</code>, plus <code>cls_removed</code></li> </ul>"},{"location":"models/satmae_rgb/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Reshapes SatMAE token sequence <code>[N,D]</code> to <code>xarray.DataArray</code> <code>(D,H,W)</code></li> <li>Grid is ViT patch-token layout, not georeferenced raster pixels</li> </ul>"},{"location":"models/satmae_rgb/#examples","title":"Examples","text":""},{"location":"models/satmae_rgb/#minimal-provider-backed-example","title":"Minimal provider-backed example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"satmae_rgb\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/satmae_rgb/#example-modelimage-size-tuning-env-controlled","title":"Example model/image-size tuning (env-controlled)","text":"<pre><code># Example (shell):\n# export RS_EMBED_SATMAE_ID=MVRL/satmae-vitlarge-fmow-pretrain-800\n# export RS_EMBED_SATMAE_IMG=224\n</code></pre>"},{"location":"models/satmae_rgb/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>backend mismatch (<code>satmae_rgb</code> is provider-only)</li> <li>wrong <code>input_chw</code> shape or band order (must be <code>CHW</code>, <code>C=3</code>, <code>(B4,B3,B2)</code>)</li> <li>missing <code>rshf</code> / incompatible <code>rshf</code> version (no <code>SatMAE</code> wrapper or <code>forward_encoder</code>)</li> <li><code>grid</code> requests failing if token output shape is unexpected</li> </ul> <p>Recommended first checks:</p> <ul> <li>inspect metadata <code>tokens_shape</code> and <code>grid_hw</code></li> <li>confirm <code>RS_EMBED_SATMAE_ID</code> and <code>RS_EMBED_SATMAE_IMG</code></li> <li>verify your custom <code>input_chw</code> is raw SR (not already 0..1 unless you intentionally converted it)</li> </ul>"},{"location":"models/satmae_rgb/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li><code>RS_EMBED_SATMAE_ID</code></li> <li>image size (<code>RS_EMBED_SATMAE_IMG</code>)</li> <li>temporal window and compositing settings</li> <li>output mode (<code>pooled</code> / <code>grid</code>) and pooling choice</li> <li><code>rshf</code> version (wrapper preprocessing behavior can matter)</li> </ul>"},{"location":"models/satmae_rgb/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_satmae.py</code></li> <li>Shared RGB/token helpers: <code>src/rs_embed/embedders/_vit_mae_utils.py</code></li> </ul>"},{"location":"models/satvision_toa/","title":"SatVision-TOA (<code>satvision_toa</code>)","text":"<p>Provider-backed SatVision-TOA adapter for 14-channel TOA inputs (default MODIS band order), with channel-aware reflectance/emissive normalization and token/grid outputs.</p>"},{"location":"models/satvision_toa/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>satvision_toa</code> Family / Backbone SatVision-TOA checkpoint (HF/local checkpoint loader) Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>) Primary input 14-channel TOA <code>CHW</code> (default MODIS/061/MOD021KM band order) Temporal mode <code>range</code> in practice (normalized via shared helper) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none (but channel calibration settings matter) Training alignment (adapter path) High only when channel order + calibration match checkpoint expectations"},{"location":"models/satvision_toa/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/satvision_toa/#good-fit-for","title":"Good fit for","text":"<ul> <li>TOA-based experiments where you want SatVision checkpoints instead of S2 SR-specific encoders</li> <li>MODIS-style provider workflows with explicit control over channel normalization/calibration</li> <li>testing pooled vs patch-token grid outputs from the same model path</li> </ul>"},{"location":"models/satvision_toa/#be-careful-when","title":"Be careful when","text":"<ul> <li>changing <code>SensorSpec.bands</code> order without updating <code>RS_EMBED_SATVISION_TOA_*</code> channel settings</li> <li>mixing raw TOA and unit-scaled inputs without logging the effective normalization mode</li> <li>assuming arbitrary 14-channel inputs will work if they do not match checkpoint training semantics</li> </ul>"},{"location":"models/satvision_toa/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/satvision_toa/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li><code>SpatialSpec</code>: <code>BBox</code> or <code>PointBuffer</code></li> <li><code>TemporalSpec</code>: normalized to a range via shared helper (<code>TemporalSpec.range(...)</code> recommended)</li> <li>Provider backend only (<code>backend=\"gee\"</code> / other provider-compatible backend)</li> </ul>"},{"location":"models/satvision_toa/#sensor-channels","title":"Sensor / channels","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>MODIS/061/MOD021KM</code></li> <li>Bands (strict default order): <code>1,2,3,26,6,20,7,27,28,29,31,32,33,34</code></li> <li><code>scale_m=1000</code>, <code>cloudy_pct=100</code>, <code>composite=\"mosaic\"</code>, <code>fill_value=0.0</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>must be <code>CHW</code></li> <li><code>C</code> must equal <code>RS_EMBED_SATVISION_TOA_IN_CHANS</code> (default <code>14</code>)</li> <li>adapter checks <code>len(sensor.bands) == in_chans</code></li> <li>values may be raw TOA-like or already unit-scaled depending on normalization mode</li> </ul> <p>Important:</p> <ul> <li>The adapter does not infer semantic channel order from values.</li> <li><code>sensor.bands</code> order must match what the checkpoint expects.</li> </ul>"},{"location":"models/satvision_toa/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Resolve runtime settings (checkpoint/model ID, <code>in_chans</code>, normalization, calibration arrays)</li> <li>Fetch provider patch (<code>CHW</code>) or use <code>input_chw</code></li> <li>If provider metadata says input is already unit-scaled, effective norm mode is forced to <code>unit</code></li> <li>Normalize with <code>RS_EMBED_SATVISION_TOA_NORM</code>:</li> <li><code>auto</code>: use <code>[0,1]</code> directly if values look unit-scaled, else fall back to raw scaling</li> <li><code>raw</code>: channel-wise scaling<ul> <li>reflectance channels: divide by <code>RS_EMBED_SATVISION_TOA_REF_DIV</code> (default <code>100</code>)</li> <li>emissive channels: min-max normalize using <code>RS_EMBED_SATVISION_TOA_EMISSIVE_MINS/MAXS</code></li> </ul> </li> <li><code>unit</code>: clip to <code>[0,1]</code></li> <li>Resize to <code>RS_EMBED_SATVISION_TOA_IMG</code> (default <code>128</code>)</li> <li>Forward model and decode output tensor</li> <li>Return:</li> <li>pooled vector (from token pooling or model-pooled output)</li> <li>grid via token reshape if output is token sequence <code>[N,D]</code></li> </ol>"},{"location":"models/satvision_toa/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":""},{"location":"models/satvision_toa/#model-weights","title":"Model / weights","text":"Env var Default Effect <code>RS_EMBED_SATVISION_TOA_ID</code> SatVision TOA HF model ID HF model identifier <code>RS_EMBED_SATVISION_TOA_CKPT</code> unset Local checkpoint path override <code>RS_EMBED_SATVISION_TOA_AUTO_DOWNLOAD</code> <code>1</code> Allow HF download when local checkpoint not set <code>RS_EMBED_SATVISION_TOA_IMG</code> <code>128</code> Resize target image size <code>RS_EMBED_SATVISION_TOA_IN_CHANS</code> <code>14</code> Expected channel count <code>RS_EMBED_SATVISION_TOA_BATCH_SIZE</code> CPU:<code>2</code>, CUDA:<code>8</code> Inference batch size (batch APIs) <code>RS_EMBED_SATVISION_TOA_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers (batch APIs)"},{"location":"models/satvision_toa/#normalization-calibration","title":"Normalization / calibration","text":"Env var Default Effect <code>RS_EMBED_SATVISION_TOA_NORM</code> <code>auto</code> <code>auto</code>, <code>raw</code>, or <code>unit</code> <code>RS_EMBED_SATVISION_TOA_REFLECTANCE_IDXS</code> adapter defaults Reflectance channel indices <code>RS_EMBED_SATVISION_TOA_EMISSIVE_IDXS</code> adapter defaults Emissive channel indices <code>RS_EMBED_SATVISION_TOA_REF_DIV</code> <code>100</code> Reflectance divisor <code>RS_EMBED_SATVISION_TOA_EMISSIVE_MINS</code> adapter defaults Emissive min calibration values <code>RS_EMBED_SATVISION_TOA_EMISSIVE_MAXS</code> adapter defaults Emissive max calibration values"},{"location":"models/satvision_toa/#default-sensor-overrides-if-sensor-omitted","title":"Default sensor overrides (if <code>sensor</code> omitted)","text":"Env var Default Effect <code>RS_EMBED_SATVISION_TOA_COLLECTION</code> <code>MODIS/061/MOD021KM</code> Default provider collection <code>RS_EMBED_SATVISION_TOA_BANDS</code> default 14-band MODIS order Override default band list <code>RS_EMBED_SATVISION_TOA_SCALE_M</code> <code>1000</code> Default fetch scale <code>RS_EMBED_SATVISION_TOA_CLOUDY_PCT</code> <code>100</code> Default cloud filter <code>RS_EMBED_SATVISION_TOA_FILL</code> <code>0</code> Default fill value <code>RS_EMBED_SATVISION_TOA_COMPOSITE</code> <code>mosaic</code> Default composite method"},{"location":"models/satvision_toa/#output-semantics","title":"Output Semantics","text":""},{"location":"models/satvision_toa/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>If model output is token sequence <code>[N,D]</code>, adapter pools patch tokens (<code>mean</code> / <code>max</code>)</li> <li>If model output is already <code>(D,)</code>, adapter returns it directly as <code>model_pooled</code></li> <li>Metadata records pooling behavior and whether CLS token was removed</li> </ul>"},{"location":"models/satvision_toa/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Requires token sequence output <code>[N,D]</code></li> <li>Reshapes patch tokens to <code>xarray.DataArray</code> <code>(D,H,W)</code></li> <li>Grid is model patch-token layout, not georeferenced raster pixels</li> </ul>"},{"location":"models/satvision_toa/#examples","title":"Examples","text":""},{"location":"models/satvision_toa/#minimal-provider-backed-example","title":"Minimal provider-backed example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"satvision_toa\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=5000),\n    temporal=TemporalSpec.range(\"2022-07-01\", \"2022-07-31\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/satvision_toa/#example-normalization-tuning-env-controlled","title":"Example normalization tuning (env-controlled)","text":"<pre><code># Example (shell):\n# export RS_EMBED_SATVISION_TOA_NORM=raw\n# export RS_EMBED_SATVISION_TOA_IMG=128\n# export RS_EMBED_SATVISION_TOA_REF_DIV=100\n# export RS_EMBED_SATVISION_TOA_IN_CHANS=14\n</code></pre>"},{"location":"models/satvision_toa/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>backend is not provider-compatible (<code>satvision_toa</code> is provider-only)</li> <li><code>sensor.bands</code> count does not match <code>RS_EMBED_SATVISION_TOA_IN_CHANS</code></li> <li>calibration list lengths mismatch (<code>EMISSIVE_IDXS</code> vs <code>EMISSIVE_MINS/MAXS</code>)</li> <li>wrong channel order for the chosen checkpoint (results look unstable even if shapes pass)</li> <li>grid requested but model output is not a token sequence</li> <li>HF download/auth issues when using gated/private checkpoints</li> </ul> <p>Recommended first checks:</p> <ul> <li>inspect metadata for <code>norm_mode</code> and <code>norm_mode_effective</code></li> <li>log <code>sensor.collection</code>, <code>sensor.bands</code>, and calibration env values used</li> <li>test <code>OutputSpec.pooled()</code> first before <code>grid</code></li> </ul>"},{"location":"models/satvision_toa/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li>checkpoint source (<code>RS_EMBED_SATVISION_TOA_ID</code> or local <code>CKPT</code>)</li> <li>exact band order and <code>in_chans</code></li> <li>normalization mode plus calibration arrays/divisor</li> <li>temporal window + compositing settings</li> <li>output mode (<code>pooled</code> / <code>grid</code>) and pooling choice</li> </ul>"},{"location":"models/satvision_toa/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_satvision_toa.py</code></li> <li>Token/grid helpers: <code>src/rs_embed/embedders/_vit_mae_utils.py</code></li> </ul>"},{"location":"models/scalemae_rgb/","title":"ScaleMAE RGB (<code>scalemae_rgb</code>)","text":"<p>Sentinel-2 RGB on-the-fly adapter for ScaleMAE (<code>rshf.scalemae.ScaleMAE</code>), with explicit scale conditioning via <code>sensor.scale_m -&gt; input_res_m</code>.</p>"},{"location":"models/scalemae_rgb/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>scalemae_rgb</code> Family / Backbone ScaleMAE via <code>rshf.scalemae.ScaleMAE</code> Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>) Primary input S2 RGB (<code>B4,B3,B2</code>) + <code>input_res_m</code> Temporal mode range window in practice (normalized via shared helper) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs required semantic scale (<code>sensor.scale_m</code> passed as <code>input_res_m</code>) Training alignment (adapter path) Medium-High when <code>sensor.scale_m</code> matches the actual input resolution semantics"},{"location":"models/scalemae_rgb/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/scalemae_rgb/#good-fit-for","title":"Good fit for","text":"<ul> <li>RGB experiments where spatial scale conditioning matters</li> <li>comparisons against SatMAE/RemoteCLIP with a scale-aware backbone</li> <li>benchmarking robustness to resolution changes (while explicitly logging <code>scale_m</code>)</li> </ul>"},{"location":"models/scalemae_rgb/#be-careful-when","title":"Be careful when","text":"<ul> <li><code>sensor.scale_m</code> is missing/incorrect for your input patch</li> <li>assuming <code>grid</code> is always available (some wrapper outputs may be pooled vectors only)</li> <li>comparing results without recording model output type (<code>tokens_kind</code>)</li> </ul>"},{"location":"models/scalemae_rgb/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/scalemae_rgb/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li>Provider backend only (<code>backend=\"gee\"</code> / provider-compatible backend)</li> <li><code>TemporalSpec</code> normalized via shared helper; use <code>TemporalSpec.range(...)</code> for reproducibility</li> </ul>"},{"location":"models/scalemae_rgb/#sensor-channels-scale","title":"Sensor / channels + scale","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: <code>(\"B4\", \"B3\", \"B2\")</code></li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>must be <code>CHW</code> with 3 channels in <code>(B4,B3,B2)</code> order</li> <li>raw S2 SR values expected in <code>0..10000</code></li> </ul> <p>Scale requirement:</p> <ul> <li>adapter passes <code>float(sensor.scale_m)</code> to ScaleMAE as <code>input_res_m</code></li> <li>if <code>sensor.scale_m</code> does not reflect actual patch resolution semantics, embeddings are not comparable</li> </ul>"},{"location":"models/scalemae_rgb/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Fetch S2 RGB patch (provider path) or convert <code>input_chw</code> raw SR -&gt; <code>[0,1]</code> -&gt; <code>uint8</code></li> <li>Resize to <code>RS_EMBED_SCALEMAE_IMG</code> (default <code>224</code>)</li> <li>Convert to tensor with CLIP-style preprocessing (<code>rgb_u8_to_tensor_clipnorm</code>)</li> <li>Build <code>input_res</code> tensor from <code>sensor.scale_m</code></li> <li>Call ScaleMAE <code>forward_features(...)</code> (preferred) or <code>forward(...)</code></li> <li>adapter handles signature differences across <code>rshf</code> versions</li> <li>passes both <code>patch_size</code> and <code>input_res</code></li> <li>Normalize output format:</li> <li><code>[N,D]</code> tokens</li> <li><code>[D]</code> pooled vector</li> <li><code>[C,H,W]</code> feature map reshaped to tokens</li> <li>Return pooled vector or token grid</li> </ol> <p>Important:</p> <ul> <li><code>grid</code> output requires token sequence (<code>[N,D]</code> after adapter normalization).</li> <li>If the model/wrapper returns pooled vectors only, <code>OutputSpec.grid()</code> raises a clear error.</li> </ul>"},{"location":"models/scalemae_rgb/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_SCALEMAE_ID</code> <code>MVRL/scalemae-vitlarge-800</code> HF model ID for <code>ScaleMAE.from_pretrained(...)</code> <code>RS_EMBED_SCALEMAE_IMG</code> <code>224</code> Resize / preprocess image size <code>RS_EMBED_SCALEMAE_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs <code>RS_EMBED_SCALEMAE_BATCH_SIZE</code> CPU:<code>8</code>, CUDA:<code>32</code> Inference batch size for batch APIs <p>Non-env but critical:</p> <ul> <li><code>sensor.scale_m</code> (used as <code>input_res_m</code>)</li> </ul>"},{"location":"models/scalemae_rgb/#output-semantics","title":"Output Semantics","text":""},{"location":"models/scalemae_rgb/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>If adapter gets token sequence <code>[N,D]</code>, it pools patch tokens (<code>mean</code> / <code>max</code>)</li> <li>If adapter gets pooled vector <code>[D]</code>, it returns it directly (<code>pooling=\"model_pooled\"</code>)</li> <li>Metadata includes <code>tokens_kind</code>, <code>used_patch_size</code>, and <code>used_scale_m</code></li> </ul>"},{"location":"models/scalemae_rgb/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Requires token sequence output after adapter normalization</li> <li>Returns patch-token grid as <code>xarray.DataArray</code> <code>(D,H,W)</code></li> <li>Grid is model token layout, not georeferenced raster pixels</li> </ul>"},{"location":"models/scalemae_rgb/#examples","title":"Examples","text":""},{"location":"models/scalemae_rgb/#minimal-provider-backed-example","title":"Minimal provider-backed example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"scalemae_rgb\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/scalemae_rgb/#example-tuning-env-scale-semantics","title":"Example tuning (env + scale semantics)","text":"<pre><code># Example (shell):\n# export RS_EMBED_SCALEMAE_ID=MVRL/scalemae-vitlarge-800\n# export RS_EMBED_SCALEMAE_IMG=224\n#\n# In code, keep sensor.scale_m correct (this is passed to ScaleMAE as input_res_m).\n</code></pre>"},{"location":"models/scalemae_rgb/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>backend mismatch (<code>scalemae_rgb</code> is provider-only)</li> <li>wrong <code>input_chw</code> shape / band order (<code>CHW</code>, 3 channels, <code>(B4,B3,B2)</code>)</li> <li>missing <code>rshf.scalemae.ScaleMAE</code></li> <li>wrapper signature mismatch in older/newer <code>rshf</code> versions (adapter has fallbacks, but still possible)</li> <li><code>grid</code> requested when model output is pooled vector only</li> <li>incorrect <code>sensor.scale_m</code> causing silent comparison drift</li> </ul> <p>Recommended first checks:</p> <ul> <li>inspect metadata <code>tokens_kind</code>, <code>used_patch_size</code>, <code>input_res_m</code> / <code>used_scale_m</code></li> <li>verify <code>sensor.scale_m</code> and <code>RS_EMBED_SCALEMAE_IMG</code></li> <li>start with <code>OutputSpec.pooled()</code> before debugging <code>grid</code></li> </ul>"},{"location":"models/scalemae_rgb/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li><code>RS_EMBED_SCALEMAE_ID</code></li> <li><code>RS_EMBED_SCALEMAE_IMG</code></li> <li><code>sensor.scale_m</code> (critical)</li> <li>temporal window + compositing settings</li> <li>output mode and pooling choice</li> <li><code>rshf</code> version</li> </ul>"},{"location":"models/scalemae_rgb/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_scalemae.py</code></li> <li>Shared RGB/token helpers: <code>src/rs_embed/embedders/_vit_mae_utils.py</code></li> </ul>"},{"location":"models/terrafm_b/","title":"TerraFM-B (<code>terrafm_b</code>)","text":"<p>TerraFM-B adapter supporting both provider and tensor backends, with two input modalities (<code>s2</code> 12-band Sentinel-2 SR or <code>s1</code> VV/VH Sentinel-1) and model-native feature-map grids.</p>"},{"location":"models/terrafm_b/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>terrafm_b</code> Family / Backbone TerraFM-B from Hugging Face (<code>MBZUAI/TerraFM</code>) Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>), also supports <code>backend=\"tensor\"</code> Primary input S2 SR 12-band or S1 VV/VH (selected by <code>sensor.modality</code>) Temporal mode provider path requires <code>TemporalSpec.range(...)</code> (v0.1 behavior) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs modality settings on <code>sensor</code> (<code>modality</code>, <code>orbit</code>, <code>use_float_linear</code>) Training alignment (adapter path) Medium-High when modality-specific preprocessing matches the intended TerraFM path"},{"location":"models/terrafm_b/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/terrafm_b/#good-fit-for","title":"Good fit for","text":"<ul> <li>experiments comparing S2 and S1 representations under one backbone family</li> <li>workflows needing both provider fetch and direct tensor backend</li> <li>model-native feature-map outputs instead of token-only grids</li> </ul>"},{"location":"models/terrafm_b/#be-careful-when","title":"Be careful when","text":"<ul> <li>mixing S1 and S2 runs without logging modality and preprocessing path</li> <li>passing tensor backend inputs with wrong channel count (<code>C</code> must be <code>2</code> or <code>12</code>)</li> <li>assuming <code>backend=\"auto\"</code> works (this adapter is stricter and expects explicit provider or <code>tensor</code>)</li> </ul>"},{"location":"models/terrafm_b/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/terrafm_b/#backend-modes","title":"Backend modes","text":"<ul> <li><code>backend=\"tensor\"</code>:</li> <li>requires <code>sensor.data</code> as <code>CHW</code> or <code>BCHW</code></li> <li>adapter resizes to <code>224</code></li> <li>provider backend (<code>gee</code> / provider-compatible, but not <code>auto</code> in current implementation):</li> <li>requires <code>TemporalSpec.range(...)</code> in v0.1</li> <li>fetches S2 or S1 based on <code>sensor.modality</code></li> </ul>"},{"location":"models/terrafm_b/#modality-selection-sensormodality","title":"Modality selection (<code>sensor.modality</code>)","text":"<ul> <li><code>s2</code> (default):</li> <li>12-band Sentinel-2 SR input (<code>B1,B2,B3,B4,B5,B6,B7,B8,B8A,B9,B11,B12</code>)</li> <li>provider fetch returns normalized <code>[0,1]</code></li> <li> <p><code>input_chw</code> override expects raw SR <code>0..10000</code>, adapter scales to <code>[0,1]</code></p> </li> <li> <p><code>s1</code>:</p> </li> <li>2-band Sentinel-1 VV/VH input (<code>VV</code>,<code>VH</code>)</li> <li>provider path fetches raw VV/VH then normalizes via shared S1 normalization helper</li> <li><code>input_chw</code> override expects raw VV/VH and applies <code>log1p</code> + percentile scaling to <code>[0,1]</code></li> </ul>"},{"location":"models/terrafm_b/#sensor-fields-used-by-adapter-provider-path","title":"Sensor fields used by adapter (provider path)","text":"<ul> <li>common: <code>scale_m</code>, <code>cloudy_pct</code>, <code>composite</code></li> <li>S1-specific: <code>orbit</code>, <code>use_float_linear</code></li> </ul> <p>Channel sanity:</p> <ul> <li>TerraFM path is strict: <code>C</code> must be <code>12</code> (S2) or <code>2</code> (S1)</li> </ul>"},{"location":"models/terrafm_b/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":""},{"location":"models/terrafm_b/#provider-path","title":"Provider path","text":"<ol> <li>Validate <code>TemporalSpec.range(...)</code></li> <li>Select modality from <code>sensor.modality</code> (<code>s2</code> / <code>s1</code>)</li> <li>Fetch provider patch:</li> <li>S2: 12-band SR -&gt; normalize to <code>[0,1]</code></li> <li>S1: VV/VH raw -&gt; shared S1 normalization helper -&gt; <code>[0,1]</code></li> <li>Optional input inspection on normalized provider input</li> <li>Resize to fixed <code>224x224</code></li> <li>Load TerraFM-B from HF code + <code>.pth</code> weights</li> <li>Forward:</li> <li><code>pooled</code>: TerraFM forward returns CLS embedding <code>(D,)</code></li> <li><code>grid</code>: adapter calls <code>extract_feature(...)</code> and uses last-layer feature map <code>(D,H,W)</code></li> </ol>"},{"location":"models/terrafm_b/#tensor-backend-path","title":"Tensor backend path","text":"<ol> <li>Read <code>sensor.data</code> (<code>CHW</code> or <code>BCHW</code>)</li> <li>Resize to <code>224x224</code></li> <li>Validate channel count (<code>2</code> or <code>12</code>)</li> <li>Load TerraFM-B and run same forward/grid extraction path</li> </ol> <p>Notes:</p> <ul> <li>Tensor backend path does not apply provider-specific fetch normalization automatically; you are responsible for matching expected input scale/semantics.</li> </ul>"},{"location":"models/terrafm_b/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_TERRAFM_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs <code>RS_EMBED_TERRAFM_BATCH_SIZE</code> CPU:<code>8</code>, CUDA:<code>64</code> Inference batch size for batch APIs <p>Related cache envs (used by HF asset download path):</p> <ul> <li><code>HUGGINGFACE_HUB_CACHE</code>, <code>HF_HOME</code>, <code>HUGGINGFACE_HOME</code></li> </ul> <p>Adapter behavior notes:</p> <ul> <li>image size is fixed to <code>224</code> in current implementation</li> <li>weights/code are fetched from <code>MBZUAI/TerraFM</code> (<code>terrafm.py</code> + <code>TerraFM-B.pth</code>)</li> </ul>"},{"location":"models/terrafm_b/#output-semantics","title":"Output Semantics","text":""},{"location":"models/terrafm_b/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Returns TerraFM forward output (CLS embedding) <code>(D,)</code></li> <li>This is not token pooling; it is the model\u2019s pooled embedding path</li> </ul>"},{"location":"models/terrafm_b/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Returns last-layer TerraFM feature map via <code>extract_feature(...)</code></li> <li><code>xarray.DataArray</code> shape <code>(D,H,W)</code></li> <li>Metadata includes <code>grid_type=\"feature_map\"</code></li> <li>Grid is model feature-map layout, not georeferenced raster pixels</li> </ul>"},{"location":"models/terrafm_b/#examples","title":"Examples","text":""},{"location":"models/terrafm_b/#minimal-provider-backed-s2-example","title":"Minimal provider-backed S2 example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec, SensorSpec\n\nsensor = SensorSpec(\n    collection=\"COPERNICUS/S2_SR_HARMONIZED\",\n    bands=(\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"),\n    scale_m=10,\n)\nsensor.modality = \"s2\"  # current adapter reads modality from sensor attrs\n\nemb = get_embedding(\n    \"terrafm_b\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    sensor=sensor,\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/terrafm_b/#s1-provider-path-example-conceptual","title":"S1 provider path example (conceptual)","text":"<pre><code># sensor.modality = \"s1\"\n# sensor.orbit = \"ASCENDING\"  # optional\n# sensor.use_float_linear = True\n</code></pre>"},{"location":"models/terrafm_b/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>using <code>backend=\"auto\"</code> (current adapter expects explicit provider backend or <code>tensor</code>)</li> <li>provider path with non-<code>range</code> temporal spec</li> <li>tensor backend without <code>sensor.data</code></li> <li>wrong channel count (<code>C</code> must be <code>2</code> or <code>12</code>)</li> <li>S1/S2 modality mismatch between data and <code>sensor.modality</code></li> <li>HF asset download issues (code or <code>.pth</code> weights)</li> </ul> <p>Recommended first checks:</p> <ul> <li>inspect metadata <code>modality</code>, <code>source</code>, <code>grid_type</code>, and weight file info</li> <li>verify tensor input scale/normalization if using <code>backend=\"tensor\"</code></li> <li>start with S2 default path before enabling S1 overrides</li> </ul>"},{"location":"models/terrafm_b/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li>backend mode (<code>provider</code> vs <code>tensor</code>)</li> <li>modality (<code>s2</code> / <code>s1</code>) and S1-specific options (<code>orbit</code>, <code>use_float_linear</code>)</li> <li>temporal window + compositing settings (provider path)</li> <li>output mode (<code>pooled</code> / <code>grid</code>)</li> <li>TerraFM HF asset source/cache snapshot if benchmarking</li> </ul>"},{"location":"models/terrafm_b/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_terrafm.py</code></li> </ul>"},{"location":"models/terramind/","title":"TerraMind (<code>terramind</code>)","text":"<p>TerraTorch-backed TerraMind adapter for Sentinel-2 SR 12-band inputs, supporting provider and tensor backends with TerraMind-specific z-score normalization.</p>"},{"location":"models/terramind/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>terramind</code> Family / Backbone TerraMind via TerraTorch <code>BACKBONE_REGISTRY</code> Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>), also supports <code>backend=\"tensor\"</code> Primary input S2 SR 12-band (<code>B1..B12</code> subset used by adapter order) Temporal mode <code>range</code> (provider path normalized via shared helper) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none required in current adapter Training alignment (adapter path) High when default TerraMind z-score normalization is preserved"},{"location":"models/terramind/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/terramind/#good-fit-for","title":"Good fit for","text":"<ul> <li>strict multispectral S2 experiments with TerraMind checkpoints</li> <li>comparisons requiring a strong S2 12-band encoder</li> <li>workflows that need both provider and direct tensor backend paths</li> </ul>"},{"location":"models/terramind/#be-careful-when","title":"Be careful when","text":"<ul> <li>changing normalization mode away from TerraMind stats (<code>zscore</code>)</li> <li>assuming <code>grid</code> is georeferenced raster space (it is patch-token grid)</li> <li>using tensor backend without matching expected channel order and preprocessing assumptions</li> </ul>"},{"location":"models/terramind/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/terramind/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li>Provider path: <code>SpatialSpec</code> + temporal normalized to range via shared helper</li> <li>Tensor path: no provider fetch; pass <code>sensor.data</code> as CHW/BCHW</li> </ul>"},{"location":"models/terramind/#sensor-channels-provider-path","title":"Sensor / channels (provider path)","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: adapter fetch order <code>_S2_SR_12_BANDS</code> = <code>B1,B2,B3,B4,B5,B6,B7,B8,B8A,B9,B11,B12</code></li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code>, <code>fill_value=0.0</code></li> </ul> <p>TerraMind internal semantic mapping is also tracked in metadata (<code>bands_terramind</code>).</p> <p><code>input_chw</code> contract (provider override path):</p> <ul> <li>must be <code>CHW</code> with 12 bands in adapter fetch order</li> <li>raw SR values expected in <code>0..10000</code></li> </ul>"},{"location":"models/terramind/#tensor-backend-contract","title":"Tensor backend contract","text":"<ul> <li><code>backend=\"tensor\"</code> requires <code>sensor.data</code></li> <li>accepted shapes: <code>CHW</code> or <code>BCHW</code></li> <li><code>C</code> must be <code>12</code></li> <li>adapter resizes to <code>224</code> and applies TerraMind normalization before forward</li> </ul>"},{"location":"models/terramind/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":""},{"location":"models/terramind/#provider-path","title":"Provider path","text":"<ol> <li>Fetch 12-band raw S2 SR patch (<code>0..10000</code>), composite over temporal window</li> <li>Optional input inspection checks on raw values (<code>value_range=(0,10000)</code>)</li> <li>Resize to fixed <code>224x224</code></li> <li>Apply TerraMind normalization (<code>RS_EMBED_TERRAMIND_NORMALIZE</code>, default <code>zscore</code>)</li> <li><code>zscore</code>: uses TerraMind v1 or v01 stats depending on model key prefix</li> <li><code>raw/none</code>: no z-score stats, only <code>nan_to_num</code></li> <li>Forward TerraMind backbone and extract token tensor</li> <li>Pool tokens or reshape to patch-token grid</li> </ol>"},{"location":"models/terramind/#tensor-path","title":"Tensor path","text":"<ul> <li>Reads <code>sensor.data</code>, coerces CHW/BCHW, resizes to <code>224</code>, applies same normalization, then forwards model</li> </ul>"},{"location":"models/terramind/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_TERRAMIND_MODEL_KEY</code> <code>terramind_v1_small</code> TerraMind backbone key <code>RS_EMBED_TERRAMIND_MODALITY</code> <code>S2L2A</code> Modality passed to TerraMind/TerraTorch <code>RS_EMBED_TERRAMIND_NORMALIZE</code> <code>zscore</code> Input normalization mode (<code>zscore</code> vs raw/none) <code>RS_EMBED_TERRAMIND_LAYER_INDEX</code> <code>-1</code> Which layer output to select when sequence-like outputs are returned <code>RS_EMBED_TERRAMIND_PRETRAINED</code> <code>1</code> Use pretrained weights <code>RS_EMBED_TERRAMIND_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs <p>Fixed adapter behavior:</p> <ul> <li>image size is fixed to <code>224</code> in current implementation</li> </ul>"},{"location":"models/terramind/#output-semantics","title":"Output Semantics","text":""},{"location":"models/terramind/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Pools TerraMind tokens with <code>mean</code> / <code>max</code> according to <code>OutputSpec.pooling</code></li> <li>Metadata records pooling mode and whether CLS removal happened</li> </ul>"},{"location":"models/terramind/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Returns ViT patch-token grid <code>(D,H,W)</code> as <code>xarray.DataArray</code></li> <li>Metadata includes <code>grid_type=\"vit_patch_tokens\"</code>, <code>grid_hw</code>, and <code>cls_removed</code></li> <li>Grid is model token layout, not georeferenced raster pixels</li> </ul>"},{"location":"models/terramind/#examples","title":"Examples","text":""},{"location":"models/terramind/#minimal-provider-backed-example","title":"Minimal provider-backed example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"terramind\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/terramind/#example-normalizationmodel-tuning-env-controlled","title":"Example normalization/model tuning (env-controlled)","text":"<pre><code># Example (shell):\n# export RS_EMBED_TERRAMIND_MODEL_KEY=terramind_v1_small\n# export RS_EMBED_TERRAMIND_NORMALIZE=zscore\n# export RS_EMBED_TERRAMIND_MODALITY=S2L2A\n</code></pre>"},{"location":"models/terramind/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>wrong channel count for <code>input_chw</code> / tensor backend (<code>C</code> must be 12)</li> <li>backend mismatch (<code>tensor</code> path requires <code>sensor.data</code>; provider path requires provider backend)</li> <li>hidden normalization changes via <code>RS_EMBED_TERRAMIND_NORMALIZE</code></li> <li>TerraTorch import/build issues for selected model key or optional deps</li> </ul> <p>Recommended first checks:</p> <ul> <li>verify provider raw input channel order and range before normalization</li> <li>inspect metadata for model key, modality, normalization mode, and layer index</li> </ul>"},{"location":"models/terramind/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed across runs:</p> <ul> <li>model key (<code>v1</code> vs <code>v01</code> changes which z-score stats are used)</li> <li>normalization mode (<code>zscore</code> strongly recommended)</li> <li>modality (<code>S2L2A</code> default)</li> <li>output mode/pooling choice</li> <li>temporal window and compositing settings (provider path)</li> </ul>"},{"location":"models/terramind/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_terramind.py</code></li> <li>Token/grid helpers: <code>src/rs_embed/embedders/_vit_mae_utils.py</code></li> </ul>"},{"location":"models/tessera/","title":"Tessera (<code>tessera</code>)","text":"<p>Precomputed embedding adapter backed by GeoTessera local tiles, with strict tile mosaic + ROI crop behavior and local-only (<code>backend=\"local\"</code>/<code>\"auto\"</code>) access.</p>"},{"location":"models/tessera/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>tessera</code> Family / Source GeoTessera local precomputed embeddings Adapter type <code>precomputed</code> Typical backend <code>local</code> (or <code>auto</code>) Primary input <code>BBox</code> / <code>PointBuffer</code> in EPSG:4326 (converted to bbox) Temporal mode year-like selection (<code>year</code>; <code>range</code> uses start year fallback) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none Training alignment (adapter path) N/A (precomputed product)"},{"location":"models/tessera/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/tessera/#good-fit-for","title":"Good fit for","text":"<ul> <li>fast offline/local baselines using existing GeoTessera cache tiles</li> <li>large-area ROI embedding extraction without model inference runtime</li> <li>workflows where local tile mosaic/crop behavior is preferable to provider fetches</li> </ul>"},{"location":"models/tessera/#be-careful-when","title":"Be careful when","text":"<ul> <li>expecting arbitrary backends (<code>tessera</code> is local/auto only)</li> <li>using <code>TemporalSpec.range(...)</code> and assuming exact temporal semantics (adapter picks the start year)</li> <li>ROI crosses tiles with inconsistent CRS/resolution (adapter requires strict mosaic compatibility)</li> </ul>"},{"location":"models/tessera/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/tessera/#spatial","title":"Spatial","text":"<p>Accepted <code>SpatialSpec</code>:</p> <ul> <li><code>BBox</code> (validated)</li> <li><code>PointBuffer</code> (converted to <code>BBox</code> in EPSG:4326 using approximate meter-to-degree conversion)</li> </ul> <p>Unsupported spatial types raise <code>ModelError</code>.</p>"},{"location":"models/tessera/#temporal","title":"Temporal","text":"<ul> <li><code>temporal=None</code> -&gt; defaults to year <code>2021</code></li> <li><code>TemporalSpec.year(...)</code> -&gt; uses <code>temporal.year</code></li> <li><code>TemporalSpec.range(start, end)</code> -&gt; uses the year parsed from <code>start</code></li> </ul> <p>This is a year selector for tile product lookup, not scene-level temporal filtering.</p>"},{"location":"models/tessera/#backend-cache","title":"Backend / cache","text":"<ul> <li>backend must be <code>local</code> or <code>auto</code></li> <li>adapter reads GeoTessera cache from:</li> <li><code>RS_EMBED_TESSERA_CACHE</code>, or</li> <li><code>sensor.collection=\"cache:/path/to/cache\"</code> override</li> </ul>"},{"location":"models/tessera/#preprocessing-retrieval-pipeline-current-rs-embed-path","title":"Preprocessing / Retrieval Pipeline (Current rs-embed Path)","text":"<ol> <li>Convert <code>SpatialSpec</code> to <code>BBox</code> in EPSG:4326</li> <li>Resolve year from <code>TemporalSpec</code> (with fallback behavior)</li> <li>Open/cache <code>geotessera.GeoTessera</code> instance by <code>cache_dir</code></li> <li>Query tile blocks covering ROI/year</li> <li>Fetch tile embeddings and normalize array layout (<code>HWC</code> or <code>CHW</code> -&gt; internal <code>HWC</code>)</li> <li>Strict mosaic + crop:</li> <li>requires north-up transforms (no rotation/shear)</li> <li>requires consistent tile CRS and resolution across fetched tiles</li> <li>reprojects ROI bbox into tile CRS if needed (requires <code>pyproj</code>)</li> <li>Convert cropped result to <code>CHW</code></li> <li>Return pooled vector or grid</li> </ol>"},{"location":"models/tessera/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_TESSERA_CACHE</code> unset (GeoTessera default) Local GeoTessera cache directory <code>RS_EMBED_TESSERA_BATCH_WORKERS</code> <code>4</code> Batch worker count for <code>get_embeddings_batch(...)</code> <p>Non-env override:</p> <ul> <li><code>sensor.collection=\"cache:/path/to/cache\"</code> overrides cache directory for the call</li> </ul>"},{"location":"models/tessera/#output-semantics","title":"Output Semantics","text":""},{"location":"models/tessera/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Pools cropped precomputed <code>CHW</code> grid over spatial dims:</li> <li><code>mean</code> -&gt; <code>mean_hw</code></li> <li><code>max</code> -&gt; <code>max_hw</code></li> </ul>"},{"location":"models/tessera/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Returns cropped precomputed embedding grid as <code>xarray.DataArray</code> <code>(D,H,W)</code></li> <li>Grid is product pixel/grid space from the precomputed tiles (after local mosaic+crop)</li> <li>Metadata includes crop/mosaic info (CRS, crop window, transform)</li> </ul>"},{"location":"models/tessera/#examples","title":"Examples","text":""},{"location":"models/tessera/#minimal-local-example","title":"Minimal local example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"tessera\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=5000),\n    temporal=TemporalSpec.year(2021),\n    output=OutputSpec.pooled(),\n    backend=\"local\",\n)\n</code></pre>"},{"location":"models/tessera/#example-cache-override","title":"Example cache override","text":"<pre><code># Example (shell):\n# export RS_EMBED_TESSERA_CACHE=/data/geotessera\n</code></pre>"},{"location":"models/tessera/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>backend is not <code>local</code>/<code>auto</code></li> <li>no tiles found for ROI/year</li> <li>tile CRS/resolution mismatch during mosaic</li> <li>tile transform has rotation/shear (not north-up)</li> <li>missing optional deps for CRS reprojection (<code>pyproj</code>) on non-4326 tiles</li> </ul> <p>Recommended first checks:</p> <ul> <li>inspect metadata <code>preferred_year</code>, <code>bbox_4326</code>, <code>chw_shape</code></li> <li>inspect crop metadata (<code>tile_crs</code>, <code>mosaic_hw</code>, <code>crop_px_window</code>)</li> <li>try a larger ROI if no tiles are found</li> </ul>"},{"location":"models/tessera/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li>GeoTessera cache snapshot/path</li> <li>year selection logic (<code>year</code> vs <code>range(start, ...)</code>)</li> <li>ROI geometry and CRS</li> <li>output mode / pooling choice</li> </ul>"},{"location":"models/tessera/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/precomputed_tessera.py</code></li> </ul>"},{"location":"models/thor_1_0_base/","title":"THOR 1.0 Base (<code>thor_1_0_base</code>)","text":"<p>TerraTorch-backed THOR adapter for Sentinel-2 SR 10-band inputs, with THOR-specific normalization and flexible group-grid aggregation (<code>mean</code> / <code>sum</code> / <code>concat</code>).</p>"},{"location":"models/thor_1_0_base/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>thor_1_0_base</code> Family / Backbone THOR via TerraTorch + <code>thor_terratorch_ext</code> (<code>thor_v1_base</code>) Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>) Primary input S2 SR 10-band <code>CHW</code> Temporal mode <code>range</code> in practice (composite window) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none required in current adapter Training alignment (adapter path) High when <code>thor_stats</code> normalization and default S2 SR setup are preserved"},{"location":"models/thor_1_0_base/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/thor_1_0_base/#good-fit-for","title":"Good fit for","text":"<ul> <li>strong S2 SR baselines with THOR pretrained weights</li> <li>experiments needing both pooled and token-grid outputs</li> <li>studies where group-wise THOR token aggregation (<code>group_merge</code>) is relevant</li> </ul>"},{"location":"models/thor_1_0_base/#be-careful-when","title":"Be careful when","text":"<ul> <li>changing normalization away from <code>thor_stats</code> for benchmark comparisons</li> <li>changing <code>patch_size</code> / <code>image_size</code> without logging <code>ground_cover_m</code></li> <li>assuming <code>grid</code> is always available (some configs may fall back to pooled-only usability)</li> </ul>"},{"location":"models/thor_1_0_base/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/thor_1_0_base/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li>Provider backend only (<code>backend=\"gee\"</code> / provider-compatible backend)</li> <li><code>TemporalSpec</code> is normalized to range via shared helper (<code>TemporalSpec.range(...)</code> recommended)</li> <li>Temporal window is used for compositing, not scene identity locking</li> </ul>"},{"location":"models/thor_1_0_base/#sensor-channels","title":"Sensor / channels","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands (adapter order): <code>B2,B3,B4,B5,B6,B7,B8,B8A,B11,B12</code></li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code>, <code>fill_value=0.0</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>must be <code>CHW</code> with <code>C=10</code></li> <li>raw S2 SR values expected in <code>0..10000</code></li> <li>adapter clips NaN/Inf and clamps to <code>0..10000</code> before normalization</li> </ul>"},{"location":"models/thor_1_0_base/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Fetch S2 SR 10-band composite patch (provider path) or accept <code>input_chw</code></li> <li>Optional input inspection on raw values (<code>expected_channels=10</code>, range <code>0..10000</code>)</li> <li>Normalize with <code>RS_EMBED_THOR_NORMALIZE</code>:</li> <li><code>thor_stats</code> (default): <code>/10000</code> then THOR z-score stats</li> <li><code>unit_scale</code>: <code>/10000</code> and clip <code>[0,1]</code></li> <li><code>none</code> / <code>raw</code>: keep raw <code>0..10000</code> (clipped)</li> <li>Resize to <code>RS_EMBED_THOR_IMG</code> (default <code>288</code>)</li> <li>Build/load THOR backbone via TerraTorch + THOR extension</li> <li><code>ground_cover_m = sensor.scale_m * image_size</code></li> <li><code>patch_size</code> passed into THOR build params</li> <li>Forward model, extract token sequence <code>[N,D]</code></li> <li>Try building <code>grid</code>:</li> <li>first via THOR group-aware token layout (<code>group_merge</code>)</li> <li>fallback to generic square patch-token reshape</li> <li>if both fail, <code>grid</code> is unavailable</li> </ol>"},{"location":"models/thor_1_0_base/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":"Env var Default Effect <code>RS_EMBED_THOR_MODEL_KEY</code> <code>thor_v1_base</code> THOR backbone key for TerraTorch registry <code>RS_EMBED_THOR_CKPT</code> unset Local checkpoint path override <code>RS_EMBED_THOR_PRETRAINED</code> <code>1</code> Use pretrained weights (HF default path) <code>RS_EMBED_THOR_IMG</code> <code>288</code> Resize target image size <code>RS_EMBED_THOR_NORMALIZE</code> <code>thor_stats</code> <code>thor_stats</code>, <code>unit_scale</code>, or <code>none</code> <code>RS_EMBED_THOR_GROUP_MERGE</code> <code>mean</code> THOR group-grid aggregation: <code>mean</code>, <code>sum</code>, <code>concat</code> <code>RS_EMBED_THOR_PATCH_SIZE</code> <code>16</code> THOR flexi patch size parameter <code>RS_EMBED_THOR_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs <p>Notes:</p> <ul> <li><code>RS_EMBED_THOR_PATCH_SIZE</code> and <code>RS_EMBED_THOR_IMG</code> jointly affect token layout and <code>ground_cover_m</code>.</li> <li>Changing <code>group_merge</code> changes grid channel semantics and dimensionality (especially <code>concat</code>).</li> </ul>"},{"location":"models/thor_1_0_base/#output-semantics","title":"Output Semantics","text":""},{"location":"models/thor_1_0_base/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Pools token sequence using <code>_pool_thor_tokens(...)</code></li> <li>Uses expected THOR patch-token count when available to avoid pooling non-patch tokens incorrectly</li> <li>Metadata records pooling mode and <code>cls_removed</code></li> </ul>"},{"location":"models/thor_1_0_base/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>Preferred path: THOR group-aware grid (<code>grid_kind=\"thor_group_grid\"</code>) built from channel groups</li> <li>Fallback path: generic ViT patch-token reshape (<code>grid_kind=\"patch_tokens\"</code>)</li> <li>Can fail for some model/config/token layouts; adapter raises a clear error suggesting pooled output</li> </ul>"},{"location":"models/thor_1_0_base/#examples","title":"Examples","text":""},{"location":"models/thor_1_0_base/#minimal-provider-backed-example","title":"Minimal provider-backed example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"thor_1_0_base\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/thor_1_0_base/#example-thor-tuning-env-controlled","title":"Example THOR tuning (env-controlled)","text":"<pre><code># Example (shell):\n# export RS_EMBED_THOR_NORMALIZE=thor_stats\n# export RS_EMBED_THOR_GROUP_MERGE=mean\n# export RS_EMBED_THOR_IMG=288\n# export RS_EMBED_THOR_PATCH_SIZE=16\n</code></pre>"},{"location":"models/thor_1_0_base/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>missing optional deps (<code>terratorch</code>, <code>thor_terratorch_ext</code>)</li> <li>wrong <code>input_chw</code> shape (<code>C</code> must be <code>10</code>)</li> <li>invalid <code>RS_EMBED_THOR_GROUP_MERGE</code> (must be <code>mean</code> / <code>sum</code> / <code>concat</code>)</li> <li>grid unavailable for chosen config (token layout not square and group parsing failed)</li> <li>normalization mismatch causing unstable comparison across runs</li> </ul> <p>Recommended first checks:</p> <ul> <li>verify metadata fields: <code>model_key</code>, <code>normalization</code>, <code>group_merge</code>, <code>patch_size</code>, <code>ground_cover_m</code></li> <li>try <code>OutputSpec.pooled()</code> to isolate grid-layout issues</li> <li>revert to default <code>thor_stats</code> + <code>group_merge=mean</code> before benchmarking</li> </ul>"},{"location":"models/thor_1_0_base/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li><code>RS_EMBED_THOR_MODEL_KEY</code>, <code>RS_EMBED_THOR_PRETRAINED</code>, and local <code>CKPT</code> (if used)</li> <li>normalization mode</li> <li><code>image_size</code> and <code>patch_size</code></li> <li><code>group_merge</code> (affects grid representation)</li> <li>temporal window and provider compositing settings</li> </ul>"},{"location":"models/thor_1_0_base/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_thor.py</code></li> <li>Token/grid helpers: <code>src/rs_embed/embedders/_vit_mae_utils.py</code></li> </ul>"},{"location":"models/wildsat/","title":"WildSAT (<code>wildsat</code>)","text":"<p>Sentinel-2 RGB on-the-fly adapter for WildSAT checkpoints, supporting multiple backbone architectures (ViT/ResNet/Swin), optional decoder image-head features, and token-grid fallback behavior.</p>"},{"location":"models/wildsat/#quick-facts","title":"Quick Facts","text":"Field Value Model ID <code>wildsat</code> Family / Backbone WildSAT checkpoint loader + torchvision backbones (<code>vitb16</code>, <code>vitl16</code>, <code>resnet50</code>, <code>swint</code>) Adapter type <code>on-the-fly</code> Typical backend provider backend (<code>gee</code>) Primary input S2 RGB (<code>B4,B3,B2</code>) Temporal mode <code>range</code> in practice (normalized via shared helper) Output modes <code>pooled</code>, <code>grid</code> Extra side inputs none (but checkpoint/arch/image-head settings matter) Training alignment (adapter path) Medium (depends on checkpoint source, arch inference, normalization mode, and feature source)"},{"location":"models/wildsat/#when-to-use-this-model","title":"When To Use This Model","text":""},{"location":"models/wildsat/#good-fit-for","title":"Good fit for","text":"<ul> <li>experimenting with WildSAT checkpoints and different feature extraction targets</li> <li>comparing backbone features vs image-head features (<code>RS_EMBED_WILDSAT_FEATURE</code>)</li> <li>RGB workflows where you want a single adapter covering ViT/ResNet/Swin variants</li> </ul>"},{"location":"models/wildsat/#be-careful-when","title":"Be careful when","text":"<ul> <li>checkpoint architecture is inferred incorrectly (set <code>RS_EMBED_WILDSAT_ARCH</code> explicitly if needed)</li> <li>comparing runs with different normalization modes (<code>minmax</code> vs <code>unit_scale</code>)</li> <li>assuming <code>grid</code> is always a ViT patch grid (non-ViT or token-disabled paths can return <code>1x1</code> vector grid)</li> </ul>"},{"location":"models/wildsat/#input-contract-current-adapter-path","title":"Input Contract (Current Adapter Path)","text":""},{"location":"models/wildsat/#spatial-temporal","title":"Spatial / temporal","text":"<ul> <li>Provider backend only (<code>backend=\"gee\"</code> / provider-compatible backend)</li> <li><code>TemporalSpec</code> normalized via shared helper; use <code>TemporalSpec.range(...)</code> for reproducibility</li> </ul>"},{"location":"models/wildsat/#sensor-channels","title":"Sensor / channels","text":"<p>Default <code>SensorSpec</code> if omitted:</p> <ul> <li>Collection: <code>COPERNICUS/S2_SR_HARMONIZED</code></li> <li>Bands: <code>(\"B4\", \"B3\", \"B2\")</code></li> <li><code>scale_m=10</code>, <code>cloudy_pct=30</code>, <code>composite=\"median\"</code></li> </ul> <p><code>input_chw</code> contract:</p> <ul> <li>must be <code>CHW</code> with <code>C=3</code> in <code>(B4,B3,B2)</code> order</li> <li>expected raw values in <code>0..10000</code></li> <li>adapter clips NaN/Inf and converts to <code>uint8</code> RGB after normalization</li> </ul>"},{"location":"models/wildsat/#preprocessing-pipeline-current-rs-embed-path","title":"Preprocessing Pipeline (Current rs-embed Path)","text":"<ol> <li>Resolve checkpoint path (local or auto-download)</li> <li>Fetch S2 RGB patch (provider path) or use <code>input_chw</code></li> <li>Normalize <code>raw_chw</code> (<code>0..10000</code> -&gt; <code>[0,1]</code>) with <code>RS_EMBED_WILDSAT_NORM</code>:</li> <li><code>minmax</code> (default): per-tile min-max stretch after unit scaling</li> <li><code>unit_scale</code> / <code>none</code>: keep unit-scaled values (no extra per-tile stretch)</li> <li>Convert to <code>uint8 HWC</code> and resize to <code>RS_EMBED_WILDSAT_IMG</code> (default <code>224</code>)</li> <li>Load torchvision backbone + optional decoder image head from checkpoint</li> <li>Forward pass:</li> <li>choose feature source (<code>image_head</code>, <code>backbone</code>, or <code>auto</code>)</li> <li>optional token extraction for ViT backbones (used for token pooling / grid)</li> <li>Return pooled vector or grid</li> </ol> <p>Important behavior:</p> <ul> <li>If <code>grid</code> is requested but ViT tokens are unavailable (e.g., non-ViT arch or token extraction disabled), adapter returns a <code>1x1</code> grid (<code>grid_kind=\"vector_as_1x1\"</code>) instead of failing.</li> </ul>"},{"location":"models/wildsat/#environment-variables-tuning-knobs","title":"Environment Variables / Tuning Knobs","text":""},{"location":"models/wildsat/#runtime-feature-extraction","title":"Runtime / feature extraction","text":"Env var Default Effect <code>RS_EMBED_WILDSAT_ARCH</code> <code>auto</code> Backbone arch hint (<code>vitb16</code>, <code>vitl16</code>, <code>resnet50</code>, <code>swint</code>, or <code>auto</code>) <code>RS_EMBED_WILDSAT_IMG</code> <code>224</code> Resize target image size <code>RS_EMBED_WILDSAT_NORM</code> <code>minmax</code> <code>minmax</code>, <code>unit_scale</code>, or <code>none</code> <code>RS_EMBED_WILDSAT_FEATURE</code> <code>image_head</code> Feature source: <code>auto</code>, <code>image_head</code>, <code>backbone</code> <code>RS_EMBED_WILDSAT_IMAGE_BRANCH</code> <code>3</code> Preferred decoder branch for image head extraction <code>RS_EMBED_WILDSAT_POOLED_FROM_TOKENS</code> <code>0</code> If true and ViT tokens available, pooled output uses token pooling <code>RS_EMBED_WILDSAT_GRID_FROM_TOKENS</code> <code>1</code> Enable ViT token extraction for grid/token-based pooling <code>RS_EMBED_WILDSAT_FETCH_WORKERS</code> <code>8</code> Provider prefetch workers for batch APIs"},{"location":"models/wildsat/#checkpoint-path-download","title":"Checkpoint path / download","text":"Env var Default Effect <code>RS_EMBED_WILDSAT_CKPT</code> unset Local checkpoint path <code>RS_EMBED_WILDSAT_AUTO_DOWNLOAD</code> <code>1</code> Allow auto-download if <code>CKPT</code> not set <code>RS_EMBED_WILDSAT_CACHE_DIR</code> <code>~/.cache/rs_embed/wildsat</code> Checkpoint cache dir <code>RS_EMBED_WILDSAT_CKPT_MIN_BYTES</code> adapter threshold Download size sanity check <code>RS_EMBED_WILDSAT_GDRIVE_ID</code> official sample file id Google Drive source (default auto-download path) <code>RS_EMBED_WILDSAT_CKPT_FILE</code> <code>vitb16-imagenet-bnfc.pth</code> Local cached filename for GDrive path <code>RS_EMBED_WILDSAT_HF_REPO</code> unset Optional HF repo override (must pair with <code>HF_FILE</code>) <code>RS_EMBED_WILDSAT_HF_FILE</code> unset Optional HF file override (must pair with <code>HF_REPO</code>)"},{"location":"models/wildsat/#output-semantics","title":"Output Semantics","text":""},{"location":"models/wildsat/#outputspecpooled","title":"<code>OutputSpec.pooled()</code>","text":"<ul> <li>Default pooled output usually comes from selected feature source vector (<code>image_head</code> preferred by default)</li> <li>If <code>RS_EMBED_WILDSAT_POOLED_FROM_TOKENS=1</code> and ViT tokens are available, pooled output uses token pooling (<code>mean</code> / <code>max</code>)</li> <li>Metadata records:</li> <li><code>feature_source</code></li> <li><code>tokens_available</code></li> <li><code>pooled_from_tokens</code></li> </ul>"},{"location":"models/wildsat/#outputspecgrid","title":"<code>OutputSpec.grid()</code>","text":"<ul> <li>If ViT tokens are available and token-grid extraction is enabled:</li> <li>returns ViT patch-token grid (<code>grid_kind=\"vit_patch_tokens\"</code>)</li> <li>Otherwise:</li> <li>returns <code>1x1</code> vector grid (<code>grid_kind=\"vector_as_1x1\"</code>)</li> <li>Grid is model feature layout, not georeferenced raster pixels</li> </ul>"},{"location":"models/wildsat/#examples","title":"Examples","text":""},{"location":"models/wildsat/#minimal-provider-backed-example","title":"Minimal provider-backed example","text":"<pre><code>from rs_embed import get_embedding, PointBuffer, TemporalSpec, OutputSpec\n\nemb = get_embedding(\n    \"wildsat\",\n    spatial=PointBuffer(lon=121.5, lat=31.2, buffer_m=2048),\n    temporal=TemporalSpec.range(\"2022-06-01\", \"2022-09-01\"),\n    output=OutputSpec.pooled(),\n    backend=\"gee\",\n)\n</code></pre>"},{"location":"models/wildsat/#example-featurearch-tuning-env-controlled","title":"Example feature/arch tuning (env-controlled)","text":"<pre><code># Example (shell):\n# export RS_EMBED_WILDSAT_ARCH=vitb16\n# export RS_EMBED_WILDSAT_FEATURE=image_head\n# export RS_EMBED_WILDSAT_NORM=minmax\n# export RS_EMBED_WILDSAT_GRID_FROM_TOKENS=1\n</code></pre>"},{"location":"models/wildsat/#common-failure-modes-debugging","title":"Common Failure Modes / Debugging","text":"<ul> <li>backend mismatch (<code>wildsat</code> is provider-only)</li> <li>missing/invalid checkpoint path or auto-download failure</li> <li>unsupported / mis-inferred architecture (<code>RS_EMBED_WILDSAT_ARCH</code>)</li> <li>invalid <code>RS_EMBED_WILDSAT_FEATURE</code> value</li> <li>misunderstanding <code>grid</code> fallback (<code>1x1</code> vector grid is expected in some configs)</li> <li>token-based pooling requested but tokens unavailable (adapter silently falls back to vector path and records metadata)</li> </ul> <p>Recommended first checks:</p> <ul> <li>inspect metadata for <code>arch</code>, <code>feature_source</code>, <code>tokens_available</code>, <code>grid_kind</code></li> <li>set <code>RS_EMBED_WILDSAT_ARCH</code> explicitly if checkpoint inference is ambiguous</li> <li>fix checkpoint source first, then tune feature branch / normalization</li> </ul>"},{"location":"models/wildsat/#reproducibility-notes","title":"Reproducibility Notes","text":"<p>Keep fixed and record:</p> <ul> <li>checkpoint path/source and file hash if possible</li> <li><code>RS_EMBED_WILDSAT_ARCH</code></li> <li>normalization mode (<code>RS_EMBED_WILDSAT_NORM</code>)</li> <li>feature source / image branch / token-grid toggles</li> <li>temporal window and provider compositing settings</li> </ul>"},{"location":"models/wildsat/#source-of-truth-code-pointers","title":"Source of Truth (Code Pointers)","text":"<ul> <li>Registration/catalog: <code>src/rs_embed/embedders/catalog.py</code></li> <li>Adapter implementation: <code>src/rs_embed/embedders/onthefly_wildsat.py</code></li> <li>Shared token/grid helpers: <code>src/rs_embed/embedders/_vit_mae_utils.py</code></li> </ul>"}]}